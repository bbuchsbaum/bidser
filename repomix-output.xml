This file is a merged representation of a subset of the codebase, containing specifically included files, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: R/**/*.R, R/**/*.r, *.Rmd, *.rmd, DESCRIPTION, tests/**/*.R, tests/**/*.r
- Files matching patterns in .gitignore are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
R/
  all_generic.R
  bids.R
  bidsio.R
  check.R
  events.R
  match_helpers.R
  matchers.R
  mock_bids.R
  plot_bids.R
  sidecar.R
  specs.R
tests/
  testthat/
    test_events.R
    test_func_scans.R
    test_mock_bids.R
    test_parse.R
    test_preproc_scans.R
    test_search_files.R
  testthat.R
DESCRIPTION
README.Rmd
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="R/mock_bids.R">
#' @importFrom data.tree Node ToDataFrameTypeCol Traverse Aggregate Get Clone
#' @importFrom dplyr mutate filter group_by summarize ungroup select everything bind_rows tibble tribble n_distinct n any_of distinct lead lag case_when if_else arrange rename slice pull row_number
#' @importFrom tidyr nest unnest pivot_longer pivot_wider replace_na
#' @importFrom stringr str_detect str_match str_split str_remove str_replace str_c str_glue
#' @importFrom jsonlite read_json toJSON write_json
#' @importFrom readr read_tsv write_tsv read_delim write_delim cols col_character col_double col_integer col_logical col_factor spec locale default_locale read_lines write_lines read_file write_file guess_encoding format_tsv write_csv read_csv problems type_convert output_column
#' @importFrom fs file_size dir_create file_create path_dir file_exists dir_exists
#' @importFrom tibble as_tibble is_tibble tibble add_row deframe enframe has_name lst is_tibble
#' @importFrom rlang sym := abort warn inform is_scalar_character is_scalar_logical list2 exec enquo quo_name is_installed is_interactive check_installed check_dots_empty check_dots_used check_dots_unnamed caller_env current_env global_env interrupt %||% maybe_missing missing_arg seq2 set_names try_fetch with_options zap format_error_bullets is_string as_name inject parse_expr eval_tidy expr exprs new_environment env env_bind env_get env_has env_parent env_parents env_poke expr_deparse f_lhs f_rhs is_call is_call_simple is_formula is_integerish is_list is_named is_null is_primitive is_true is_false is_symbol local_options parse_expr caller_env empty_env global_env is_environment new_formula new_quosure quo quo_get_env quo_get_expr quo_is_call quo_is_missing quo_is_null quo_is_symbol quos rep_along splice with_handlers
#' @importFrom crayon has_color bold cyan green magenta yellow %+% blue red silver white make_style style has_style num_colors num_colors
NULL

# ---------------------------------------------------------------------------
# Helper Functions (Internal)
# ---------------------------------------------------------------------------

#' Generate BIDS Filename String
#'
#' Constructs a BIDS filename from provided entities based on common order.
#' Assumes entities are single strings or NULL/NA.
#'
#' @param subid Subject ID (required).
#' @param session Session ID (optional).
#' @param task Task label (optional).
#' @param acq Acquisition label (optional).
#' @param ce Contrast enhancement label (optional).
#' @param rec Reconstruction label (optional).
#' @param dir Direction label (optional).
#' @param run Run index (optional).
#' @param mod Modality label (optional, e.g., for fieldmaps).
#' @param echo Echo index (optional).
#' @param space Space label (optional, derivatives).
#' @param res Resolution label (optional, derivatives).
#' @param desc Description label (optional, derivatives).
#' @param label Label (optional, derivatives).
#' @param variant Variant label (optional, derivatives).
#' @param suffix The final suffix including extension (e.g., "bold.nii.gz") (required).
#' @param other_entities A named list of less common key-value pairs (optional).
#' @return A string representing the BIDS filename.
#' @keywords internal
#' @noRd
generate_bids_filename <- function(subid, session = NULL, task = NULL, acq = NULL, ce = NULL,
                                   rec = NULL, dir = NULL, run = NULL, mod = NULL, echo = NULL,
                                   space = NULL, res = NULL, desc = NULL, label = NULL,
                                   variant = NULL, suffix, other_entities = list()) {

  if (is.null(subid) || subid == "" || is.na(subid)) stop("'subid' is required.")
  if (is.null(suffix) || suffix == "" || is.na(suffix)) stop("'suffix' is required.")

  # Ensure prefix for subject ID
  if (!startsWith(subid, "sub-")) subid <- paste0("sub-", subid)

  # Common order of entities
  entities <- list(
    sub = subid,
    ses = session,
    task = task,
    acq = acq,
    ce = ce,
    dir = dir,
    rec = rec,
    run = run,
    mod = mod,
    echo = echo,
    space = space,
    res = res,
    label = label, # Often before desc
    desc = desc,
    variant = variant
  )

  # Append other entities
  entities <- c(entities, other_entities)

  # Filter out NULL, NA, or empty string values
  entities <- entities[!sapply(entities, function(x) is.null(x) || is.na(x) || x == "")]

  # Construct the filename parts
  parts <- lapply(names(entities), function(key) {
    val <- entities[[key]]
    # Check if value already has the key prefix (e.g., subid already "sub-01")
    if (startsWith(as.character(val), paste0(key, "-"))) {
      as.character(val)
    } else {
      paste0(key, "-", val)
    }
  })

  # Ensure suffix does not start with '_' (handled by joining)
  if (startsWith(suffix, "_")) suffix <- sub("^_", "", suffix)

  # Join parts with underscores and append the final suffix
  filename_base <- paste(unlist(parts), collapse = "_")
  filename <- paste0(filename_base, "_", suffix)

  # Replace potential double underscores (if an entity was empty but kept)
  filename <- gsub("__", "_", filename, fixed = TRUE)

  return(filename)
}


#' Generate Relative BIDS Path
#'
#' Constructs the relative directory path for a file within a BIDS structure.
#'
#' @param subid Subject ID.
#' @param session Session ID (optional).
#' @param datatype Datatype folder ('func', 'anat', 'fmap', 'dwi', etc.).
#' @param fmriprep Logical, is this a derivative file?
#' @param prep_dir The relative path to the derivatives directory.
#' @return A string representing the relative path (without the filename).
#' @keywords internal
#' @noRd
generate_bids_path <- function(subid, session = NULL, datatype, fmriprep = FALSE, prep_dir = "derivatives/fmriprep") {

  if (is.null(subid) || subid == "" || is.na(subid)) stop("'subid' is required.")
  if (is.null(datatype) || datatype == "" || is.na(datatype)) stop("'datatype' is required.")

  # Ensure prefix for subject ID
  if (!startsWith(subid, "sub-")) subid <- paste0("sub-", subid)

  path_parts <- character()

  if (fmriprep) {
    path_parts <- c(path_parts, prep_dir)
  } else {
    # Assumes raw data implies no top-level 'raw' folder in path string itself
    # path_parts <- c(path_parts, "raw") # Usually not part of the path string
  }

  path_parts <- c(path_parts, subid)

  if (!is.null(session) && !is.na(session) && session != "") {
    if (!startsWith(session, "ses-")) session <- paste0("ses-", session)
    path_parts <- c(path_parts, session)
  }

  path_parts <- c(path_parts, datatype)

  return(paste(path_parts, collapse = "/"))
}

#' @keywords internal
mock_key_match <- function(node_attrs, filters, default = FALSE) {
  # No longer uses ..., takes filters list directly
  if (length(filters) == 0) {
    return(TRUE)
  }

  keys <- names(filters)

  # Directly return the result of the checks for the given node_attrs
  result <- all(vapply(keys, function(k) {
    query_val <- filters[[k]]

    # Check if the key 'k' exists in the node attributes
    if (!k %in% names(node_attrs)) {
      # Key is missing in node. Match only if query allows ".*" or default=TRUE (strict=FALSE)
      match_result <- (is.character(query_val) && query_val == ".*") || default
      return(match_result)
    }

    # Key exists, get the node value
    node_val <- node_attrs[[k]]

    # If query is NULL, node must be NULL for a match
    if (is.null(query_val)) {
      match_result <- is.null(node_val)
      return(match_result)
    }

    # If query is ".*", it matches anything (if key exists or default allows missing)
    if (identical(query_val, ".*")) {
      return(TRUE)
    }

    # If node value is missing/NULL (despite key existing), match depends on default
    if (is.null(node_val) || is.na(node_val)) {
      match_result <- default
      return(match_result)
    }

    # Perform comparison/regex match
    if (is.character(node_val)) {
      # Use anchored regex match (^...$) for exact entity value comparison
      # Ensure query_val is treated as a pattern
      match_result <- any(stringr::str_detect(node_val, paste0("^(?:", query_val, ")$")))
      return(match_result)
    } else if (is.numeric(node_val) || is.integer(node_val)) {
      # Allow direct comparison or regex if query looks like one
      query_char <- as.character(query_val)
      # Check if query_char contains any common regex metacharacters
      if (grepl("[.^$*+?()\\[\\]\\{\\|\\\\]", query_char)) { 
        match_result <- stringr::str_detect(as.character(node_val), paste0("^(?:", query_char, ")$"))
        return(match_result)
      } else {
        match_result <- as.character(node_val) == query_char # Direct match
        return(match_result)
      }
    } else if (is.logical(node_val) && is.logical(query_val)) {
        match_result <- node_val == query_val # Allow logical matching
        return(match_result)
    }
    else {
      # Default to FALSE for other types or mismatches
      return(FALSE)
    }
  }, logical(1)))
  
  return(result)
}


#' Reconstruct Relative Path from Node
#'
#' Given a data.tree node from the mock BIDS structure, reconstructs its
#' relative path string. Handles raw vs derivative paths.
#'
#' @param node The data.tree node.
#' @param prep_dir The derivatives directory name used in the tree.
#' @return Relative path string.
#' @keywords internal
#' @noRd
reconstruct_node_path <- function(node, prep_dir = "derivatives/fmriprep") {
    pdir_parts <- strsplit(prep_dir, "/")[[1]]
    node_path_parts <- node$path

    # Check if the node is within the derivatives path structure
    # The root is level 1, 'raw' or 'prep_dir' is level 2
    is_prep <- length(node_path_parts) > (1 + length(pdir_parts)) &&
               all(node_path_parts[2:(1 + length(pdir_parts))] == pdir_parts)

    if (is_prep) {
        # Path starts from prep_dir downwards
        # e.g. node$path = [proj, deriv, fmriprep, sub-01, func, file.nii.gz]
        # result should be "derivatives/fmriprep/sub-01/func/file.nii.gz"
        paste(node_path_parts[-1], collapse = "/")
    } else if (length(node_path_parts) > 2 && node_path_parts[2] == "raw") {
        # Path starts from raw downwards (skip root and 'raw')
        # e.g. node$path = [proj, raw, sub-01, func, file.nii.gz]
        # result should be "sub-01/func/file.nii.gz"
        paste(node_path_parts[-(1:2)], collapse = "/")
    } else if (length(node_path_parts) == 2 && node$name %in% c("participants.tsv", "dataset_description.json")) {
         # Handle root files like participants.tsv directly
         node$name
    }
    else {
        # Fallback or unexpected structure, return full path minus root?
        # Or perhaps return NA/error. Let's try full path minus root for now.
        if (length(node_path_parts) > 1) {
            paste(node_path_parts[-1], collapse = "/")
        } else {
            node$name # Should only be the root node name
        }
    }
}



# ---------------------------------------------------------------------------
# Constructor Function: create_mock_bids
# ---------------------------------------------------------------------------

#' Create a Mock BIDS Project Object
#'
#' Generates an in-memory representation of a BIDS project, suitable for
#' testing and demonstration without requiring actual data files. Can optionally
#' create a "stub" directory structure on disk.
#'
#' @param project_name A character string for the project name.
#' @param participants Either a `data.frame` mirroring `participants.tsv` content
#'   (must include 'participant_id') or a character vector of participant IDs
#'   (e.g., `c("01", "02")`). If IDs are given, a minimal `part_df` is created.
#' @param dataset_description A list representing the `dataset_description.json`
#'   content. Defaults to a minimal valid description.
#' @param file_structure A `data.frame` or `tibble` defining the files in the
#'   mock structure. Each row represents a file. Required columns:
#'   `subid`, `datatype`, `suffix`. Optional BIDS entity columns: `session`,
#'   `task`, `run`, `acq`, `rec`, `dir`, `space`, `desc`, etc. Must also include
#'   a logical column `fmriprep` indicating if the file belongs in the derivatives
#'   directory specified by `prep_dir`.
#' @param event_data A named list where names are the *relative paths* of
#'   `events.tsv` files (e.g., "sub-01/func/sub-01_task-A_run-1_events.tsv")
#'   and values are the corresponding `tibble` or `data.frame` content for
#'   those files. These paths must correspond to files defined in `file_structure`
#'   with a `suffix` like "events.tsv".
#' @param create_stub Logical (default `FALSE`). If `TRUE`, write a stub BIDS
#'   directory structure to disk at `stub_path`. Zero-byte files are created
#'   except for `participants.tsv`, `dataset_description.json`, and `events.tsv`
#'   files specified in `event_data`.
#' @param stub_path Character string, the path where the stub directory will be
#'   created. Required if `create_stub = TRUE`.
#' @param prep_dir Character string, the path relative to the root for derivatives
#'   (default "derivatives/fmriprep"). This path structure will be used both in
#'   the internal `data.tree` and for stub creation.
#'
#' @return An object of class `mock_bids_project`.
#' @export
#' @examples
#' \donttest{
#' # --- Example Setup ---
#' participants_df <- tibble::tibble(participant_id = c("01", "02"), age = c(25, 30))
#'
#' file_structure_df <- tibble::tribble(
#'   ~subid, ~session, ~datatype, ~task,   ~run, ~suffix,                  ~fmriprep, ~desc,
#'   "01",   NA,       "anat",    NA,      NA,   "T1w.nii.gz",             FALSE,     NA,
#'   "01",   NA,       "func",    "taskA", "01", "bold.nii.gz",            FALSE,     NA,
#'   "01",   NA,       "func",    "taskA", "01", "events.tsv",             FALSE,     NA,
#'   "02",   "test",   "anat",    NA,      NA,   "T1w.nii.gz",             FALSE,     NA,
#'   "02",   "test",   "func",    "taskA", "01", "bold.nii.gz",            FALSE,     NA,
#'   "02",   "test",   "func",    "taskA", "01", "events.tsv",             FALSE,     NA,
#'   # Example derivative
#'   "01",   NA,       "func",    "taskA", "01", "preproc_bold.nii.gz",    TRUE,      "preproc" # Note: suffix carries desc
#' )
#'
#' # Define event data (paths must match generated structure)
#' event_data_list <- list()
#' event_data_list[["sub-01/func/sub-01_task-taskA_run-01_events.tsv"]] <- tibble::tibble(
#'   onset = c(1.0, 5.0), duration = c(0.5, 0.5), trial_type = c("condA", "condB")
#' )
#' event_data_list[["sub-02/ses-test/func/sub-02_ses-test_task-taskA_run-01_events.tsv"]] <-
#'   tibble::tibble(
#'     onset = c(1.5, 5.5), duration = c(0.5, 0.5), trial_type = c("condC", "condD")
#' )
#'
#' # Create the mock project (in memory only)
#' mock_proj <- create_mock_bids(
#'   project_name = "MockTaskA",
#'   participants = participants_df,
#'   file_structure = file_structure_df,
#'   event_data = event_data_list
#' )
#'
#' # Create the mock project and write stubs
#' mock_proj_stub <- create_mock_bids(
#'   project_name = "MockTaskA_stub",
#'   participants = c("01", "02"), # Example using just IDs
#'   file_structure = file_structure_df,
#'   event_data = event_data_list,
#'   create_stub = TRUE,
#'   stub_path = tempdir() # Use a temporary directory for example
#' )
#'
#' # --- Using the Mock Project ---
#' print(mock_proj)
#' print(participants(mock_proj))
#' print(tasks(mock_proj))
#' print(sessions(mock_proj)) # Should return "test"
#'
#' print(func_scans(mock_proj, subid = "01"))
#' print(event_files(mock_proj, subid = "02", session = "test"))
#'
#' # Read the injected event data
#' events_sub1 <- read_events(mock_proj, subid = "01")
#' print(events_sub1)
#' if (nrow(events_sub1) > 0) print(tidyr::unnest(events_sub1, cols = data))
#'
#' # Search for derivatives
#' print(search_files(mock_proj, suffix = "preproc_bold.nii.gz"))
#'
#' # Check stub directory (if created)
#' # list.files(mock_proj_stub$path, recursive = TRUE)
#' # if (file.exists(file.path(mock_proj_stub$path, names(event_data_list)[1]))) {
#' #   print(readLines(file.path(mock_proj_stub$path, names(event_data_list)[1])))
#' # }
#'
#' # Clean up stub directory if created in temp
#' # unlink(mock_proj_stub$path, recursive = TRUE)
#' }
create_mock_bids <- function(project_name,
                             participants,
                             file_structure,
                             dataset_description = NULL,
                             event_data = list(),
                             create_stub = FALSE,
                             stub_path = NULL,
                             prep_dir = "derivatives/fmriprep") {

  # --- Input Validation ---
  if (!rlang::is_scalar_character(project_name)) abort("'project_name' must be a single character string.")
  if (missing(file_structure) || !is.data.frame(file_structure)) abort("'file_structure' must be a data.frame or tibble.")
  req_cols <- c("subid", "datatype", "suffix", "fmriprep")
  if (!all(req_cols %in% names(file_structure))) {
    abort(paste("'file_structure' must contain columns:", paste(req_cols, collapse=", ")))
  }
  if (!is.logical(file_structure$fmriprep)) abort("'file_structure$fmriprep' must be logical.")

  if (create_stub && (!rlang::is_scalar_character(stub_path) || stub_path == "")) {
    abort("'stub_path' must be provided as a character string when 'create_stub' is TRUE.")
  }
  if (!rlang::is_list(event_data)) abort("'event_data' must be a list.")
  if (length(event_data) > 0 && !rlang::is_named(event_data)) abort("'event_data' list must be named with relative file paths.")

  # --- Process Participants ---
  if (is.character(participants)) {
    part_df <- tibble::tibble(participant_id = participants)
  } else if (is.data.frame(participants)) {
    if (!"participant_id" %in% names(participants)) {
      abort("'participants' data.frame must contain a 'participant_id' column.")
    }
    part_df <- tibble::as_tibble(participants)
  } else {
    abort("'participants' must be a character vector of IDs or a data.frame.")
  }
  # Ensure participant_id is character
  part_df$participant_id <- as.character(part_df$participant_id)
   # Ensure participant IDs in file_structure are valid
  valid_subs <- part_df$participant_id
  invalid_file_subs <- unique(file_structure$subid[!file_structure$subid %in% valid_subs])
   if (length(invalid_file_subs) > 0) {
       abort(paste("The following subids in 'file_structure' are not present in 'participants':", paste(invalid_file_subs, collapse=", ")))
   }


  # --- Process Dataset Description ---
  if (is.null(dataset_description)) {
    desc <- list(
      Name = project_name,
      BIDSVersion = "1.7.0", # Example version
      DatasetType = "raw", # Or specify if derivatives are primary
      GeneratedBy = list(list(Name = "bidser::create_mock_bids"))
    )
  } else if (rlang::is_list(dataset_description)) {
    desc <- dataset_description
  } else {
    abort("'dataset_description' must be a list or NULL.")
  }

  # --- Determine Metadata ---
  # Need to check the file_structure for sessions or fmriprep=TRUE
  has_sessions <- "session" %in% names(file_structure) && any(!is.na(file_structure$session) & file_structure$session != "")
  has_fmriprep <- any(file_structure$fmriprep)

  # --- Initialize Data Tree ---
  bids_tree <- data.tree::Node$new(project_name)
  bids_tree$AddChild("raw")
  if (has_fmriprep) {
    # Add prep_dir structure, potentially nested (e.g., derivatives/fmriprep)
    prep_parts <- strsplit(prep_dir, "/")[[1]]
    current_node <- bids_tree
    for (part in prep_parts) {
      if (is.null(current_node[[part]])) {
         current_node$AddChild(part)
      }
       current_node <- current_node[[part]]
    }
     # prep_root_node <- bids_tree[[prep_dir]] # simple case
     prep_root_node <- current_node # Use the deepest node created
  } else {
    prep_root_node <- NULL
  }
  raw_root_node <- bids_tree$raw

  # --- Populate Data Tree ---
  generated_event_paths <- character() # Keep track of event files defined

  for (i in 1:nrow(file_structure)) {
    row <- file_structure[i, ]

    # Extract all potential BIDS entities from the row
    # Handle cases where optional columns might not exist
    get_entity <- function(colname) {
      if (colname %in% names(row)) row[[colname]] else NULL
    }
    entities_in <- list(
        subid = get_entity("subid"),
        session = get_entity("session"),
        task = get_entity("task"),
        acq = get_entity("acq"),
        ce = get_entity("ce"),
        rec = get_entity("rec"),
        dir = get_entity("dir"),
        run = get_entity("run"),
        mod = get_entity("mod"),
        echo = get_entity("echo"),
        space = get_entity("space"),
        res = get_entity("res"),
        desc = get_entity("desc"),
        label = get_entity("label"),
        variant = get_entity("variant"),
        suffix = get_entity("suffix") # suffix is mandatory
    )
    # Clean NULLs for filename generation if function expects no NULLs
    entities_clean <- entities_in[!sapply(entities_in, is.null)]
    # Ensure mandatory fields are present if needed by helper
    entities_clean$subid <- row$subid # Ensure subid is always passed
    entities_clean$suffix <- row$suffix # Ensure suffix is always passed

    # Generate filename and path
    filename <- tryCatch({
        rlang::exec(generate_bids_filename, !!!entities_clean)
    }, error = function(e) {
        abort(paste("Error generating filename for row", i, ":", e$message))
    })

    relative_dir <- generate_bids_path(
      subid = row$subid,
      session = get_entity("session"),
      datatype = row$datatype,
      fmriprep = row$fmriprep,
      prep_dir = prep_dir
    )
    relative_path <- file.path(relative_dir, filename)

    # Use bidser::encode to get canonical entities (important!)
    # Requires bidser to be loaded or use :::
    encoded_entities <- tryCatch({
        # Use internal encode if possible, otherwise assume global ::
         if (exists("encode", envir = environment(create_mock_bids), inherits = FALSE)) {
             result <- bidser::encode(filename)
             result
         } else {
             # Fallback if running outside package context? Risky.
              # This requires the bidser package to be loaded globally.
             # A safer approach is to ensure this function is part of the bidser pkg.
              result <- encode(filename) # Assumes bidser::encode is available
              result
         }
    }, error = function(e) {
        warn(paste("Could not encode generated filename:", filename, " - May impact querying. Error:", e$message))
        # Fallback: use entities from file_structure row directly with standardized names
        fallback_entities <- list(
            name = filename,
            relative_path = relative_path,
            sub = row$subid,  # Use standard BIDS key
            ses = row$session, # Use standard BIDS key
            task = row$task,
            run = row$run,
            desc = row$desc,
            space = row$space
        )
        
        # Determine 'kind' from suffix or explicit kind if provided
        if (!is.null(row$kind) && !is.na(row$kind)) {
            fallback_entities$kind <- row$kind
        } else {
            # Try to guess kind from suffix
            if (grepl("bold", row$suffix, ignore.case = TRUE)) {
                fallback_entities$kind <- "bold"
                fallback_entities$suffix <- "bold" # Extract BIDS suffix part
            } 
            else if (grepl("T1w", row$suffix, ignore.case = TRUE)) {
                fallback_entities$kind <- "T1w"
                fallback_entities$suffix <- "T1w"
            } 
            else if (grepl("events.tsv", row$suffix, fixed=TRUE)) {
                fallback_entities$kind <- "events"
                fallback_entities$suffix <- "events"
            }
            else {
                # Default: try to extract suffix without extension
                suffix_part <- sub("\\.[^.]*$", "", row$suffix)
                fallback_entities$suffix <- suffix_part
                fallback_entities$kind <- suffix_part
            }
        }
        
        # Remove NULL or NA values
        fallback_entities <- fallback_entities[!sapply(fallback_entities, is.null)]
        fallback_entities <- fallback_entities[!sapply(fallback_entities, is.na)]
                
        return(fallback_entities)
    })

    if (is.null(encoded_entities)) {
       warn(paste("Encoding failed for:", filename, "- skipping this file in mock tree."))
       next # Skip file if encoding failed entirely
    }

    # Add filename itself to entities list for the node
    encoded_entities$name <- filename
    encoded_entities$relative_path <- relative_path # Store for convenience

    # Determine parent node in the tree
    parent_node <- if (row$fmriprep) prep_root_node else raw_root_node

    # Create directory structure within the data.tree
    path_parts <- strsplit(relative_dir, "/")[[1]]
    # Remove prep_dir parts if fmriprep=TRUE, as prep_root_node is already there
    if (row$fmriprep) {
        prep_dir_parts <- strsplit(prep_dir,"/")[[1]]
        # Check if path_parts start with prep_dir_parts and remove them
        if (length(path_parts) >= length(prep_dir_parts) &&
            all(path_parts[1:length(prep_dir_parts)] == prep_dir_parts)) {
            path_parts <- path_parts[-(1:length(prep_dir_parts))]
        }
    }

    current_node <- parent_node
    # Create intermediate nodes (subject, session, datatype)
    for (part in path_parts) {
       if (is.null(current_node[[part]])) {
            current_node$AddChild(part)
            # Add session ID attribute to session node when created
            if (grepl("^ses-", part) && !is.null(get_entity("session"))) {
                current_node[[part]]$session <- get_entity("session")
            }
             # Add subid attribute to subject node when created
             if (grepl("^sub-", part) && !is.null(get_entity("subid"))) {
                current_node[[part]]$subid <- get_entity("subid")
            }
        }
        current_node <- current_node[[part]]
    }

    # Add the leaf node (file) with its BIDS entities
    leaf_node <- current_node$AddChild(filename)
        
    # Assign all encoded entities to the node
    for (entity_name in names(encoded_entities)) {
      leaf_node[[entity_name]] <- encoded_entities[[entity_name]]
    }
    
    # Ensure both 'sub' and 'subid' are present for consistent searching
    if ("sub" %in% names(encoded_entities) && !("subid" %in% names(encoded_entities))) {
      leaf_node$subid <- encoded_entities$sub
    } else if ("subid" %in% names(encoded_entities) && !("sub" %in% names(encoded_entities))) {
      leaf_node$sub <- encoded_entities$subid
    }

    # Ensure both 'session' and 'ses' are present
    if ("session" %in% names(encoded_entities) && !("ses" %in% names(encoded_entities))) {
      leaf_node$ses <- encoded_entities$session
    } else if ("ses" %in% names(encoded_entities) && !("session" %in% names(encoded_entities))) {
      leaf_node$session <- encoded_entities$ses
    }

    # Track generated event file paths
    if (isTRUE(endsWith(row$suffix, "events.tsv"))) {
        generated_event_paths <- c(generated_event_paths, relative_path)
    }

  } # End loop through file_structure

  # --- Validate Event Data ---
  event_data_names <- names(event_data)
  mismatched_event_paths <- event_data_names[!event_data_names %in% generated_event_paths]
  if (length(mismatched_event_paths) > 0) {
    warn(paste("The following names in 'event_data' do not correspond to any 'events.tsv' files generated from 'file_structure':",
               paste(mismatched_event_paths, collapse=", ")))
    # Filter event_data to keep only valid ones
    event_data <- event_data[event_data_names %in% generated_event_paths]
  }
  # Ensure event data is tibble
  event_data_store <- lapply(event_data, tibble::as_tibble)


  # --- Create Stub Directory (Optional) ---
  actual_stub_path <- NULL
  if (create_stub) {
    actual_stub_path <- normalizePath(stub_path, mustWork = FALSE)
    fs::dir_create(actual_stub_path)

    # Write participants.tsv
    part_tsv_path <- file.path(actual_stub_path, "participants.tsv")
    tryCatch({
        readr::write_tsv(part_df, part_tsv_path)
    }, error = function(e) {
        warn(paste("Failed to write participants.tsv stub:", e$message))
    })

    # Write dataset_description.json
    desc_json_path <- file.path(actual_stub_path, "dataset_description.json")
    tryCatch({
        jsonlite::write_json(desc, desc_json_path, auto_unbox = TRUE, pretty = TRUE)
    }, error = function(e) {
        warn(paste("Failed to write dataset_description.json stub:", e$message))
    })

    # Get leaf nodes first
    leaf_nodes <- data.tree::Traverse(bids_tree, 
                        filterFun = function(node) node$isLeaf, 
                        traversal = "pre-order")

    # Now iterate over the collected leaf nodes
    for (node in leaf_nodes) { 
        # Skip root node files if handled above
        if (node$level <= 2 && node$name %in% c("participants.tsv", "dataset_description.json")) next

        # Reconstruct the intended relative path for this leaf node
        # This needs care to match the event_data keys exactly
        rel_path_for_file <- node$relative_path # Use stored path

        if (is.null(rel_path_for_file)) {
            warn(paste("Node", node$name, "missing relative_path attribute, cannot create stub file."))
            next # Skip this node
        }

        full_disk_path <- file.path(actual_stub_path, rel_path_for_file)

        # Ensure directory exists
        fs::dir_create(fs::path_dir(full_disk_path))

        # Check if it's an event file with data
        if (endsWith(node$name, "events.tsv") && rel_path_for_file %in% names(event_data_store)) {
            tryCatch({
                readr::write_tsv(event_data_store[[rel_path_for_file]], full_disk_path, na = "n/a")
            }, error = function(e) {
                warn(paste("Failed to write event file stub:", full_disk_path, "-", e$message))
                fs::file_create(full_disk_path) # Create empty if write fails
            })
        } else {
            # Create zero-byte file
            if (!fs::file_exists(full_disk_path)) { # Avoid overwriting if somehow exists
                 fs::file_create(full_disk_path)
            }
        }
    }
  }

  # --- Construct Mock Project Object ---
  mock_project <- structure(
    list(
      name = project_name,
      part_df = part_df,
      desc = desc,
      bids_tree = bids_tree,
      event_data_store = event_data_store,
      path = if (create_stub) actual_stub_path else paste0("mock://", project_name), # Indicate mock path
      has_sessions = has_sessions,
      has_fmriprep = has_fmriprep,
      prep_dir = prep_dir
    ),
    class = c("mock_bids_project", "list") # Inherit from list for basic access
  )

  return(mock_project)
}


# ---------------------------------------------------------------------------
# S3 Methods for mock_bids_project
# ---------------------------------------------------------------------------

#' Print Mock BIDS Project Summary
#'
#' Provides a console summary of the mock BIDS project, displaying key information
#' like participant count, tasks, sessions, derivatives status, and discovered
#' BIDS entities.
#'
#' @param x A `mock_bids_project` object.
#' @param ... Extra arguments (ignored).
#' @return The `mock_bids_project` object `x` invisibly.
#' @export
#' @examples
#' # Create a simple mock project
#' parts <- data.frame(participant_id = "01")
#' fs <- data.frame(participant_id = "01", datatype="func", suffix="bold.nii.gz", fmriprep=FALSE)
#' mock_proj <- create_mock_bids("SimpleMock", parts, fs)
#'
#' # Print the summary
#' print(mock_proj)
print.mock_bids_project <- function(x, ...) {
  # Check if crayon is available and use it
  has_crayon <- rlang::is_installed("crayon") && crayon::has_color()

  cat_col <- function(label, value, col_fn = crayon::cyan) {
      if (has_crayon) {
          cat(crayon::bold(label), col_fn(value), "\n")
      } else {
          cat(label, value, "\n")
      }
  }

  cat(if (has_crayon) crayon::bold("Mock BIDS Project Summary") else "Mock BIDS Project Summary", "\n")
  cat_col("Project Name: ", x$name)
  cat_col("Participants (n): ", nrow(x$part_df), col_fn = crayon::green)

  tasks_list <- tasks(x)
  tasks_str <- if (length(tasks_list) > 0) paste(tasks_list, collapse = ", ") else "(none)"
  cat_col("Tasks: ", tasks_str, col_fn = crayon::yellow)

  if (x$has_sessions) {
    sessions_list <- sessions(x)
    sessions_str <- if (length(sessions_list) > 0) paste(sessions_list, collapse = ", ") else "(none)"
    cat_col("Sessions: ", sessions_str, col_fn = crayon::yellow)
  }

  if (x$has_fmriprep) {
    cat_col("Derivatives: ", x$prep_dir, col_fn = crayon::magenta)
  }

  # Get unique datatypes from the tree structure
  datatypes <- unique(na.omit(x$bids_tree$Get("datatype", filterFun = data.tree::isLeaf)))
  dt_str <- if (length(datatypes) > 0) paste(datatypes, collapse = ", ") else "(none)"
  cat_col("Datatypes: ", dt_str, col_fn = crayon::green)

  # Get unique suffixes from leaf nodes
  suffixes <- unique(na.omit(x$bids_tree$Get("suffix", filterFun = data.tree::isLeaf)))
  suf_str <- if (length(suffixes) > 0) paste(suffixes, collapse = ", ") else "(none)"
  cat_col("Suffixes: ", suf_str, col_fn = crayon::green)

  # Get all unique keys stored in leaf nodes
  all_keys <- unique(unlist(x$bids_tree$Get(function(node) names(node$attributes), filterFun = data.tree::isLeaf)))
  # Filter out internal/common ones if desired
  internal_keys <- c("name", "relative_path", "children", "level", "parent", "path", "path_string", "position", "count", "is_leaf", "is_root", "root", "height")
  bids_keys <- sort(setdiff(all_keys, internal_keys))
  keys_str <- if (length(bids_keys) > 0) paste(bids_keys, collapse = ", ") else "(none)"
  cat_col("BIDS Keys: ", keys_str, col_fn = crayon::yellow)

  cat("Path: ", x$path, "\n") # Display the path (mock or stub)

  invisible(x)
}


#' Get Participants from Mock BIDS Project
#'
#' Extracts the unique participant IDs from the mock project definition.
#' Note: Returns IDs *without* the "sub-" prefix for consistency with `bids_project` methods.
#'
#' @param x A `mock_bids_project` object.
#' @param ... Extra arguments (ignored).
#' @return Character vector of unique participant IDs (e.g., c("01", "02")), sorted.
#' @export
#' @examples
#' # Create a mock project
#' parts <- data.frame(participant_id = c("sub-01", "sub-02"))
#' fs <- data.frame(subid=c("01", "02"), datatype="func", suffix="bold.nii.gz", fmriprep=FALSE)
#' mock_proj <- create_mock_bids("SimpleMock", parts, fs)
#'
#' # Get participant IDs
#' participants(mock_proj)
participants.mock_bids_project <- function(x, ...) {
  # Ensure participant_id is character, remove "sub-" prefix if present for consistency
  ids <- as.character(x$part_df$participant_id)
  ids <- stringr::str_remove(ids, "^sub-")
  # Return sorted unique IDs
  return(sort(unique(ids)))
}


#' Get Sessions from Mock BIDS Project
#'
#' Extracts the unique session IDs found in the mock project's file structure.
#' Note: Returns IDs *without* the "ses-" prefix.
#'
#' @param x A `mock_bids_project` object.
#' @param ... Extra arguments (ignored).
#' @return Character vector of unique session IDs (e.g., c("pre", "post")), sorted,
#'   or `NULL` if the project does not have sessions.
#' @export
#' @examples
#' # Create a mock project with sessions
#' parts <- data.frame(participant_id = "01")
#' fs <- data.frame(subid="01", session="test", datatype="func", suffix="bold.nii.gz", fmriprep=FALSE)
#' mock_proj <- create_mock_bids("SessionMock", parts, fs)
#'
#' # Get session IDs
#' sessions(mock_proj)
#'
#' # Project without sessions
#' fs_no_session <- data.frame(subid="01", datatype="func", suffix="bold.nii.gz", fmriprep=FALSE)
#' mock_proj_no_sess <- create_mock_bids("NoSessionMock", parts, fs_no_session)
#' sessions(mock_proj_no_sess) # Returns NULL
sessions.mock_bids_project <- function(x, ...) {
  if (!x$has_sessions) {
    return(NULL)
  }
  # Retrieve 'session' attribute from nodes that have it defined
  sessions_found <- unique(unlist(x$bids_tree$Get("session", filterFun = function(node) !is.null(node$session))))
  if (length(sessions_found) == 0) {
    return(NULL)
  }
  # Remove "ses-" prefix if present
  sessions_found <- stringr::str_remove(sessions_found, "^ses-")
  return(sort(sessions_found))
}


#' Get Tasks from Mock BIDS Project
#'
#' Extracts the unique task names found in the mock project's file structure.
#' Note: Returns names *without* the "task-" prefix.
#'
#' @param x A `mock_bids_project` object.
#' @param ... Extra arguments (ignored).
#' @return Character vector of unique task names (e.g., c("rest", "nback")), sorted.
#' @export
#' @examples
#' # Create a mock project with tasks
#' parts <- data.frame(participant_id = "01")
#' fs <- data.frame(subid="01", task="taskA", run="01", datatype="func", 
#'                  suffix="bold.nii.gz", fmriprep=FALSE)
#' fs <- rbind(fs, data.frame(subid="01", task="taskB", run="01", datatype="func", 
#'                           suffix="bold.nii.gz", fmriprep=FALSE))
#' mock_proj <- create_mock_bids("TaskMock", parts, fs)
#'
#' # Get task names
#' tasks(mock_proj)
tasks.mock_bids_project <- function(x, ...) {
  # Retrieve 'task' attribute from nodes where it's defined
  tasks_found <- unique(unlist(x$bids_tree$Get("task", filterFun = function(node) !is.null(node$task) && !is.na(node$task))))
  # Remove "task-" prefix if present
  tasks_found <- stringr::str_remove(tasks_found, "^task-")
  return(sort(tasks_found))
}

#' Search Files in Mock BIDS Structure
#'
#' Finds files in the mock BIDS tree by matching file names and BIDS entities.
#'
#' @param x A `mock_bids_project` object.
#' @param regex A regular expression to match filenames (node names). Default `".*"`.
#' @param full_path If `TRUE`, return full paths (prefixed with `x$path`).
#'        If `FALSE`, return relative paths within the BIDS structure. Default `FALSE`.
#' @param strict If `TRUE` (default), queries for a BIDS entity (e.g., `task="X"`)
#'        require the entity to exist on the file node and match the pattern.
#'        If `FALSE`, files lacking the queried entity are not automatically excluded
#'        (though they won't match if the pattern isn't `.*`).
#' @param ... Additional BIDS entities to match (e.g., `subid = "01"`, `task = "rest"`).
#'        Values are treated as regex patterns unless they are simple strings without regex characters.
#' @return A character vector of matching file paths, or `NULL` if no matches.
#' @export
search_files.mock_bids_project <- function(x, regex = ".*", full_path = FALSE, strict = TRUE, ...) {
  # Extract fmriprep parameter if provided
  dots <- list(...)
  fmriprep_filter <- NULL
  
  # Handle parameter name conversion
  # Map 'sub' to 'subid' and vice versa to handle inconsistencies in storage vs search
  if("subid" %in% names(dots) && !("sub" %in% names(dots))) { 
    dots$sub <- dots$subid  # When user passes subid, also check sub
  }
  if("sub" %in% names(dots) && !("subid" %in% names(dots))) {
    dots$subid <- dots$sub  # When user passes sub, also check subid
  }
  
  # Use `ses` for consistency if provided as `session`
  if("session" %in% names(dots) && !("ses" %in% names(dots))) { 
    dots$ses <- dots$session 
  }
  # Also ensure 'session' exists if 'ses' is provided
  if("ses" %in% names(dots) && !("session" %in% names(dots))) { 
    dots$session <- dots$ses 
  }

  if ("fmriprep" %in% names(dots)) {
    fmriprep_filter <- dots$fmriprep
    # Remove fmriprep from dots before passing to mock_key_match
    dots <- dots[names(dots) != "fmriprep"]
    if (!is.logical(fmriprep_filter) || length(fmriprep_filter) != 1) {
       rlang::warn("'fmriprep' filter must be TRUE or FALSE. Ignoring.")
       fmriprep_filter <- NULL
    }
  }

  # Define the filter function
  filterNodes <- function(node) {
    if (!node$isLeaf) return(FALSE)

    # Check filename regex
    if (!stringr::str_detect(node$name, regex)) {
      # cat("DEBUG search_files: Node", node$name, "rejected - filename doesn't match regex\n")
      return(FALSE)
    }

    # Determine if node is raw or derivative based on its path
    is_in_deriv <- FALSE
    node_path_str_parts <- node$path # Get path components from root
    prep_dir_parts <- strsplit(x$prep_dir, "/")[[1]]
    if (x$has_fmriprep && 
        length(node_path_str_parts) > (1 + length(prep_dir_parts)) &&
        all(node_path_str_parts[2:(1 + length(prep_dir_parts))] == prep_dir_parts)) {
         is_in_deriv <- TRUE
    }

    # Apply fmriprep filter if specified
    if (!is.null(fmriprep_filter)) {
      # Filter based on fmriprep value
      if (fmriprep_filter && !is_in_deriv) {
        # cat("DEBUG search_files: Node", node$name, "rejected - want deriv but not in deriv\n")
        return(FALSE) # Want deriv, but not in deriv
      }
      if (!fmriprep_filter && is_in_deriv) {
        # cat("DEBUG search_files: Node", node$name, "rejected - want raw but in deriv\n")
        return(FALSE) # Want raw, but in deriv
      }
    }

    # Regular entity filtering using mock_key_match
    if (!mock_key_match(node_attrs = node, filters = dots, default = !strict)) {
      # Debugging for specific node failures can go here if needed, carefully accessing variables
      return(FALSE)
    }

    return(TRUE)
  }

  # Get the relative paths of matching leaf nodes
  relative_paths <- x$bids_tree$Get(function(node) node$relative_path, filterFun = filterNodes, simplify = FALSE)

  # Filter out any NULL paths that might have resulted
  relative_paths <- Filter(Negate(is.null), relative_paths)

  if (length(relative_paths) == 0) {
    return(NULL)
  }

  # Convert list to vector and ensure uniqueness
  relative_paths <- unique(unlist(relative_paths))

  # Add full path prefix if requested
  if (full_path) {
    if (startsWith(x$path, "mock://")) {
      proj_prefix <- sub("^mock://", "", x$path)
      final_paths <- file.path(proj_prefix, relative_paths)
    } else {
      final_paths <- file.path(x$path, relative_paths)
    }
  } else {
    final_paths <- relative_paths
  }

  return(final_paths)
}


#' Get Functional Scans from Mock BIDS Project
#' @export
#' @rdname func_scans
#' @param x A mock_bids_project object
#' @param subid Regex to match subject IDs (default: ".*")
#' @param task Regex to match tasks (default: ".*")
#' @param run Regex to match runs (default: ".*") 
#' @param session Regex to match sessions (default: ".*")
#' @param kind Type of functional data (default: "bold")
#' @param suffix Regex pattern for file suffix (default: "nii(\\.gz)?$")
#' @param full_path If TRUE, return full file paths (default: TRUE)
#' @param ... Additional arguments passed to search_files
func_scans.mock_bids_project <- function(x, subid = ".*", task = ".*", run = ".*", session = ".*",
                                         kind = "bold", suffix = "nii(\\.gz)?$", full_path = TRUE, ...) {
  # Use search_files, filtering for raw files (fmriprep=FALSE),
  # and matching the provided kind. Use suffix arg for regex matching filename end.

  filter_entities <- list(
      kind = kind,
      sub = subid,  # Both parameter names for consistent matching 
      subid = subid,
      task = task,
      run = run,
      ses = session, # Both parameter names for consistent matching 
      session = session,
      ...
  )
  filter_entities <- Filter(Negate(is.null), filter_entities)

  search_args <- list(
      x = x,
      regex = paste0(".*\\.", suffix), # Regex for filename ending
      full_path = full_path,
      fmriprep = FALSE # Explicitly search only raw data
  )

  final_args <- c(search_args, filter_entities)
  rlang::exec(search_files, !!!final_args)
}



#' Get Event Files from Mock BIDS Project
#' @export
#' @rdname event_files-method
#' @param x A mock_bids_project object
#' @param subid Regex to match subject IDs (default: ".*")
#' @param task Regex to match tasks (default: ".*")
#' @param run Regex to match runs (default: ".*")
#' @param session Regex to match sessions (default: ".*")
#' @param full_path If TRUE, return full paths of files (default: TRUE)
#' @param ... Additional arguments passed to internal functions
event_files.mock_bids_project <- function(x, subid = ".*", task = ".*", run = ".*", session = ".*", full_path = TRUE, ...) {
  
  # Search specifically for events.tsv files, assuming they are raw data
  result <- search_files(
    x,
    regex = "events\\.tsv$",
    full_path = full_path,
    sub = subid,
    subid = subid, # Pass both parameter names for consistent matching
    task = task,
    run = run,
    ses = session, # Both parameter names for consistent matching 
    session = session,
    fmriprep = FALSE, # Events usually associated with raw data
    kind = "events", # Pass kind="events" if encode() produces it reliably
    ...
  )
  
  return(result)
}




#' @export
preproc_scans.mock_bids_project <- function(x, subid = ".*", task = ".*", run = ".*", session = ".*",
                                           variant = NULL, space = ".*", modality = "bold",
                                           kind = "bold", desc = "preproc", suffix = "nii\\.gz$",
                                           full_path = TRUE, ...) {
  if (!x$has_fmriprep) {
    rlang::inform("Mock project does not have derivatives enabled.")
    return(NULL)
  }

  # Build entity list for filtering
  filter_entities <- list(
      kind = kind,       # Usually the BIDS type like 'bold' or 'T1w'
      desc = desc,       # e.g., 'preproc'
      space = space,
      sub = subid,       # Pass both parameter names for consistent matching
      subid = subid,
      task = task,
      run = run,
      ses = session, # Both parameter names for consistent matching 
      session = session,
      variant = variant, # Will be NULL if not provided, handled by Filter
      ...
  )
  filter_entities <- Filter(Negate(is.null), filter_entities)

  # Build arguments for search_files call
  search_args <- list(
      x = x,
      regex = paste0(".*\\.", suffix), # Regex for filename ending
      full_path = full_path,
      fmriprep = TRUE # Explicitly search only derivatives
  )

  final_args <- c(search_args, filter_entities)
  rlang::exec(search_files, !!!final_args)
}


#' Read Event Files from Mock BIDS Project
#'
#' Retrieves and formats event data stored within the mock project object.
#'
#' @param x A `mock_bids_project` object.
#' @param subid Regex pattern for subject IDs. Default `".*"`.
#' @param task Regex pattern for task names. Default `".*"`.
#' @param run Regex pattern for run indices. Default `".*"`.
#' @param session Regex pattern for session IDs. Default `".*"`.
#' @param ... Additional arguments passed to `event_files`.
#' @return A nested tibble with columns `.subid`, `.task`, `.run`, `.session` (if applicable),
#'   and `data` (containing the event tibbles), or an empty tibble if no matching data.
#' @export
read_events.mock_bids_project <- function(x, subid = ".*", task = ".*", run = ".*", session = ".*", ...) {

  # Find the relative paths of the relevant event files using the S3 method
  relative_event_paths <- event_files.mock_bids_project(
      x,
      subid = subid, # Pass subid here
      task = task,
      run = run,
      session = session, # Pass session here
      full_path = FALSE, # Need relative paths to key into event_data_store
      ...
  )

  if (is.null(relative_event_paths) || length(relative_event_paths) == 0) {
    # inform is noisy, return empty tibble quietly unless verbose option added
    # rlang::inform("No matching event files found in the mock project.")
    return(tibble::tibble(
        .subid = character(),
        .task = character(),
        .run = character(),
        .session = character(),
        data = list()
        ))
  }

  all_event_data <- list()

  # Retrieve data for each found path
  for (rel_path in relative_event_paths) {
    if (rel_path %in% names(x$event_data_store)) {
      event_df <- x$event_data_store[[rel_path]]

      # Find the corresponding node in the tree to get metadata reliably
      target_node <- NULL
      # Use data.tree::FindNode which might be cleaner if node names are unique path components
      # Or stick with Traverse if nodes might have same name but different attrs/path
      node_list <- data.tree::Traverse(x$bids_tree, filterFun = function(n) {
           n$isLeaf && !is.null(n$relative_path) && n$relative_path == rel_path
      })
      if (!is.null(node_list) && length(node_list) > 0) {
          target_node <- node_list[[1]] # Assume first match is correct
      }

      if (!is.null(target_node)) {
          # --- Extract metadata --- Ensure these attribute names are correct!
          meta <- list(
              .subid = target_node$subid %||% target_node$sub, # Try both attribute names
              .task = target_node$task,
              .run = target_node$run,
              .session = target_node$ses %||% target_node$session # Try both attribute names
          )
          # Remove NULLs and ensure required columns exist, even if NA
          meta$.subid <- meta$.subid %||% NA_character_
          meta$.task <- meta$.task %||% NA_character_
          meta$.run <- meta$.run %||% NA_character_
          meta$.session <- meta$.session %||% NA_character_

          # Combine with event_df
          if(nrow(event_df) > 0) {
              meta_df <- tibble::as_tibble(meta)
              combined_df <- dplyr::bind_cols(meta_df, event_df)
              all_event_data[[rel_path]] <- combined_df
          } else {
              # Handle empty event files - create tibble with just metadata
               meta_df <- tibble::as_tibble(meta)
               # Add necessary columns if event_df was empty but metadata exists
               if(nrow(meta_df)>0){
                    meta_df <- meta_df %>% dplyr::mutate(onset = NA_real_, duration = NA_real_) # Example cols
               }
               # If meta is also empty, this results in an empty tibble, handled by bind_rows
               all_event_data[[rel_path]] <- meta_df
          }
      } else {
        warn(paste("Could not find node in bids_tree corresponding to event file path:", rel_path))
      }
    } else {
      warn(paste("Event data not found in store for path:", rel_path))
    }
  }

  if (length(all_event_data) == 0) {
     # inform is noisy
     # rlang::inform("No event data could be loaded for the matching files.")
     return(tibble::tibble(
         .subid = character(), .task = character(), .run = character(),
         .session = character(), data = list()
       ))
  }

  # Combine all data frames
  final_df <- dplyr::bind_rows(all_event_data)

  # Check if essential grouping vars were created
  if (!all(c(".subid", ".task", ".run", ".session") %in% names(final_df))) {
       rlang::warn("Missing essential metadata columns (.subid, .task, .run, .session) after combining event data. Cannot nest correctly.")
       # Return flat frame or try partial nesting? Return flat for now.
       return(final_df)
   }


  # Create the nested structure
  # Ensure grouping vars actually exist before grouping
  grouping_vars <- intersect(c(".subid", ".task", ".run", ".session"), names(final_df))

  # Remove grouping vars with all NAs (like .session if none exist)
  # grouping_vars <- grouping_vars[sapply(grouping_vars, function(v) !all(is.na(final_df[[v]])))]

  if (length(grouping_vars) > 0) {
      # Handle potential NA grouping vars if needed by group_by
      nested_df <- final_df %>%
          # Convert NA sessions/runs to a specific value if group_by drops NAs?
          # Or ensure they are character NAs
          dplyr::group_by(!!!rlang::syms(grouping_vars)) %>%
          tidyr::nest()

      # Ensure standard columns exist
       std_cols <- c(".subid", ".task", ".run", ".session", "data")
       for(col in std_cols) {
           if (!col %in% names(nested_df)) {
               # Add missing column - decide default type carefully
               if(col=="data") nested_df[[col]] <- list() else nested_df[[col]] <- NA_character_
           }
       }
       # Reorder columns
       nested_df <- nested_df %>% dplyr::select(dplyr::all_of(std_cols))

  } else {
       rlang::warn("Could not determine grouping variables for nesting event data.")
       nested_df <- tibble::tibble(data = list(final_df)) # Fallback
  }

  return(nested_df)
}


#' Find Confound Files in Mock BIDS Project
#'
#' Searches the mock BIDS structure for files matching typical confound file patterns
#' (e.g., `*_confounds*.tsv`, `*_regressors*.tsv`, `*_timeseries*.tsv`)
#' within the derivatives directory.
#'
#' @details This function assumes confound files reside in the derivatives path
#'   specified by `x$prep_dir` and were defined in the `file_structure`
#'   passed to `create_mock_bids` with `fmriprep=TRUE`.
#'
#' @param x A `mock_bids_project` object.
#' @param subid Regex pattern for subject IDs. Default `".*"`.
#' @param task Regex pattern for task names. Default `".*"`.
#' @param session Regex pattern for session IDs. Default `".*"`.
#' @param run Regex pattern for run indices. Default `".*"`.
#' @param full_path If `TRUE`, return full paths (prefixed with `x$path`). 
#'        If `FALSE` (default), return relative paths.
#' @param ... Additional arguments passed to `search_files`.
#' @return A character vector of relative or full paths to potential confound files,
#'   or `NULL` if none are found.
#' @export
#' @rdname confound_files-method
#' @examples
#' # Setup mock project with a derivative confound file
#' participants_df <- tibble::tibble(participant_id = "01")
#' file_structure_df <- tibble::tribble(
#'   ~subid, ~session, ~datatype, ~task, ~run, ~suffix, ~fmriprep, ~desc,
#'   "01",   NA,       "func",    "taskA", "01", 
#'   "desc-confounds_timeseries.tsv", TRUE, "confounds"
#' )
#' mock_proj <- create_mock_bids("ConfoundMock", participants_df, file_structure_df)
#' 
#' # Find confound files
#' confound_files(mock_proj)
#' 
#' # Find for specific subject
#' confound_files(mock_proj, subid="01")
confound_files.mock_bids_project <- function(x, subid = ".*", task = ".*", session = ".*", run = ".*", full_path = FALSE, ...) {
  if (!x$has_fmriprep) {
    inform("Mock project does not have derivatives enabled, cannot search for confound files.")
    return(NULL)
  }
  
  # Define common regex patterns for confound files
  confound_regex <- "(confounds|regressors|timeseries)\\.tsv$"
  
  search_files(
    x,
    regex = confound_regex,
    full_path = full_path,
    sub = subid,
    task = task,
    ses = session,
    run = run,
    fmriprep = TRUE, # Explicitly search only derivatives
    ...
  )
}


# Example placeholder for read_confounds
#' Read Confound Files (Mock Implementation)
#' @inheritParams search_files.mock_bids_project
#' @param x A `mock_bids_project` object.
#' @param cvars Variables to select (ignored in mock).
#' @param npcs PCA components (ignored in mock).
#' @param perc_var PCA variance (ignored in mock).
#' @param nest Nest output (ignored in mock, returns NULL).
#' @param ... Additional BIDS entities (passed to `search_files`).
#' @return NULL (or potentially an empty mock structure). Currently returns NULL.
#' @export
read_confounds.mock_bids_project <- function(x, subid = ".*", task = ".*", session = ".*", run = ".*",
                                             cvars = NULL, npcs = -1, perc_var = -1, nest = TRUE, ...) {
  inform("`read_confounds` for mock_bids_project is not implemented to return data. Finding files only.")

  # Find confound file paths
  conf_files <- search_files(x, regex = "(confounds|regressors|timeseries)\\.tsv$",
                             full_path = FALSE, # Relative path might be useful
                             sub = subid, # Use 'sub'
                             task = task, 
                             ses = session, # Use 'ses'
                             run = run, ...)

  if (is.null(conf_files)) {
     inform("No matching confound files found in mock project structure.")
  } else {
     inform(paste("Found potential confound files:", paste(conf_files, collapse=", ")))
  }
  # Mock version does not store or return confound data by default
  # Could be extended to accept confound_data similar to event_data if needed
  return(NULL)
}


#' Create Preprocessing Mask (Mock Implementation)
#'
#' This function is not implemented for `mock_bids_project` objects as they do not
#' contain actual image data required to create a mask.
#'
#' @param x A `mock_bids_project` object.
#' @param ... Arguments (ignored).
#' @return Throws an error indicating the function is not applicable to mock objects.
#' @export
#' @rdname create_preproc_mask-method
create_preproc_mask.mock_bids_project <- function(x, ...) {
  abort("`create_preproc_mask` requires actual image data and cannot be used with `mock_bids_project` objects.")
}
</file>

<file path="R/plot_bids.R">
#' Plot a comprehensive visual overview of a BIDS project
#'
#' This function creates a multi-panel visualization of a BIDS project structure,
#' showing file distributions, completeness, and data characteristics.
#'
#' @param x A \code{bids_project} object
#' @param interactive Logical. Whether to create an interactive plot (default TRUE)
#' @param color_scheme Character. Name of the color palette to use (default "viridis")
#' @param include_derivatives Logical. Whether to include derivatives data in the visualization (default TRUE)
#' @param file_size_scale Character. Whether to scale file sizes ("log", "sqrt", or "linear", default "log")
#' @param highlight_missing Logical. Whether to highlight missing data points (default TRUE)
#' @param visualization_mode Character. The mode of visualization to use ("standard", "heatmap", or "complete")
#' @param debug Logical. Whether to print debugging information (default FALSE)
#' @return A plot object (ggplot2, plotly, or other depending on settings)
#' @import ggplot2
#' @import dplyr
#' @import tidyr
#' @import patchwork
#' @import plotly
#' @import viridis
#' @export
#' @examples
#' \donttest{
#' proj <- bids_project(system.file("extdata/ds001", package="bidser"))
#' plot_bids(proj)
#'
#' # Create a non-interactive plot with a different color scheme
#' plot_bids(proj, interactive = FALSE, color_scheme = "plasma")
#'
#' # Create a focused heatmap visualization
#' plot_bids(proj, visualization_mode = "heatmap")
#'
#' # Create a comprehensive visualization with all plot types
#' plot_bids(proj, visualization_mode = "complete")
#' 
#' # Or use the specialized heatmap function
#' bids_heatmap(proj)
#'
#' # Create a virtual project and visualize it
#' virtual_proj <- bids_structure(
#'   name = "my_project",
#'   subjects = c("01", "02", "03"),
#'   sessions = c("pre", "post"),
#'   tasks = c("rest", "task1", "task2"),
#'   runs = c(1, 2),
#'   include_fmriprep = TRUE
#' )
#' plot_bids(virtual_proj, highlight_missing = TRUE)
#' }
plot_bids <- function(x, interactive = TRUE, color_scheme = "viridis",
                      include_derivatives = TRUE, file_size_scale = "log",
                      highlight_missing = TRUE, visualization_mode = "standard",
                      debug = FALSE) {
  
  # Check input
  if (!inherits(x, "bids_project")) {
    stop("Input must be a bids_project object")
  }
  
  # Load required packages
  for (pkg in c("ggplot2", "dplyr", "viridis", "scales")) {
    if (!requireNamespace(pkg, quietly = TRUE)) {
      stop("Package ", pkg, " is required but not installed")
    }
  }
  if (interactive && !requireNamespace("plotly", quietly = TRUE)) {
    warning("Package plotly is required for interactive plots but not installed. Falling back to static plot.")
    interactive <- FALSE
  }
  
  # Validate mode
  valid_modes <- c("standard", "heatmap", "complete")
  if (!visualization_mode %in% valid_modes) {
    warning("Invalid visualization_mode. Using 'standard'.")
    visualization_mode <- "standard"
  }

  # Print debug info if requested
  if (debug) {
    cat("Project name:", x$name, "\n")
    cat("Project type:", paste(class(x), collapse=" "), "\n")
    if (!is.null(x$subjects)) cat("Number of subjects:", length(x$subjects), "\n")
    if (!is.null(x$tasks)) cat("Tasks:", paste(x$tasks, collapse=", "), "\n")
    cat("Has raw data table:", !is.null(x$tbl), "\n")
    if (!is.null(x$tbl)) cat("Raw data rows:", nrow(x$tbl), "\n")
    cat("Has sessions:", !is.null(x$sessions) && length(x$sessions) > 0, "\n")
  }
  
  # Check if the BIDS project has any data
  if (is.null(x$tbl) || nrow(x$tbl) == 0) {
    if (debug) cat("No data found in the BIDS project\n")
    # Create a minimal plot indicating no data
    p <- ggplot2::ggplot() + 
         ggplot2::annotate("text", x = 0.5, y = 0.5, 
                  label = "No data found in BIDS project") +
         ggplot2::theme_void() +
         ggplot2::theme(
           plot.background = ggplot2::element_rect(fill = "white"),
           plot.margin = ggplot2::margin(20, 20, 20, 20)
         )
    return(p)
  }
  
  # Try to safely extract project data
  project_data <- tryCatch({
    # Extract metadata from the BIDS project
    data <- prepare_bids_data_for_plot(x, include_derivatives)
    
    if (debug) {
      cat("Project data prepared successfully\n")
      cat("Raw data rows:", nrow(data$raw_data), "\n")
    }
    
    data
  }, error = function(e) {
    if (debug) cat("Error preparing project data:", e$message, "\n")
    NULL
  })
  
  # If data preparation failed, create a very simple plot from the raw data
  if (is.null(project_data)) {
    if (debug) cat("Using raw data directly for plotting\n")
    
    # Use the raw data table directly
    raw_data <- x$tbl
    
    # Create a very simple plot
    if (nrow(raw_data) > 0) {
      # Ensure we have subject ID and some kind of type
      if (!"subid" %in% names(raw_data)) {
        raw_data$subid <- "subject"
      }
      
      if (!"type" %in% names(raw_data) && "folder" %in% names(raw_data)) {
        raw_data$type <- raw_data$folder
      } else if (!"type" %in% names(raw_data)) {
        raw_data$type <- "data"
      }
      
      # Create a basic count plot
      p <- ggplot2::ggplot(raw_data, ggplot2::aes(x = subid, fill = type)) +
           ggplot2::geom_bar() +
           ggplot2::scale_fill_viridis_d(option = color_scheme) +
           ggplot2::labs(
             title = paste0("BIDS Dataset: ", x$name),
             subtitle = "Basic Overview (Limited Data)",
             x = "Subject",
             y = "File Count"
           ) +
           ggplot2::theme_minimal() +
           ggplot2::theme(
             axis.text.x = ggplot2::element_text(angle = 45, hjust = 1),
             plot.background = ggplot2::element_rect(fill = "white")
           )
      
      if (interactive) {
        tryCatch({
          p <- plotly::ggplotly(p)
        }, error = function(e) {
          if (debug) cat("Error making plot interactive:", e$message, "\n")
        })
      }
      
      return(p)
    } else {
      # No data at all
      p <- ggplot2::ggplot() + 
           ggplot2::annotate("text", x = 0.5, y = 0.5, 
                    label = "No data available in BIDS project") +
           ggplot2::theme_void() +
           ggplot2::theme(
             plot.background = ggplot2::element_rect(fill = "white"),
             plot.margin = ggplot2::margin(20, 20, 20, 20)
           )
      return(p)
    }
  }
  
  # Check if the data is too minimal to create complex plots
  if (nrow(project_data$raw_data) < 3) {
    if (debug) cat("Data is minimal, creating a simple fallback plot\n")
    
    # Create a simple fallback plot
    plot_data <- project_data$raw_data
    
    # Ensure required columns exist
    if (!"type" %in% names(plot_data)) {
      if ("folder" %in% names(plot_data)) {
        plot_data$type <- plot_data$folder
      } else {
        plot_data$type <- "data"
      }
    }
    
    if (!"subid" %in% names(plot_data)) {
      plot_data$subid <- "subject"
    }
    
    # If task column exists, add it to the labels
    if ("task" %in% names(plot_data)) {
      plot_data$label <- paste0(plot_data$type, "\n(", plot_data$task, ")")
    } else {
      plot_data$label <- plot_data$type
    }
    
    # If file_size doesn't exist, create it
    if (!"file_size" %in% names(plot_data)) {
      plot_data$file_size <- 1e6  # Default 1MB
    }
    
    # Create a visually distinct fallback plot
    p <- ggplot2::ggplot(plot_data, ggplot2::aes(x = subid, y = label, fill = file_size)) +
      ggplot2::geom_tile(color = "white") +
      ggplot2::scale_fill_viridis_c(option = color_scheme, name = "File Size", 
                           trans = "log10", labels = scales::label_bytes(units = "MB")) +
      ggplot2::geom_text(ggplot2::aes(label = scales::label_bytes(units = "MB")(file_size)), 
                          color = "white", size = 3.5) +
      ggplot2::labs(
        title = paste0("BIDS Dataset: ", x$name),
        subtitle = "Simple Overview (Limited Data)",
        x = "Subject",
        y = "Data Type"
      ) +
      ggplot2::theme_minimal() +
      ggplot2::theme(
        axis.text.x = ggplot2::element_text(angle = 45, hjust = 1),
        panel.grid = ggplot2::element_blank(),
        plot.background = ggplot2::element_rect(fill = "white")
      )
    
    if (interactive) {
      tryCatch({
        p <- plotly::ggplotly(p) %>%
          plotly::layout(hovermode = "closest")
      }, error = function(e) {
        if (debug) cat("Error making plot interactive:", e$message, "\n")
      })
    }
    
    return(p)
  }
  
  # Create plots based on the selected visualization mode
  if (visualization_mode == "heatmap") {
    # Create just the heatmap visualization
    tryCatch({
      p <- bids_heatmap(project_data, color_scheme, highlight_missing)
      
      if (interactive) {
        p <- plotly::ggplotly(p) %>%
          plotly::layout(hovermode = "closest")
      }
      
      return(p)
    }, error = function(e) {
      warning("Error creating heatmap visualization: ", e$message)
      # Return an empty plot with error message
      return(ggplot2::ggplot() + 
             ggplot2::annotate("text", x = 0, y = 0, 
                     label = paste("Error creating heatmap:", e$message)) +
             ggplot2::theme_void())
    })
  } else if (visualization_mode == "complete") {
    # Create a complete set of visualizations including the heatmap
    plots <- list()
    
    # Safely create each plot component
    tryCatch({
      # 1. Create the advanced heatmap
      plots$heatmap <- bids_heatmap(project_data, color_scheme, highlight_missing)
      if (debug) cat("Created heatmap plot\n")
      
      # 2. Create the data completeness heatmap
      plots$completeness <- plot_bids_completeness(project_data, color_scheme)
      if (debug) cat("Created completeness plot\n")
      
      # 3. Create file size distribution
      plots$file_sizes <- plot_bids_file_sizes(project_data, color_scheme, file_size_scale)
      if (debug) cat("Created file sizes plot\n")
      
      # 4. Create task distribution plot
      plots$tasks <- plot_bids_tasks(project_data, color_scheme)
      if (debug) cat("Created tasks plot\n")
      
      # 5. Create structure overview
      plots$structure <- plot_bids_structure(project_data, color_scheme)
      if (debug) cat("Created structure plot\n")
      
      # Check if any plot is NULL or missing
      missing_plots <- names(plots)[sapply(plots, is.null)]
      if (length(missing_plots) > 0) {
        warning("Some plots could not be created: ", paste(missing_plots, collapse=", "))
        # Replace any NULL plots with empty plots
        for (name in missing_plots) {
          plots[[name]] <- ggplot2::ggplot() + 
                          ggplot2::annotate("text", x = 0, y = 0, label = paste("No data for", name)) +
                          ggplot2::theme_void()
        }
      }
      
      # Combine plots using patchwork
      combined_plot <- (plots$heatmap) / 
                        (plots$completeness + plots$file_sizes) / 
                        (plots$tasks + plots$structure) +
                        patchwork::plot_annotation(
                          title = paste0("BIDS Dataset Overview: ", x$name),
                          subtitle = paste0(
                            length(participants(x)), " subjects, ", 
                            ifelse(!is.null(x$sessions) && length(x$sessions) > 0, 
                                  paste0(length(x$sessions), " sessions, "), ""),
                            length(tasks(x)), " tasks"),
                          tag_levels = "A"
                        ) +
                        patchwork::plot_layout(heights = c(1.5, 1, 1))
      
    }, error = function(e) {
      warning("Error creating complete visualization: ", e$message)
      # Return an empty plot with error message
      return(ggplot2::ggplot() + 
             ggplot2::annotate("text", x = 0, y = 0, 
                              label = paste("Error creating visualization:", e$message)) +
             ggplot2::theme_void())
    })
  } else {
    # Default "standard" mode
    plots <- list()
    
    # Safely create each plot component
    tryCatch({
      # 1. Create the data completeness heatmap
      plots$completeness <- plot_bids_completeness(project_data, color_scheme)
      if (debug) cat("Created completeness plot\n")
      
      # 2. Create file size distribution
      plots$file_sizes <- plot_bids_file_sizes(project_data, color_scheme, file_size_scale)
      if (debug) cat("Created file sizes plot\n")
      
      # 3. Create task distribution plot
      plots$tasks <- plot_bids_tasks(project_data, color_scheme)
      if (debug) cat("Created tasks plot\n")
      
      # 4. Create structure overview
      plots$structure <- plot_bids_structure(project_data, color_scheme)
      if (debug) cat("Created structure plot\n")
      
      # Check if any plot is NULL or missing
      missing_plots <- names(plots)[sapply(plots, is.null)]
      if (length(missing_plots) > 0) {
        warning("Some plots could not be created: ", paste(missing_plots, collapse=", "))
        # Replace any NULL plots with empty plots
        for (name in missing_plots) {
          plots[[name]] <- ggplot2::ggplot() + 
                          ggplot2::annotate("text", x = 0, y = 0, label = paste("No data for", name)) +
                          ggplot2::theme_void()
        }
      }
      
      # Combine plots using patchwork
      combined_plot <- (plots$completeness + plots$file_sizes) / 
                        (plots$tasks + plots$structure) +
                        patchwork::plot_annotation(
                          title = paste0("BIDS Dataset Overview: ", x$name),
                          subtitle = paste0(
                            length(participants(x)), " subjects, ", 
                            ifelse(!is.null(x$sessions) && length(x$sessions) > 0, 
                                  paste0(length(x$sessions), " sessions, "), ""),
                            length(tasks(x)), " tasks"),
                          tag_levels = "A"
                        )
    }, error = function(e) {
      warning("Error creating standard visualization: ", e$message)
      # Return an empty plot with error message
      return(ggplot2::ggplot() + 
             ggplot2::annotate("text", x = 0, y = 0, 
                              label = paste("Error creating visualization:", e$message)) +
             ggplot2::theme_void())
    })
  }
  
  # Convert to interactive if requested
  if (interactive) {
    tryCatch({
      p <- plotly::ggplotly(combined_plot)
      # Add custom hover information and interactivity features
      p <- plotly::layout(p, 
                 hovermode = "closest",
                 updatemenus = list(
                   list(
                     buttons = list(
                       list(method = "relayout",
                            args = list("showlegend", TRUE),
                            label = "Show Legend"),
                       list(method = "relayout",
                            args = list("showlegend", FALSE),
                            label = "Hide Legend")
                     ),
                     type = "buttons",
                     direction = "right",
                     xanchor = "center",
                     yanchor = "top",
                     x = 0.5,
                     y = 1.2
                   )
                 )
               )
      if (debug) cat("Converted to interactive plot successfully\n")
      return(p)
    }, error = function(e) {
      warning("Error converting to interactive plot: ", e$message, 
              ". Returning static plot instead.")
      return(combined_plot)
    })
  } else {
    return(combined_plot)
  }
}

#' Prepare BIDS data for visualization
#'
#' This internal function processes a bids_project object and extracts the necessary
#' data for visualization, including project info and formatted data.
#'
#' @param x A bids_project object
#' @param include_derivatives Logical. Whether to include derivatives data
#' @return A list containing project info and formatted data
#' @keywords internal
prepare_bids_data_for_plot <- function(x, include_derivatives = TRUE) {
  if (!inherits(x, "bids_project")) {
    stop("Input must be a bids_project object")
  }
  
  # Extract project information
  project_info <- list(
    name = x$name,
    root = x$root,
    subjects = x$subjects,
    sessions = x$sessions,
    tasks = x$tasks,
    runs = x$runs,
    is_virtual = isTRUE(x$is_virtual)
  )
  
  # Process the raw data table
  raw_data <- x$tbl
  
  # Check if file_size column exists, and add if not
  if (!"file_size" %in% names(raw_data)) {
    if (isTRUE(project_info$is_virtual)) {
      # For virtual projects, generate random file sizes
      raw_data$file_size <- runif(nrow(raw_data), min = 1e6, max = 100e6)
    } else {
      # For real projects, get file sizes when possible
      raw_data$file_size <- NA_real_
      
      if ("path" %in% names(raw_data)) {
        # Try to get file sizes for files that exist
        file_sizes <- vapply(
          raw_data$path, 
          function(p) {
            if (!is.na(p) && file.exists(p)) {
              return(file.info(p)$size)
            } else {
              return(NA_real_)
            }
          },
          FUN.VALUE = numeric(1)
        )
        raw_data$file_size <- file_sizes
      }
    }
  }
  
  # Filter out derivatives if not requested
  if (!include_derivatives) {
    if ("derivative" %in% names(raw_data)) {
      raw_data <- dplyr::filter(raw_data, !derivative)
    }
  }
  
  # Replace any NAs in the file_size with a reasonable default
  raw_data$file_size <- ifelse(is.na(raw_data$file_size), 1e6, raw_data$file_size)
  
  return(list(
    project_info = project_info,
    raw_data = raw_data
  ))
}

#' Plot BIDS data completeness
#'
#' Creates a heatmap showing data completeness across subjects and tasks.
#'
#' @param data Preprocessed BIDS data from prepare_bids_data_for_plot
#' @param color_scheme Color scheme to use
#' @return A ggplot object
#' @keywords internal
plot_bids_completeness <- function(data, color_scheme = "viridis") {
  # Extract data
  raw_data <- data$raw_data
  
  # Determine if we need to include sessions
  has_sessions <- !is.null(data$project_info$sessions) && length(data$project_info$sessions) > 0
  
  # Prepare data for completeness heatmap
  if (has_sessions) {
    # With sessions: subject x session x task
    if (length(data$project_info$tasks) > 0) {
      completeness_data <- raw_data %>%
        filter(!is.na(subid), !is.na(session), !is.na(task)) %>%
        group_by(subid, session, task) %>%
        summarize(
          has_data = n() > 0,
          file_count = n(),
          total_size = sum(file_size, na.rm = TRUE),
          .groups = "drop"
        )
      
      # Plot
      p <- ggplot(completeness_data, aes(x = subid, y = interaction(session, task), 
                                         fill = total_size)) +
        geom_tile(color = "white", size = 0.2) +
        scale_fill_viridis_c(option = color_scheme, name = "Data Size (bytes)", 
                             trans = "log10", na.value = "grey90") +
        labs(
          title = "Data Completeness by Subject, Session, and Task",
          x = "Subject ID",
          y = "Session × Task",
          fill = "Data Size"
        ) +
        theme_minimal() +
        theme(
          axis.text.x = element_text(angle = 45, hjust = 1),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank()
        )
    } else {
      # With sessions but no tasks: subject x session x type
      completeness_data <- raw_data %>%
        filter(!is.na(subid), !is.na(session), !is.na(type)) %>%
        group_by(subid, session, type) %>%
        summarize(
          has_data = n() > 0,
          file_count = n(),
          total_size = sum(file_size, na.rm = TRUE),
          .groups = "drop"
        )
      
      # Plot
      p <- ggplot(completeness_data, aes(x = subid, y = interaction(session, type),
                                         fill = total_size)) +
        geom_tile(color = "white", size = 0.2) +
        scale_fill_viridis_c(option = color_scheme, name = "Data Size (bytes)",
                             trans = "log10", na.value = "grey90") +
        labs(
          title = "Data Completeness by Subject, Session, and Type",
          x = "Subject ID",
          y = "Session × Type",
          fill = "Data Size"
        ) +
        theme_minimal() +
        theme(
          axis.text.x = element_text(angle = 45, hjust = 1),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank()
        )
    }
  } else {
    # No sessions: subject x task/type
    if (length(data$project_info$tasks) > 0) {
      completeness_data <- raw_data %>%
        filter(!is.na(subid), !is.na(task)) %>%
        group_by(subid, task) %>%
        summarize(
          has_data = n() > 0,
          file_count = n(),
          total_size = sum(file_size, na.rm = TRUE),
          .groups = "drop"
        )
      
      # Plot
      p <- ggplot(completeness_data, aes(x = subid, y = task, fill = total_size)) +
        geom_tile(color = "white", size = 0.2) +
        scale_fill_viridis_c(option = color_scheme, name = "Data Size (bytes)",
                             trans = "log10", na.value = "grey90") +
        labs(
          title = "Data Completeness by Subject and Task",
          x = "Subject ID",
          y = "Task",
          fill = "Data Size"
        ) +
        theme_minimal() +
        theme(
          axis.text.x = element_text(angle = 45, hjust = 1),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank()
        )
    } else {
      # No sessions and no tasks: subject x type
      completeness_data <- raw_data %>%
        filter(!is.na(subid), !is.na(type)) %>%
        group_by(subid, type) %>%
        summarize(
          has_data = n() > 0,
          file_count = n(),
          total_size = sum(file_size, na.rm = TRUE),
          .groups = "drop"
        )
      
      # Plot
      p <- ggplot(completeness_data, aes(x = subid, y = type, fill = total_size)) +
        geom_tile(color = "white", size = 0.2) +
        scale_fill_viridis_c(option = color_scheme, name = "Data Size (bytes)",
                             trans = "log10", na.value = "grey90") +
        labs(
          title = "Data Completeness by Subject and Type",
          x = "Subject ID",
          y = "Data Type",
          fill = "Data Size"
        ) +
        theme_minimal() +
        theme(
          axis.text.x = element_text(angle = 45, hjust = 1),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank()
        )
    }
  }
  
  return(p)
}

#' Plot BIDS file size distribution
#'
#' Creates a plot showing the distribution of file sizes across types.
#'
#' @param data Preprocessed BIDS data from prepare_bids_data_for_plot
#' @param color_scheme Color scheme to use
#' @param scale Scale to use for file sizes ("log", "sqrt", or "linear")
#' @return A ggplot object
#' @keywords internal
plot_bids_file_sizes <- function(data, color_scheme = "viridis", scale = "log") {
  # Extract data
  raw_data <- data$raw_data
  
  # Create a boxplot of file sizes by type
  p <- ggplot(raw_data, aes(x = type, y = file_size, fill = type)) +
    geom_boxplot(alpha = 0.8, outlier.shape = 21, outlier.size = 1.5) +
    scale_fill_viridis_d(option = color_scheme) +
    labs(
      title = "File Size Distribution by Type",
      x = "Data Type",
      y = "File Size (bytes)"
    ) +
    theme_minimal() +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1),
      legend.position = "none"
    )
  
  # Apply scale transformation
  if (scale == "log") {
    p <- p + scale_y_log10()
  } else if (scale == "sqrt") {
    p <- p + scale_y_sqrt()
  }
  
  return(p)
}

#' Plot BIDS task distribution
#'
#' Creates a plot showing the distribution of tasks across subjects.
#'
#' @param data Preprocessed BIDS data from prepare_bids_data_for_plot
#' @param color_scheme Color scheme to use
#' @return A ggplot object
#' @keywords internal
plot_bids_tasks <- function(data, color_scheme = "viridis") {
  # Extract data
  raw_data <- data$raw_data
  
  # Check if we have tasks
  if (length(data$project_info$tasks) == 0 || 
      !("task" %in% names(raw_data)) || 
      all(is.na(raw_data$task))) {
    # No tasks, create a plot showing data types instead
    # Check if type_summary exists, if not, create it
    if (is.null(data$type_summary)) {
      # Create type summary from raw data
      type_summary <- raw_data %>%
        dplyr::filter(!is.na(type)) %>%
        dplyr::group_by(type) %>%
        dplyr::summarize(total_files = dplyr::n(), .groups = "drop")
    } else {
      type_summary <- data$type_summary
    }
    
    # If there are no valid types, create a placeholder plot
    if (nrow(type_summary) == 0) {
      p <- ggplot2::ggplot() + 
           ggplot2::annotate("text", x = 0.5, y = 0.5, label = "No task or type data available") +
           ggplot2::theme_void() +
           ggplot2::theme(plot.background = ggplot2::element_rect(fill = "white"))
      return(p)
    }
    
    p <- ggplot2::ggplot(type_summary, ggplot2::aes(x = reorder(type, total_files), y = total_files, fill = type)) +
      ggplot2::geom_bar(stat = "identity") +
      ggplot2::scale_fill_viridis_d(option = color_scheme) +
      ggplot2::labs(
        title = "File Count by Data Type",
        x = "Data Type",
        y = "Number of Files"
      ) +
      ggplot2::theme_minimal() +
      ggplot2::theme(
        axis.text.x = ggplot2::element_text(angle = 45, hjust = 1),
        legend.position = "none"
      )
  } else {
    # With tasks, create a count plot of runs by task
    # Check if run column exists
    if (!"run" %in% names(raw_data)) {
      # Create a simplified plot without run information
      task_summary <- raw_data %>%
        dplyr::filter(!is.na(task)) %>%
        dplyr::group_by(subid, task) %>%
        dplyr::summarize(count = dplyr::n(), .groups = "drop")
      
      p <- ggplot2::ggplot(task_summary, ggplot2::aes(x = task, y = count, fill = task)) +
        ggplot2::geom_boxplot(alpha = 0.8) +
        ggplot2::geom_jitter(alpha = 0.5, width = 0.2, height = 0) +
        ggplot2::scale_fill_viridis_d(option = color_scheme) +
        ggplot2::labs(
          title = "File Count by Task",
          x = "Task",
          y = "Number of Files"
        ) +
        ggplot2::theme_minimal() +
        ggplot2::theme(
          axis.text.x = ggplot2::element_text(angle = 45, hjust = 1),
          legend.position = "none"
        )
    } else {
      task_summary <- raw_data %>%
        dplyr::filter(!is.na(task)) %>%
        dplyr::group_by(subid, task) %>%
        dplyr::summarize(runs = dplyr::n_distinct(run), .groups = "drop")
      
      p <- ggplot2::ggplot(task_summary, ggplot2::aes(x = task, y = runs, fill = task)) +
        ggplot2::geom_boxplot(alpha = 0.8) +
        ggplot2::geom_jitter(alpha = 0.5, width = 0.2, height = 0) +
        ggplot2::scale_fill_viridis_d(option = color_scheme) +
        ggplot2::labs(
          title = "Run Distribution by Task",
          x = "Task",
          y = "Number of Runs"
        ) +
        ggplot2::theme_minimal() +
        ggplot2::theme(
          axis.text.x = ggplot2::element_text(angle = 45, hjust = 1),
          legend.position = "none"
        )
    }
  }
  
  return(p)
}

#' Plot BIDS structure overview
#'
#' Creates a hierarchical visualization of the BIDS structure.
#'
#' @param data Preprocessed BIDS data from prepare_bids_data_for_plot
#' @param color_scheme Color scheme to use
#' @return A ggplot object
#' @keywords internal
#' @noRd
plot_bids_structure <- function(data, color_scheme = "viridis") {
  # Extract data
  raw_data <- data$raw_data
  
  # Create a tree-like structure representation
  # This is a simplified version that shows the proportion of different data types
  
  # Count files by type and subject
  structure_data <- raw_data %>%
    filter(!is.na(type)) %>%
    group_by(subid, type) %>%
    summarize(count = n(), .groups = "drop") %>%
    group_by(subid) %>%
    mutate(proportion = count / sum(count)) %>%
    ungroup()
  
  # Order subjects by total file count
  subject_order <- raw_data %>%
    group_by(subid) %>%
    summarize(total = n(), .groups = "drop") %>%
    arrange(desc(total)) %>%
    pull(subid)
  
  structure_data$subid <- factor(structure_data$subid, levels = subject_order)
  
  # Create the plot
  p <- ggplot(structure_data, aes(x = subid, y = proportion, fill = type)) +
    geom_bar(stat = "identity", position = "stack") +
    scale_fill_viridis_d(option = color_scheme, name = "Data Type") +
    labs(
      title = "Proportion of Data Types by Subject",
      x = "Subject ID",
      y = "Proportion of Files"
    ) +
    theme_minimal() +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1)
    )
  
  return(p)
}

#' Create a specialized heatmap visualization of BIDS data
#'
#' This function creates a heatmap visualization of a BIDS project, where the x-axis represents
#' subjects and the y-axis represents tasks by run. Each cell in the heatmap is colored by
#' file size, providing an intuitive view of data completeness and size distribution across
#' the project. This is particularly useful for quality control and identifying missing data.
#'
#' @param x A \code{bids_project} object
#' @param interactive Logical. Whether to create an interactive plot (default TRUE)
#' @param color_scheme Character. Name of the color palette to use (default "viridis")
#' @param file_type Character. Type of files to visualize (default "func")
#' @param highlight_missing Logical. Whether to highlight missing data points (default TRUE)
#' @param text_size Numeric. Size of text labels (default 2.5)
#' @param rotate_labels Logical. Whether to rotate the axis labels (default TRUE)
#' @return A plot object (ggplot2 or plotly depending on interactive parameter)
#' @examples
#' \donttest{
#' # Create a basic interactive heatmap for a BIDS dataset
#' proj <- bids_project(system.file("extdata/ds001", package="bidser"))
#' bids_heatmap(proj)
#'
#' # Create a static heatmap with custom settings
#' bids_heatmap(proj, 
#'              interactive = FALSE,
#'              color_scheme = "plasma",
#'              text_size = 3,
#'              rotate_labels = FALSE)
#'
#' # Visualize anatomical data with missing data highlighted
#' bids_heatmap(proj, 
#'              file_type = "anat",
#'              highlight_missing = TRUE,
#'              color_scheme = "magma")
#'
#' # Create a compact visualization for a large dataset
#' ds007 <- bids_project(system.file("extdata/ds007", package="bidser"))
#' bids_heatmap(ds007, 
#'              text_size = 2,
#'              rotate_labels = TRUE,
#'              highlight_missing = FALSE)
#' }
#' @export
bids_heatmap <- function(x, interactive=TRUE, color_scheme="viridis", file_type="func",
                        highlight_missing=TRUE, text_size=2.5, rotate_labels=TRUE) {
  
  # Check input
  if (!inherits(x, "bids_project")) {
    stop("Input must be a bids_project object")
  }
  
  # Prepare data
  project_data <- prepare_bids_data_for_plot(x, include_derivatives = TRUE)
  raw_data <- project_data$raw_data
  
  # Filter by file type
  if (!file_type %in% unique(raw_data$type)) {
    stop(paste0("File type '", file_type, "' not found in dataset. Available types: ", 
                paste(unique(raw_data$type), collapse = ", ")))
  }
  
  filtered_data <- raw_data %>% 
    dplyr::filter(type == file_type)
  
  # Determine if we have sessions
  has_sessions <- !is.null(project_data$project_info$sessions) && 
                 length(project_data$project_info$sessions) > 0
  
  # Create different visualizations based on file type
  if (file_type == "func") {
    # For functional data, use task and run
    if (!all(c("task", "run") %in% names(filtered_data))) {
      warning("Task or run information missing for functional data. Creating simplified heatmap.")
      # Fall back to a simpler visualization
      return(plot_bids_heatmap(project_data, color_scheme, highlight_missing))
    }
    
    # Create a task-run combination for y-axis
    if (has_sessions) {
      # With sessions
      heatmap_data <- filtered_data %>%
        dplyr::filter(!is.na(subid), !is.na(task), !is.na(run)) %>%
        dplyr::group_by(subid, session, task, run) %>%
        dplyr::summarize(
          file_size = sum(file_size, na.rm = TRUE),
          file_count = dplyr::n(),
          .groups = "drop"
        ) %>%
        # Create a combined task-run label for the y-axis
        dplyr::mutate(task_run = paste0(task, "-run", run))
      
      # Create a complete grid to detect missing data
      if (highlight_missing) {
        all_subj <- unique(heatmap_data$subid)
        all_sess <- unique(heatmap_data$session)
        all_task_runs <- unique(heatmap_data$task_run)
        
        expected_grid <- expand.grid(
          subid = all_subj,
          session = all_sess,
          task_run = all_task_runs,
          stringsAsFactors = FALSE
        )
        
        # Merge to find missing combinations
        heatmap_data <- dplyr::left_join(expected_grid, heatmap_data, 
                                by = c("subid", "session", "task_run")) %>%
          dplyr::mutate(
            file_size = ifelse(is.na(file_size), 0, file_size),
            file_count = ifelse(is.na(file_count), 0, file_count),
            missing = file_count == 0
          )
      }
      
      # Create the plot - THIS IS THE MAIN VISUALIZATION
      # x-axis: subject, y-axis: task/run, facet by session, color by file size
      p <- ggplot2::ggplot(heatmap_data, ggplot2::aes(x = subid, y = task_run, fill = file_size)) +
        ggplot2::geom_tile(color = "white", size = 0.2, 
                 ggplot2::aes(alpha = ifelse(file_size == 0, 0.3, 1))) +
        ggplot2::scale_fill_viridis_c(option = color_scheme, name = "File Size",
                            trans = "log10", na.value = "grey90",
                            labels = scales::label_bytes(units = "MB")) +
        ggplot2::scale_alpha_identity() +
        ggplot2::facet_wrap(~ session, scales = "free_x", ncol = 1) +
        ggplot2::labs(
          title = paste0("BIDS Functional Data: ", x$name),
          subtitle = "Subject × Task-Run Heatmap",
          x = "Subject ID",
          y = "Task and Run"
        )
      
      # Add file size labels
      if (text_size > 0) {
        p <- p + ggplot2::geom_text(
          ggplot2::aes(label = ifelse(file_size > 0, 
                            paste0(round(file_size / 1e6, 1), "MB"), 
                            "")),
          size = text_size, color = "white"
        )
      }
    } else {
      # No sessions
      heatmap_data <- filtered_data %>%
        dplyr::filter(!is.na(subid), !is.na(task), !is.na(run)) %>%
        dplyr::group_by(subid, task, run) %>%
        dplyr::summarize(
          file_size = sum(file_size, na.rm = TRUE),
          file_count = dplyr::n(),
          .groups = "drop"
        ) %>%
        # Create a combined task-run label for the y-axis
        dplyr::mutate(task_run = paste0(task, "-run", run))
      
      # Create a complete grid to detect missing data
      if (highlight_missing) {
        all_subj <- unique(heatmap_data$subid)
        all_task_runs <- unique(heatmap_data$task_run)
        
        expected_grid <- expand.grid(
          subid = all_subj,
          task_run = all_task_runs,
          stringsAsFactors = FALSE
        )
        
        # Merge to find missing combinations
        heatmap_data <- dplyr::left_join(expected_grid, heatmap_data, by = c("subid", "task_run")) %>%
          dplyr::mutate(
            file_size = ifelse(is.na(file_size), 0, file_size),
            file_count = ifelse(is.na(file_count), 0, file_count),
            missing = file_count == 0
          )
      }
      
      # Create the plot - THIS IS THE MAIN VISUALIZATION
      # x-axis: subject, y-axis: task/run, color by file size
      p <- ggplot2::ggplot(heatmap_data, ggplot2::aes(x = subid, y = task_run, fill = file_size)) +
        ggplot2::geom_tile(color = "white", size = 0.2, 
                 ggplot2::aes(alpha = ifelse(file_size == 0, 0.3, 1))) +
        ggplot2::scale_fill_viridis_c(option = color_scheme, name = "File Size",
                            trans = "log10", na.value = "grey90",
                            labels = scales::label_bytes(units = "MB")) +
        ggplot2::scale_alpha_identity() +
        ggplot2::labs(
          title = paste0("BIDS Functional Data: ", x$name),
          subtitle = "Subject × Task-Run Heatmap",
          x = "Subject ID",
          y = "Task and Run"
        )
      
      # Add file size labels
      if (text_size > 0) {
        p <- p + ggplot2::geom_text(
          ggplot2::aes(label = ifelse(file_size > 0, 
                            paste0(round(file_size / 1e6, 1), "MB"), 
                            "")),
          size = text_size, color = "white"
        )
      }
    }
  } else if (file_type == "anat") {
    # For anatomical data, use anatomical modality (T1w, T2w, etc.)
    # x-axis: subject, y-axis: anatomical type, color by file size
    
    # Check if 'kind' column exists, if not use 'modality' or create a default
    if (!"kind" %in% names(filtered_data)) {
      if ("modality" %in% names(filtered_data)) {
        filtered_data$kind <- filtered_data$modality
      } else {
        filtered_data$kind <- "anatomical"
      }
    }
    
    if (has_sessions) {
      # With sessions
      heatmap_data <- filtered_data %>%
        dplyr::filter(!is.na(subid)) %>%
        dplyr::group_by(subid, session, kind) %>%
        dplyr::summarize(
          file_size = sum(file_size, na.rm = TRUE),
          file_count = dplyr::n(),
          .groups = "drop"
        )
      
      # Create a complete grid for missing data
      if (highlight_missing) {
        all_subj <- unique(heatmap_data$subid)
        all_sess <- unique(heatmap_data$session)
        all_kinds <- unique(heatmap_data$kind)
        
        expected_grid <- expand.grid(
          subid = all_subj,
          session = all_sess,
          kind = all_kinds,
          stringsAsFactors = FALSE
        )
        
        # Merge to find missing combinations
        heatmap_data <- dplyr::left_join(expected_grid, heatmap_data, 
                                by = c("subid", "session", "kind")) %>%
          dplyr::mutate(
            file_size = ifelse(is.na(file_size), 0, file_size),
            file_count = ifelse(is.na(file_count), 0, file_count),
            missing = file_count == 0
          )
      }
      
      # Create the plot
      p <- ggplot2::ggplot(heatmap_data, ggplot2::aes(x = subid, y = kind, fill = file_size)) +
        ggplot2::geom_tile(color = "white", size = 0.2, 
                 ggplot2::aes(alpha = ifelse(file_size == 0, 0.3, 1))) +
        ggplot2::scale_fill_viridis_c(option = color_scheme, name = "File Size",
                            trans = "log10", na.value = "grey90",
                            labels = scales::label_bytes(units = "MB")) +
        ggplot2::scale_alpha_identity() +
        ggplot2::facet_wrap(~ session, scales = "free_x", ncol = 1) +
        ggplot2::labs(
          title = paste0("BIDS Anatomical Data: ", x$name),
          subtitle = "Subject × Image Type Heatmap",
          x = "Subject ID",
          y = "Anatomical Type"
        )
      
      # Add file size labels
      if (text_size > 0) {
        p <- p + ggplot2::geom_text(
          ggplot2::aes(label = ifelse(file_size > 0, 
                            paste0(round(file_size / 1e6, 1), "MB"), 
                            "")),
          size = text_size, color = "white"
        )
      }
    } else {
      # No sessions
      heatmap_data <- filtered_data %>%
        dplyr::filter(!is.na(subid)) %>%
        dplyr::group_by(subid, kind) %>%
        dplyr::summarize(
          file_size = sum(file_size, na.rm = TRUE),
          file_count = dplyr::n(),
          .groups = "drop"
        )
      
      # Create a complete grid for missing data
      if (highlight_missing) {
        all_subj <- unique(heatmap_data$subid)
        all_kinds <- unique(heatmap_data$kind)
        
        expected_grid <- expand.grid(
          subid = all_subj,
          kind = all_kinds,
          stringsAsFactors = FALSE
        )
        
        # Merge to find missing combinations
        heatmap_data <- dplyr::left_join(expected_grid, heatmap_data, 
                                by = c("subid", "kind")) %>%
          dplyr::mutate(
            file_size = ifelse(is.na(file_size), 0, file_size),
            file_count = ifelse(is.na(file_count), 0, file_count),
            missing = file_count == 0
          )
      }
      
      # Create the plot
      p <- ggplot2::ggplot(heatmap_data, ggplot2::aes(x = subid, y = kind, fill = file_size)) +
        ggplot2::geom_tile(color = "white", size = 0.2, 
                 ggplot2::aes(alpha = ifelse(file_size == 0, 0.3, 1))) +
        ggplot2::scale_fill_viridis_c(option = color_scheme, name = "File Size",
                            trans = "log10", na.value = "grey90",
                            labels = scales::label_bytes(units = "MB")) +
        ggplot2::scale_alpha_identity() +
        ggplot2::labs(
          title = paste0("BIDS Anatomical Data: ", x$name),
          subtitle = "Subject × Image Type Heatmap",
          x = "Subject ID",
          y = "Anatomical Type"
        )
      
      # Add file size labels
      if (text_size > 0) {
        p <- p + ggplot2::geom_text(
          ggplot2::aes(label = ifelse(file_size > 0, 
                            paste0(round(file_size / 1e6, 1), "MB"), 
                            "")),
          size = text_size, color = "white"
        )
      }
    }
  } else {
    # For other file types, just use the file type as the y-axis
    heatmap_data <- filtered_data %>%
      dplyr::filter(!is.na(subid)) %>%
      dplyr::group_by(subid) %>%
      dplyr::summarize(
        file_size = sum(file_size, na.rm = TRUE),
        file_count = dplyr::n(),
        .groups = "drop"
      )
    
    # Create the plot
    p <- ggplot2::ggplot(heatmap_data, ggplot2::aes(x = subid, y = 1, fill = file_size)) +
      ggplot2::geom_tile(color = "white", size = 0.2) +
      ggplot2::scale_fill_viridis_c(option = color_scheme, name = "File Size",
                          trans = "log10", na.value = "grey90",
                          labels = scales::label_bytes(units = "MB")) +
      ggplot2::labs(
        title = paste0("BIDS ", file_type, " Data: ", x$name),
        subtitle = "Subject Heatmap",
        x = "Subject ID",
        y = ""
      ) +
      ggplot2::scale_y_continuous(breaks = NULL)
    
    # Add file size labels
    if (text_size > 0) {
      p <- p + ggplot2::geom_text(
        ggplot2::aes(label = paste0(round(file_size / 1e6, 1), "MB")),
        size = text_size, color = "white"
      )
    }
  }
  
  # Apply common theme settings
  p <- p + ggplot2::theme_minimal() +
    ggplot2::theme(
      axis.text.x = ggplot2::element_text(angle = if(rotate_labels) 45 else 0, hjust = 1),
      panel.grid.major = ggplot2::element_blank(),
      panel.grid.minor = ggplot2::element_blank(),
      legend.position = "right"
    )
  
  # Convert to interactive if requested
  if (interactive) {
    p <- plotly::ggplotly(p) %>%
      plotly::layout(
        hovermode = "closest",
        hoverlabel = list(bgcolor = "white"),
        title = list(
          text = paste0("BIDS ", file_type, " Data: ", x$name,
                       "<br><sup>Subject × ", 
                       if(file_type == "func") "Task-Run" else "Image Type", 
                       " Heatmap</sup>")
        )
      )
  }
  
  return(p)
}

#' Plot BIDS data as a heatmap
#'
#' @param data Preprocessed BIDS data from prepare_bids_data_for_plot
#' @param color_scheme Color scheme to use
#' @param highlight_missing Whether to highlight missing data
#' @return A ggplot object
#' @keywords internal
plot_bids_heatmap <- function(data, color_scheme = "viridis", highlight_missing = TRUE) {
  # Implementation details...
}

#' Test the bids_heatmap visualization with example data
#'
#' This function creates a virtual BIDS project and generates a heatmap visualization
#' using the bids_heatmap function. It is useful for demonstration and testing purposes.
#'
#' @return A plotly or ggplot object
#' @keywords internal
#' @noRd
test_bids_heatmap <- function() {
  # First try to use a real dataset if it exists
  example_path <- system.file("extdata/ds001", package = "bidser")
  
  if (dir.exists(example_path) && length(list.files(example_path)) > 0) {
    message("Using real dataset from package: ", example_path)
    x <- bidser::bids_project(example_path)
  } else {
    message("Real dataset not found, creating virtual project")
    x <- create_virtual_bids_project(
      name = "Test Project",
      subjects = paste0("sub-", sprintf("%02d", 1:10)),
      sessions = c("ses-01", "ses-02"),
      tasks = c("rest", "task1", "task2"),
      runs = c("01", "02"),
      modalities = c("T1w", "T2w", "bold"),
      derivatives = TRUE
    )
  }
  
  # Return heatmap visualization
  bids_heatmap(x, interactive = TRUE, file_type = "func")
}

#' Create a virtual BIDS project for testing
#'
#' This function creates a virtual BIDS project structure for testing purposes.
#' It simulates a project with specified subjects, sessions, tasks, runs, and modalities.
#'
#' @param name Character. Name of the project
#' @param subjects Character vector. Subject IDs (e.g., "sub-01")
#' @param sessions Character vector. Session IDs (e.g., "ses-01") 
#' @param tasks Character vector. Task names (e.g., "rest")
#' @param runs Character vector. Run numbers (e.g., "01")
#' @param modalities Character vector. Imaging modalities (e.g., "T1w", "bold")
#' @param derivatives Logical. Whether to include derivative files
#' @return A bids_project object
#' @keywords internal
#' @noRd
create_virtual_bids_project <- function(name = "Virtual Project",
                                        subjects = paste0("sub-", sprintf("%02d", 1:5)),
                                        sessions = NULL,
                                        tasks = c("rest"),
                                        runs = c("01"),
                                        modalities = c("T1w", "bold"),
                                        derivatives = FALSE) {
  
  # Create an empty structure
  structure <- bidser::bids_structure()
  
  # Function to randomly skip some files to create an incomplete dataset
  should_include <- function() {
    # 80% chance of including a file
    runif(1) < 0.8
  }
  
  # Add anatomical files
  for (sub in subjects) {
    if (!is.null(sessions) && length(sessions) > 0) {
      for (ses in sessions) {
        for (mod in modalities) {
          if (mod %in% c("T1w", "T2w") && should_include()) {
            file_path <- file.path(sub, ses, "anat", 
                                  paste0(sub, "_", ses, "_", mod, ".nii.gz"))
            structure <- structure$add_node(file_path)
          }
        }
      }
    } else {
      for (mod in modalities) {
        if (mod %in% c("T1w", "T2w") && should_include()) {
          file_path <- file.path(sub, "anat", 
                                paste0(sub, "_", mod, ".nii.gz"))
          structure <- structure$add_node(file_path)
        }
      }
    }
  }
  
  # Add functional files
  for (sub in subjects) {
    if (!is.null(sessions) && length(sessions) > 0) {
      for (ses in sessions) {
        for (task in tasks) {
          for (run in runs) {
            if ("bold" %in% modalities && should_include()) {
              file_path <- file.path(sub, ses, "func", 
                                    paste0(sub, "_", ses, "_task-", task, 
                                          "_run-", run, "_bold.nii.gz"))
              structure <- structure$add_node(file_path)
            }
          }
        }
      }
    } else {
      for (task in tasks) {
        for (run in runs) {
          if ("bold" %in% modalities && should_include()) {
            file_path <- file.path(sub, "func", 
                                  paste0(sub, "_task-", task, 
                                        "_run-", run, "_bold.nii.gz"))
            structure <- structure$add_node(file_path)
          }
        }
      }
    }
  }
  
  # Construct the project object
  project <- list(
    name = name,
    root = paste0("/virtual/", name),
    structure = structure,
    is_virtual = TRUE
  )
  
  # Add derivatives if requested
  if (derivatives) {
    derivatives_structure <- bidser::bids_structure()
    
    for (sub in subjects) {
      if (!is.null(sessions) && length(sessions) > 0) {
        for (ses in sessions) {
          for (task in tasks) {
            for (run in runs) {
              if (should_include()) {
                file_path <- file.path("derivatives", "fmriprep", sub, ses, "func", 
                                      paste0(sub, "_", ses, "_task-", task, 
                                            "_run-", run, "_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz"))
                derivatives_structure <- derivatives_structure$add_node(file_path)
              }
            }
          }
        }
      } else {
        for (task in tasks) {
          for (run in runs) {
            if (should_include()) {
              file_path <- file.path("derivatives", "fmriprep", sub, "func", 
                                    paste0(sub, "_task-", task, 
                                          "_run-", run, "_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz"))
              derivatives_structure <- derivatives_structure$add_node(file_path)
            }
          }
        }
      }
    }
    
    project$derivatives <- derivatives_structure
  }
  
  # Add class and generate raw data table with random file sizes
  class(project) <- "bids_project"
  
  # Get the raw data table
  raw_data <- bidser::raw_data(project)
  
  # Add simulated file sizes (in bytes) for testing visualization
  raw_data <- raw_data %>%
    dplyr::mutate(file_size = round(runif(dplyr::n(), 1e6, 50e6)))
  
  # Store the raw data with file sizes
  project$raw_data <- raw_data
  
  return(project)
}
</file>

<file path="tests/testthat/test_events.R">
context("events")
library(testthat)
library(bidser)

test_that("can extract event files from bids project", {
  proj <- bids_project(system.file("extdata/ds001", package="bidser"), fmriprep=FALSE)
  evfiles <- event_files(proj)
  testthat::expect_true(!is.null(evfiles))
  testthat::expect_equal(length(evfiles), 48)
})

test_that("can search for event files from bids project", {
  proj <- bids_project(system.file("extdata/ds001", package="bidser"), fmriprep=FALSE)
  evfiles <- search_files(proj, regex=".*events.tsv$")
  testthat::expect_true(!is.null(evfiles))
  testthat::expect_equal(length(evfiles), 48)
})


test_that("can read in event files from bids project", {
  proj <- bids_project(system.file("extdata/ds001", package="bidser"), fmriprep=FALSE)
  ev <- read_events(proj)
  testthat::expect_equal(nrow(ev), 48)
})

test_that("can read in event files from a  single subject", {
  proj <- bids_project(system.file("extdata/ds001", package="bidser"), fmriprep=FALSE)
  ev <- read_events(proj, subid="01")
  testthat::expect_equal(nrow(ev), 3)
})
</file>

<file path="tests/testthat/test_func_scans.R">
context("func_scans")
library(testthat)
library(bidser)

test_that("can extract functional files from bids project", {
  proj <- bids_project(system.file("extdata/ds001", package="bidser"), fmriprep=FALSE)
  fscans <- func_scans(proj)
  expect_equal(length(fscans), 48)
})

test_that("can extract functional files for one subject from bids project", {
  proj <- bids_project(system.file("extdata/ds001", package="bidser"), fmriprep=FALSE)
  fscans <- func_scans(proj, subid="01")
  expect_equal(length(fscans), 3)
})

test_that("attempt to find func_scan with non-existent id should return NULL", {
  proj <- bids_project(system.file("extdata/ds001", package="bidser"), fmriprep=FALSE)
  fscans <- func_scans(proj, subid="junk")
  expect_null(fscans)
})
</file>

<file path="tests/testthat/test_mock_bids.R">
# tests/testthat/test_mock_bids.R

library(testthat)
library(tibble)
# Ensure bidser is loaded, or use bidser:: where needed if testing externally
# library(bidser) 

context("Mock BIDS Project Functionality")

# --- Test Data Setup ---
participants_df <- tibble::tibble(participant_id = c("01", "02"), age = c(25, 30))

# Define file structure more carefully, including 'kind' if used by encode/search
# Ensure attributes match what bidser::encode would produce
file_structure_df <- tibble::tribble(
  ~subid, ~session, ~datatype, ~task,   ~run, ~suffix,      ~fmriprep, ~desc,     ~space, # Suffix is BIDS suffix only now
  "01",   NA,       "anat",    NA,      NA,   "T1w",        FALSE,     NA,        NA,        
  "01",   NA,       "func",    "taskA", "01", "bold",       FALSE,     NA,        NA,        
  "01",   NA,       "func",    "taskA", "01", "events",     FALSE,     NA,        NA,        
  "02",   "test",   "anat",    NA,      NA,   "T1w",        FALSE,     NA,        NA,        
  "02",   "test",   "func",    "taskA", "01", "bold",       FALSE,     NA,        NA,        
  "02",   "test",   "func",    "taskA", "01", "events",     FALSE,     NA,        NA,        
  # Derivatives 
  "01",   NA,       "anat",    NA,      NA,   "T1w",        TRUE,      "preproc", "MNI",  
  "01",   NA,       "func",    "taskA", "01", "bold",       TRUE,      "preproc", "MNI"
)

# Define event data (paths must match generated structure)
# Use hardcoded paths based on what generate_bids_filename would likely produce
# Note: suffix in generate_bids_filename needs the extension!
event_filename_1 <- generate_bids_filename(subid = "01", task = "taskA", run = "01", suffix = "events.tsv")
event_filename_2 <- generate_bids_filename(subid = "02", session = "test", task = "taskA", run = "01", suffix = "events.tsv")
event_path_1 <- file.path("sub-01", "func", event_filename_1)
event_path_2 <- file.path("sub-02", "ses-test", "func", event_filename_2)

event_data_list <- list()
event_data_list[[event_path_1]] <- tibble::tibble(
  onset = c(1.0, 5.0), duration = c(0.5, 0.5), trial_type = c("condA", "condB")
)
event_data_list[[event_path_2]] <- tibble::tibble(
  onset = c(1.5, 5.5), duration = c(0.5, 0.5), trial_type = c("condC", "condD")
)

# Construct expected derivative filenames/patterns
# Filename generation helper needs extension in suffix arg
deriv_anat_filename <- generate_bids_filename(subid = "01", suffix = "T1w.nii.gz", space="MNI", desc="preproc")
deriv_func_filename <- generate_bids_filename(subid = "01", task = "taskA", run = "01", suffix = "bold.nii.gz", space="MNI", desc="preproc")

deriv_anat_relpath <- file.path("derivatives", "mockprep", "sub-01", "anat", deriv_anat_filename)
deriv_func_relpath <- file.path("derivatives", "mockprep", "sub-01", "func", deriv_func_filename)

# --- Test Creation ---
test_that("Mock BIDS project can be created", {
  # Need to add .nii.gz back to suffix in file_structure for filename generation
  fs_for_create <- file_structure_df %>%
    mutate(suffix_ext = case_when(
      suffix == "T1w" ~ "T1w.nii.gz",
      suffix == "bold" ~ "bold.nii.gz",
      suffix == "events" ~ "events.tsv",
      TRUE ~ suffix # Fallback
    ))
    
  mock_proj <- create_mock_bids(
    project_name = "MockTaskA",
    participants = participants_df,
    file_structure = fs_for_create %>% select(-suffix) %>% rename(suffix=suffix_ext), # Pass suffix with extension
    event_data = event_data_list,
    prep_dir = "derivatives/mockprep" # Use a distinct prep_dir for testing
  )

  expect_s3_class(mock_proj, "mock_bids_project")
  expect_equal(mock_proj$name, "MockTaskA")
  expect_true(mock_proj$has_sessions)
  expect_true(mock_proj$has_fmriprep)
  expect_equal(mock_proj$prep_dir, "derivatives/mockprep")
})

# --- Test Basic Queries ---
test_that("Basic queries work on mock BIDS project", {
  fs_for_create <- file_structure_df %>%
    mutate(suffix_ext = case_when(
      suffix == "T1w" ~ "T1w.nii.gz",
      suffix == "bold" ~ "bold.nii.gz",
      suffix == "events" ~ "events.tsv",
      TRUE ~ suffix
    ))
  mock_proj <- create_mock_bids(
    project_name = "MockTaskA",
    participants = participants_df,
    file_structure = fs_for_create %>% select(-suffix) %>% rename(suffix=suffix_ext),
    event_data = event_data_list,
    prep_dir = "derivatives/mockprep"
  )

  expect_equal(sort(participants(mock_proj)), c("01", "02"))
  expect_equal(sessions(mock_proj), "test") # Only one session defined
  expect_equal(tasks(mock_proj), "taskA") # Only one task defined
})

# --- Test File Searching ---
test_that("File searching methods work on mock BIDS project", {
  fs_for_create <- file_structure_df %>%
    mutate(suffix_ext = case_when(
      suffix == "T1w" ~ "T1w.nii.gz",
      suffix == "bold" ~ "bold.nii.gz",
      suffix == "events" ~ "events.tsv",
      TRUE ~ suffix
    ))
  mock_proj <- create_mock_bids(
    project_name = "MockTaskA",
    participants = participants_df,
    file_structure = fs_for_create %>% select(-suffix) %>% rename(suffix=suffix_ext),
    event_data = event_data_list,
    prep_dir = "derivatives/mockprep"
  )

  # search_files for raw T1w
  # Filter by kind="T1w", fmriprep=FALSE, regex for extension
  t1w_files_raw <- search_files(mock_proj, kind = "T1w", regex = "\\.nii\\.gz$", fmriprep = FALSE, full_path = FALSE)
  expect_equal(length(t1w_files_raw), 2) # Should find 2 raw T1w files
  raw_t1w_f1 <- generate_bids_filename(subid="01", suffix="T1w.nii.gz")
  raw_t1w_f2 <- generate_bids_filename(subid="02", session="test", suffix="T1w.nii.gz")
  expect_true(all(sort(t1w_files_raw) %in% sort(c(file.path("sub-01","anat",raw_t1w_f1),
                                                  file.path("sub-02","ses-test","anat",raw_t1w_f2)))))

  # func_scans (should only return raw bold)
  # Pass suffix as the extension pattern, use 'sub'
  fscans_sub1 <- func_scans(mock_proj, sub = "01", suffix = "nii\\.gz$", full_path = FALSE)
  expect_equal(length(fscans_sub1), 1) # Should find 1 raw bold for sub-01
  raw_bold_f1 <- generate_bids_filename(subid="01", task="taskA", run="01", suffix="bold.nii.gz")
  expect_equal(fscans_sub1, file.path("sub-01", "func", raw_bold_f1))

  fscans_all <- func_scans(mock_proj, suffix = "nii\\.gz$", full_path = FALSE)
  expect_equal(length(fscans_all), 2) # Should find 2 raw bold files total

  # event_files
  # Use 'subid', 'session' instead of 'sub', 'ses'
  ev_files_sub2_ses <- event_files(mock_proj, subid = "02", session = "test", full_path = FALSE)
  expect_equal(length(ev_files_sub2_ses), 1) # Should find 1 event file
  expect_equal(ev_files_sub2_ses, event_path_2)

  ev_files_all <- event_files(mock_proj, full_path = FALSE)
  expect_equal(length(ev_files_all), 2) # Should find 2 event files total
  expect_true(all(sort(ev_files_all) %in% sort(c(event_path_1, event_path_2))))

  # preproc_scans (functional) - check path construction
  # Filter by BIDS entities: kind, desc, space. Use 'sub'. Pass suffix for extension regex.
  preproc_func <- preproc_scans(mock_proj, sub = "01", task = "taskA", kind="bold", space="MNI", desc="preproc", suffix = "nii\\.gz$", full_path = FALSE)
  expect_equal(length(preproc_func), 1) # Should find 1 derivative func
  expect_equal(preproc_func, deriv_func_relpath)

  # search_files for derivatives (anatomical)
  # Filter by kind="T1w", fmriprep=TRUE, regex for extension. Use 'sub'.
  preproc_anat <- search_files(mock_proj, sub = "01", kind="T1w", space="MNI", desc="preproc", regex = "\\.nii\\.gz$", fmriprep=TRUE, full_path = FALSE)
  expect_equal(length(preproc_anat), 1) # Should find 1 derivative anat
  expect_equal(preproc_anat, deriv_anat_relpath)
})


# --- Test Event Reading --- # (Check test content based on the expected output of the fixed read_events)
test_that("Event reading works on mock BIDS project", {
   fs_for_create <- file_structure_df %>%
    mutate(suffix_ext = case_when(
      suffix == "T1w" ~ "T1w.nii.gz",
      suffix == "bold" ~ "bold.nii.gz",
      suffix == "events" ~ "events.tsv",
      TRUE ~ suffix
    ))
   mock_proj <- create_mock_bids(
    project_name = "MockTaskA",
    participants = participants_df,
    file_structure = fs_for_create %>% select(-suffix) %>% rename(suffix=suffix_ext),
    event_data = event_data_list,
    prep_dir = "derivatives/mockprep"
  )

  expect_true(length(mock_proj$event_data_store) > 0) # Check data was stored

  # Read events for sub-01. Use 'sub'
  events_sub1 <- read_events(mock_proj, sub = "01")

  expect_s3_class(events_sub1, "tbl_df")
  expect_gt(nrow(events_sub1), 0) # Expect one row for the sub-01 run

  # Check metadata columns in the *outer* tibble
  expect_named(events_sub1, c(".subid", ".task", ".run", ".session", "data"), ignore.order = TRUE)
  expect_equal(events_sub1$.subid[[1]], "01") # Access first element
  expect_equal(events_sub1$.task[[1]], "taskA")
  expect_equal(events_sub1$.run[[1]], "01")
  # Check session is NA or correct value if applicable
  expect_true(is.na(events_sub1$.session[[1]]) || is.character(events_sub1$.session[[1]]))

  # Check the *nested* data
  expect_s3_class(events_sub1$data[[1]], "tbl_df") # Access first list element
  expect_equal(events_sub1$data[[1]]$trial_type, c("condA", "condB"))

  # Read all events
  events_all <- read_events(mock_proj)
  expect_equal(nrow(events_all), 2) # Expect two rows (one per event file)
})


# --- Test Stub Creation (Optional) ---
# This test writes to disk, might be skipped on CI or needs cleanup
test_that("Mock BIDS stub creation works (writes to temp)", {
  skip_on_cran() # Don't run this on CRAN as it writes files
  # skip_if_not_installed("readr") # Ensure readr is available if used

  temp_stub_path <- tempfile(pattern = "mockbids_stub_")
  on.exit(unlink(temp_stub_path, recursive = TRUE, force = TRUE), add = TRUE)

  fs_for_create <- file_structure_df %>%
    mutate(suffix_ext = case_when(
      suffix == "T1w" ~ "T1w.nii.gz",
      suffix == "bold" ~ "bold.nii.gz",
      suffix == "events" ~ "events.tsv",
      TRUE ~ suffix
    ))
  mock_proj_stub <- create_mock_bids(
    project_name = "MockStub",
    participants = participants_df,
    file_structure = fs_for_create %>% select(-suffix) %>% rename(suffix=suffix_ext),
    event_data = event_data_list,
    create_stub = TRUE,
    stub_path = temp_stub_path,
    prep_dir = "derivatives/mockprep" # Match prep dir
  )

  expect_true(dir.exists(temp_stub_path))
  expect_true(file.exists(file.path(temp_stub_path, "participants.tsv")))
  expect_true(file.exists(file.path(temp_stub_path, "dataset_description.json")))
  expect_true(dir.exists(file.path(temp_stub_path, "sub-01", "func")))
  # Check for a raw file using its expected generated name
  raw_bold_f1 <- generate_bids_filename(subid="01", task="taskA", run="01", suffix="bold.nii.gz")
  expect_true(file.exists(file.path(temp_stub_path, "sub-01/func", raw_bold_f1)))
  expect_true(dir.exists(file.path(temp_stub_path, "derivatives", "mockprep", "sub-01", "func")))
  
  # Check for derivative files using exact paths now that we generate them
  expect_true(file.exists(file.path(temp_stub_path, deriv_func_relpath)))
  expect_true(file.exists(file.path(temp_stub_path, deriv_anat_relpath)))

  # Check event file content
  event_file_path_1_disk <- file.path(temp_stub_path, event_path_1)
  expect_true(file.exists(event_file_path_1_disk))
  
  # Use tryCatch for reading in case readr isn't available or file issue
  stub_event_data_1 <- tryCatch({
      readr::read_tsv(event_file_path_1_disk, show_col_types = FALSE)
  }, error = function(e) {
      warning("Could not read stub event file: ", e$message)
      NULL
  })
  
  if (!is.null(stub_event_data_1)) {
      expect_s3_class(stub_event_data_1, "tbl_df")
      expect_equal(nrow(stub_event_data_1), 2)
      expect_equal(stub_event_data_1$trial_type, c("condA", "condB"))
  }
})

# --- Test Debugging: Node Inspection ---
test_that("Node attributes inspection", {
  skip_on_cran() # Skip on CRAN, this is a debugging test
  
  fs_for_create <- file_structure_df %>%
    mutate(suffix_ext = case_when(
      suffix == "T1w" ~ "T1w.nii.gz",
      suffix == "bold" ~ "bold.nii.gz",
      suffix == "events" ~ "events.tsv",
      TRUE ~ suffix
    ))
  
  mock_proj <- create_mock_bids(
    project_name = "Debug",
    participants = participants_df,
    file_structure = fs_for_create %>% select(-suffix) %>% rename(suffix=suffix_ext),
    event_data = event_data_list,
    prep_dir = "derivatives/mockprep"
  )
  
  # Find a T1w file node 
  t1w_node <- NULL
  print("Getting T1w leaf nodes...")
  leaf_nodes <- data.tree::Traverse(mock_proj$bids_tree, 
                                   filterFun = function(n) n$isLeaf && stringr::str_detect(n$name, "T1w"))
  if (length(leaf_nodes) > 0) {
    t1w_node <- leaf_nodes[[1]]
    
    # Print tree structure first for debugging
    print("======== Tree Structure ========")
    print(mock_proj$bids_tree)
    print("=============================")
    
    # Print the node's attributes
    cat("Node name:", t1w_node$name, "\n")
    cat("Node path:", paste(t1w_node$path, collapse="/"), "\n")
    
    # Print all attributes in a way that handles environments
    cat("All node attributes (excluding complex types):\n")
    # Use attributesAll which is the non-deprecated way
    all_attrs <- t1w_node$attributesAll
    # Filter out complex data types that cause printing issues
    attrs_to_print <- names(all_attrs)[!sapply(all_attrs, function(x) is.environment(x) || is.list(x) || is.function(x) || inherits(x, "Node"))]
    
    for (attr_name in attrs_to_print) {
        cat("  -", attr_name, ":", toString(all_attrs[[attr_name]]), "\n")
    }
  }
  
  # Try direct use of search functions with verbose debugging
  cat("\n======== Direct Search Test ========\n")
  
  t1w_files_raw <- search_files(mock_proj, kind = "T1w", regex = "\\.nii\\.gz$", fmriprep = FALSE, full_path = FALSE)
  cat("Raw T1w search results:", length(t1w_files_raw), "\n")
  if (!is.null(t1w_files_raw)) {
    print(t1w_files_raw)
  }
  
  # Check if our filtering function would catch it
  cat("\nManually testing filter function on first T1w node...\n")
  # Get a T1w node
  if (!is.null(t1w_node)) {
    # Checks equivalent to those in filterNodes in search_files
    cat("Name match regex:", stringr::str_detect(t1w_node$name, "\\.nii\\.gz$"), "\n")
    
    # Check kind filter
    cat("Node has kind=T1w:", (!is.null(t1w_node$kind) && t1w_node$kind == "T1w"), "\n")
    
    # Check fmriprep filter
    is_in_deriv <- FALSE
    node_path_str_parts <- t1w_node$path
    prep_dir_parts <- strsplit(mock_proj$prep_dir, "/")[[1]]
    if (mock_proj$has_fmriprep && 
        length(node_path_str_parts) > (1 + length(prep_dir_parts)) &&
        all(node_path_str_parts[2:(1 + length(prep_dir_parts))] == prep_dir_parts)) {
      is_in_deriv <- TRUE
    }
    cat("Node is in derivatives:", is_in_deriv, "\n")
    
    # Manual mock_key_match equivalent
    filters <- list(kind = "T1w")
    node_attrs <- t1w_node
    
    for (k in names(filters)) {
      cat("Checking filter", k, "=", filters[[k]], "\n")
      cat("  Node has attribute:", k %in% names(node_attrs), "\n")
      if (k %in% names(node_attrs)) {
        cat("  Node value:", node_attrs[[k]], "\n")
        cat("  Values match:", node_attrs[[k]] == filters[[k]], "\n")
      } else {
        cat("  (Key missing)\n")
      }
    }
  }
  
  # Debugging assertions:
  expect_true(length(leaf_nodes) > 0, "No T1w nodes found")
  
  if (length(leaf_nodes) > 0) {
    expect_true(!is.null(t1w_node$relative_path), "T1w node is missing relative_path")
    
    # Check the specific attributes needed by search filters
    attrs_to_check <- c("kind", "sub", "suffix")
    has_needed_attrs <- attrs_to_check %in% names(t1w_node)
    
    if (!all(has_needed_attrs)) {
      missing <- attrs_to_check[!has_needed_attrs]
      warning("Missing attributes: ", paste(missing, collapse=", "))
    }
    
    for (attr in attrs_to_check) {
      # Only try to access attributes we've confirmed exist
      if (attr %in% names(t1w_node)) {
        # Safely check the attribute value
        val <- t1w_node[[attr]]
        expect_true(!is.null(val) && !is.environment(val),
                   paste("Attribute", attr, "is NULL or an environment"))
      }
    }
  }
})

# Add a dedicated inspect_create_mock_bids test to see what bidser::encode is returning
test_that("inspect create_mock_bids internals", {
  skip_on_cran() # Skip on CRAN, this is a debugging test

  # Create a simple test filename to encode
  test_filename <- "sub-01_task-rest_run-01_bold.nii.gz"
  
  # See what bidser::encode returns
  cat("\nTesting bidser::encode on", test_filename, "\n")
  enc <- bidser::encode(test_filename)
  
  # Print out what encode returns
  cat("encode() result fields:", paste(names(enc), collapse=", "), "\n")
  for (field in names(enc)) {
    cat("  - ", field, ": ", toString(enc[[field]]), "\n", sep="")
  }
  
  # Directly test the actual mapping from row in file_structure to node attributes
  cat("\nDemo parsing:\n")
  test_row <- data.frame(
    subid = "01",
    session = NA,
    datatype = "func",
    task = "rest",
    run = "01",
    suffix = "bold.nii.gz",
    fmriprep = FALSE,
    desc = NA,
    space = NA
  )
  
  print(test_row)
  
  # Manually generate filename
  filename <- generate_bids_filename(
    subid = test_row$subid,
    task = test_row$task,
    run = test_row$run,
    suffix = test_row$suffix
  )
  cat("Generated filename:", filename, "\n")
  
  # See what bidser::encode returns for this
  cat("\nEncoding result for generated filename:\n")
  enc <- bidser::encode(filename)
  print(enc)
})
</file>

<file path="tests/testthat/test_preproc_scans.R">
context("preproc_scans")
library(testthat)
library(bidser)

# Helper function to check if the phoneme_stripped dataset with fmriprep data is available
has_phoneme_data <- function() {
  test_path <- system.file("extdata/phoneme_stripped/derivatives/fmriprep", package="bidser")
  return(nchar(test_path) > 0 && dir.exists(test_path))
}

test_that("can extract preprocessed functional files from bids project", {
  skip_if_not(has_phoneme_data(), "Phoneme dataset with fmriprep derivatives not available")
  
  proj <- bids_project(system.file("extdata/phoneme_stripped", package="bidser"), fmriprep=TRUE)
  pscans <- preproc_scans(proj)
  expect_true(length(pscans) > 0)
  # Ensure there are preproc files for the dataset
  expect_true(any(grepl("preproc\\.nii\\.gz$", pscans)))
})

test_that("can extract preprocessed functional files for one subject", {
  skip_if_not(has_phoneme_data(), "Phoneme dataset with fmriprep derivatives not available")
  
  proj <- bids_project(system.file("extdata/phoneme_stripped", package="bidser"), fmriprep=TRUE)
  pscans <- preproc_scans(proj, subid="1001")
  expect_true(length(pscans) > 0)
  # Ensure all files are for subject 1001
  expect_true(all(grepl("sub-1001", pscans)))
})

test_that("can filter preprocessed files by run", {
  skip_if_not(has_phoneme_data(), "Phoneme dataset with fmriprep derivatives not available")
  
  proj <- bids_project(system.file("extdata/phoneme_stripped", package="bidser"), fmriprep=TRUE)
  pscans <- preproc_scans(proj, subid="1001", run="01")
  expect_true(length(pscans) > 0)
  # Ensure all files are for run 01
  expect_true(all(grepl("run-01", pscans)))
})

test_that("can filter preprocessed files by space", {
  skip_if_not(has_phoneme_data(), "Phoneme dataset with fmriprep derivatives not available")
  
  proj <- bids_project(system.file("extdata/phoneme_stripped", package="bidser"), fmriprep=TRUE)
  pscans <- preproc_scans(proj, space="MNI152NLin2009cAsym")
  expect_true(length(pscans) > 0)
  # Ensure all files are in MNI space
  expect_true(all(grepl("space-MNI152NLin2009cAsym", pscans)))
})

test_that("can get relative paths for preprocessed files", {
  skip_if_not(has_phoneme_data(), "Phoneme dataset with fmriprep derivatives not available")
  
  proj <- bids_project(system.file("extdata/phoneme_stripped", package="bidser"), fmriprep=TRUE)
  abs_pscans <- preproc_scans(proj, subid="1001", run="01", full_path=TRUE)
  rel_pscans <- preproc_scans(proj, subid="1001", run="01", full_path=FALSE)
  
  expect_true(length(abs_pscans) > 0)
  expect_true(length(rel_pscans) > 0)
  expect_equal(length(abs_pscans), length(rel_pscans))
  
  # Absolute paths should include the full system path
  expect_true(all(grepl("^/", abs_pscans)))
  
  # Relative paths should start with derivatives/fmriprep
  expect_true(all(grepl("^derivatives/fmriprep", rel_pscans)))
})

test_that("combining multiple filters works correctly", {
  skip_if_not(has_phoneme_data(), "Phoneme dataset with fmriprep derivatives not available")
  
  proj <- bids_project(system.file("extdata/phoneme_stripped", package="bidser"), fmriprep=TRUE)
  pscans <- preproc_scans(proj, 
                         subid="1001", 
                         task="phoneme", 
                         run="01", 
                         space="MNI152NLin2009cAsym")
  
  expect_true(length(pscans) > 0)
  # Ensure all files match all criteria
  expect_true(all(grepl("sub-1001", pscans)))
  expect_true(all(grepl("task-phoneme", pscans)))
  expect_true(all(grepl("run-01", pscans)))
  expect_true(all(grepl("space-MNI152NLin2009cAsym", pscans)))
})

test_that("attempt to find preproc scans with non-existent id returns NULL", {
  skip_if_not(has_phoneme_data(), "Phoneme dataset with fmriprep derivatives not available")
  
  proj <- bids_project(system.file("extdata/phoneme_stripped", package="bidser"), fmriprep=TRUE)
  pscans <- preproc_scans(proj, subid="nonexistent")
  expect_null(pscans)
})
</file>

<file path="tests/testthat/test_search_files.R">
library(testthat)
library(bidser)

# Load the example BIDS project once for all tests
proj_path <- system.file("extdata/phoneme_stripped", package="bidser")
proj <- bids_project(proj_path)

# Helper to get expected relative paths (stripping the project name prefix)
# e.g., "phoneme_stripped/raw/sub-1001/anat/sub-1001_T1w.json" -> "raw/sub-1001/anat/sub-1001_T1w.json"
get_relative_paths <- function(full_paths, project_name) {
  sub_pattern <- paste0("^", project_name, "/")
  sub("^raw/", "", gsub(sub_pattern, "", full_paths)) # Remove leading raw/ too
}


test_that("search_files finds files by regex", {
  # Find all .tsv files (should be events files)
  event_files_rel <- search_files(proj, regex = "events\\.tsv$", full_path = FALSE)
  expect_true(length(event_files_rel) > 0)
  expect_true(all(grepl("events\\.tsv$", event_files_rel)))
  expect_false(any(grepl(proj$name, event_files_rel))) # Check they are relative
  
  # Find all .nii.gz files (anat and func)
  nifti_files_full <- search_files(proj, regex = "\\.nii\\.gz$", full_path = TRUE)
  expect_true(length(nifti_files_full) > 0)
  expect_true(all(grepl("\\.nii\\.gz$", nifti_files_full)))
  expect_true(all(startsWith(nifti_files_full, proj$path))) # Check they are full paths
  
  # Find files with 'T1w' in the name
  t1w_files <- search_files(proj, regex = "T1w", full_path = FALSE)
  expect_true(length(t1w_files) > 0)
  expect_true(all(grepl("T1w", basename(t1w_files))))
})

test_that("search_files filters by subid", {
  sub1001_files <- search_files(proj, regex = ".*", subid = "1001", full_path = FALSE)
  expect_true(length(sub1001_files) > 0)
  expect_true(all(grepl("sub-1001", sub1001_files)))
  
  # Check against another subject
  sub1002_files <- search_files(proj, regex = ".*", subid = "1002", full_path = FALSE)
  expect_true(length(sub1002_files) > 0)
  expect_true(all(grepl("sub-1002", sub1002_files)))
  
  # Ensure no overlap unless expected (e.g. root files - not applicable here)
  expect_false(any(sub1001_files %in% sub1002_files))
})

test_that("search_files filters by task", {
  # This dataset only has 'phoneme' and 'rest' tasks
  phoneme_files <- search_files(proj, regex = ".*", task = "phoneme", full_path = FALSE)
  expect_true(length(phoneme_files) > 0)
  expect_true(all(grepl("task-phoneme", phoneme_files)))
  
  rest_files <- search_files(proj, regex = ".*", task = "rest", full_path = FALSE)
  expect_true(length(rest_files) > 0)
  expect_true(all(grepl("task-rest", rest_files)))
  
  # No overlap expected
  expect_false(any(phoneme_files %in% rest_files))
})

test_that("search_files filters by run", {
  run01_files <- search_files(proj, regex = ".*", run = "01", full_path = FALSE)
  expect_true(length(run01_files) > 0)
  expect_true(all(grepl("run-01", run01_files)))
  
  run02_files <- search_files(proj, regex = ".*", run = "02", full_path = FALSE)
  expect_true(length(run02_files) > 0)
  expect_true(all(grepl("run-02", run02_files)))
})

test_that("search_files combines filters", {
  sub1001_task_phoneme_run01_bold <- search_files(proj, 
                                                  regex = "bold\\.nii\\.gz$", 
                                                  subid = "1001", 
                                                  task = "phoneme", 
                                                  run = "01", 
                                                  full_path = FALSE)
  expect_equal(length(sub1001_task_phoneme_run01_bold), 1)
  expect_equal(sub1001_task_phoneme_run01_bold, "sub-1001/func/sub-1001_task-phoneme_run-01_bold.nii.gz")

  sub1002_task_phoneme_run05_events <- search_files(proj, 
                                                    regex = "events\\.tsv$", 
                                                    subid = "1002", 
                                                    task = "phoneme", 
                                                    run = "05", 
                                                    full_path = TRUE)
  expect_equal(length(sub1002_task_phoneme_run05_events), 1)
  
})

test_that("search_files handles kind='bold' correctly", {
  # kind="bold" should find the functional nifti files
  bold_files <- search_files(proj, kind = "bold", full_path = FALSE, suffix="nii.gz")
  expect_true(length(bold_files) > 0)
  # Check they are all nifti files from func folders
  expect_true(all(grepl("sub-.*/func/.*_bold\\.nii\\.gz$", bold_files)))
  
  # Combine kind='bold' with other filters
  sub1001_bold_files <- search_files(proj, kind = "bold", subid = "1001", full_path = FALSE)
  expect_true(length(sub1001_bold_files) > 0)
  expect_true(all(grepl("sub-1001/func/.*_bold.*", sub1001_bold_files)))
  
  sub1001_task_phoneme_bold_files <- search_files(proj, kind = "bold", subid = "1001", task = "phoneme", full_path = FALSE)
  expect_true(length(sub1001_task_phoneme_bold_files) > 0)
  expect_true(all(grepl("sub-1001/func/sub-1001_task-phoneme.*_bold.*", sub1001_task_phoneme_bold_files)))
})

test_that("search_files handles no matches", {
  no_match_regex <- search_files(proj, regex = "nonexistent_file_pattern")
  expect_null(no_match_regex)
  
  no_match_filter <- search_files(proj, subid = "9999")
  expect_null(no_match_filter)
  
  no_match_combo <- search_files(proj, task = "nonexistent_task", run = "01")
  expect_null(no_match_combo)
})

# Note: Testing `strict` is difficult with the current structure as attributes 
# are usually present if the key exists in the filename. A more complex mock 
# object might be needed to test strict=FALSE effectively where an attribute is NULL.
# We can test strict=TRUE implicitly (default behavior).

test_that("search_files strict=TRUE works (implicitly)", {
  # This should only return the T1w file for sub-1001, which has kind=T1w implicitly
  t1w_anat_files <- search_files(proj, subid = "1001", type = "anat", kind = "T1w", regex = "T1w\\.nii\\.gz$", strict = TRUE)
  expect_equal(length(t1w_anat_files), 1)
  expect_true(grepl("sub-1001_T1w.nii.gz", t1w_anat_files))
  
  # This should return NULL because T1w files don't have a 'task' attribute
  no_match_strict <- search_files(proj, subid = "1001", task = "phoneme", kind = "T1w", regex = "T1w\\.nii\\.gz$", strict = TRUE)
  expect_null(no_match_strict)
})

# Add tests for derivatives if fmriprep is loaded
proj_fmriprep_path <- system.file("extdata/phoneme_fmriprep", package="bidser")
if (dir.exists(proj_fmriprep_path)) {
  proj_prep <- bids_project(proj_fmriprep_path, fmriprep = TRUE)

  test_that("search_files finds files in derivatives", {
    # Find preprocessed bold files
    prep_bold_files <- search_files(proj_prep, 
                                    regex = "preproc_bold\\.nii\\.gz$", 
                                    kind = "preproc", # Or use desc = "preproc"
                                    full_path = FALSE)
    expect_true(length(prep_bold_files) > 0)
    # Check paths include derivatives dir
    expect_true(all(grepl(paste0("^", proj_prep$prep_dir), prep_bold_files)))
    expect_true(all(grepl("desc-preproc_bold\\.nii\\.gz$", prep_bold_files)))
    
    # Find confounds files for a specific subject
    confounds_sub1001 <- search_files(proj_prep, 
                                      regex = "confounds_timeseries\\.tsv$", 
                                      subid = "1001", 
                                      full_path = FALSE)
    expect_true(length(confounds_sub1001) > 0)
    expect_true(all(grepl(paste0("^", proj_prep$prep_dir, "/sub-1001"), confounds_sub1001)))
    expect_true(all(grepl("desc-confounds_timeseries\\.tsv$", confounds_sub1001)))
  })
} else {
  message("Skipping derivative search tests: extdata/phoneme_fmriprep not found.")
}
</file>

<file path="tests/testthat.R">
library(testthat)
library(bidser)

test_check("bidser")
</file>

<file path="R/sidecar.R">
#' Read sidecar JSON files and return metadata as a tidy tibble
#'
#' This function searches for JSON sidecar files matching the given criteria (subject, task, run, session),
#' reads the JSON content, and converts all top-level fields into columns of a tibble. Each file's metadata
#' becomes one row in the returned tibble. This is particularly useful for extracting metadata about BIDS
#' imaging files, such as acquisition parameters, task descriptions, and other relevant information.
#'
#' @param x A \code{bids_project} object.
#' @param subid A regex for matching subject IDs. Default is `".*"`.
#' @param task A regex for matching tasks. Default is `".*"`.
#' @param run A regex for matching runs. Default is `".*"`.
#' @param session A regex for matching sessions. Default is `".*"`.
#' @param modality A regex for matching modality (e.g. "bold"). Default is `"bold"`.
#' @param full_path If TRUE, return full file paths in the `file` column. Default is TRUE.
#' @param ... Additional arguments passed to `search_files()`.
#'
#' @return A tibble with one row per JSON file. Columns include:
#'   - `file`: the JSON file path
#'   - `.subid`: subject ID extracted from filename
#'   - `.session`: session ID extracted from filename (if present)
#'   - `.task`: task name extracted from filename (if present)
#'   - `.run`: run number extracted from filename (if present)
#'   - Additional columns for each top-level key in the JSON files
#'   If no files are found, returns an empty tibble.
#'
#' @examples
#' # Read all BOLD sidecar files from a BIDS dataset
#' proj <- bids_project(system.file("extdata/ds001", package="bidser"))
#' metadata <- read_sidecar(proj)
#'
#' # Read sidecar files for a specific subject and task
#' sub01_meta <- read_sidecar(proj, 
#'                           subid="01", 
#'                           task="balloonanalogrisktask")
#'
#' # Read sidecar files for anatomical data
#' anat_meta <- read_sidecar(proj, 
#'                          modality="T1w",
#'                          full_path=FALSE)
#'
#' # Read sidecar files for a specific session
#' ds007 <- bids_project(system.file("extdata/ds007", package="bidser"))
#' session_meta <- read_sidecar(ds007, session="test")
#'
#' @importFrom tibble tibble
#' @importFrom dplyr bind_rows mutate
#' @importFrom jsonlite read_json
#' @importFrom stringr str_match
#' @export
read_sidecar <- function(x, subid=".*", task=".*", run=".*", session=".*", modality="bold", full_path=TRUE, ...) {
  # Find all JSON sidecar files (assumed to end with .json)
  # and match given criteria:
  json_files <- search_files(x, regex="\\.json$", full_path=full_path, strict=TRUE,
                             subid=subid, task=task, run=run, session=session, modality=modality, ...)
  
  if (is.null(json_files) || length(json_files) == 0) {
    message("No matching JSON sidecar files found.")
    return(tibble::tibble())
  }
  
  parse_metadata <- function(fn) {
    bname <- basename(fn)
    # Extract metadata from filename
    subid_val <- stringr::str_match(bname, "sub-([A-Za-z0-9]+)")[,2]
    session_val <- stringr::str_match(bname, "ses-([A-Za-z0-9]+)")[,2]
    task_val <- stringr::str_match(bname, "task-([A-Za-z0-9]+)")[,2]
    run_val <- stringr::str_match(bname, "run-([0-9]+)")[,2]
    
    # Read the JSON
    jdata <- tryCatch({
      jsonlite::read_json(fn, simplifyVector = TRUE)
    }, error=function(e) {
      warning("Failed to read JSON: ", fn, " - ", e$message)
      return(NULL)
    })
    if (is.null(jdata)) return(NULL)
    
    # Convert JSON named list into a one-row tibble
    meta_tibble <- as.data.frame(jdata, stringsAsFactors = FALSE)
    if (nrow(meta_tibble) == 0) {
      # If empty, just return a row of NAs
      meta_tibble <- tibble::tibble()
    }
    meta_tibble <- tibble::as_tibble(meta_tibble)
    
    # Add identifying columns
    meta_tibble <- meta_tibble %>%
      dplyr::mutate(.subid = subid_val,
                    .session = session_val,
                    .task = task_val,
                    .run = run_val,
                    file = fn)
    
    meta_tibble
  }
  
  df_list <- lapply(json_files, parse_metadata)
  df_list <- df_list[!sapply(df_list, is.null)]
  
  if (length(df_list) == 0) {
    message("No valid JSON files could be read.")
    return(tibble::tibble())
  }
  
  dplyr::bind_rows(df_list)
}


#' Get Repetition Time (TR) from a sidecar JSON
#'
#' This function attempts to find and return the repetition time (TR) for a given subject, task, and run
#' (and optionally session) by locating the associated BOLD sidecar JSON file and extracting the 
#' 'RepetitionTime' field. If not found, returns NA.
#'
#' @param x A \code{bids_project} object.
#' @param subid Subject ID (exact or regex).
#' @param task Task name (exact or regex).
#' @param run Run number (exact or regex). Default is ".*" to allow flexible matching.
#' @param session Session ID (exact or regex). Default is ".*".
#' @param ... Additional arguments passed to `read_sidecar()`.
#'
#' @return A numeric value representing the RepetitionTime in seconds, or NA if not found.
#'
#' @export
get_repetition_time <- function(x, subid, task, run=".*", session=".*", ...) {
  # Load sidecar JSONs for matching subid, task, run, session with a 'bold' modality by default
  sidecars <- read_sidecar(x, subid=subid, task=task, run=run, session=session, modality="bold", ...)
  
  if (nrow(sidecars) == 0) {
    message("No matching sidecar JSON file found for the specified criteria.")
    return(NA_real_)
  }
  
  # If multiple files match, just take the first (or implement more logic if needed)
  # TR is usually consistent per run.
  # `RepetitionTime` is the BIDS key for TR in seconds.
  tr_val <- sidecars$RepetitionTime[1]
  if (is.null(tr_val) || is.na(tr_val)) {
    # Not found
    return(NA_real_)
  } else {
    return(as.numeric(tr_val))
  }
}
</file>

<file path="R/check.R">
#' Check Functional Scans in a BIDS Project
#'
#' This function performs a comprehensive inspection of functional scans within a BIDS project,
#' providing detailed summaries of scan counts and file sizes per subject and task. It helps
#' identify potential issues such as missing scans, inconsistent file sizes, or unexpected
#' variations in the data.
#'
#' @param x A \code{bids_project} object created by \code{bids_project()}.
#'
#' @return A list containing:
#'   - `scans`: A tibble with details of all functional scans, including:
#'     - Subject ID
#'     - Task name
#'     - Run number
#'     - File size
#'     - Full file path
#'   - `tasklist`: A vector of unique tasks found in the project
#'   - `scans_per_subject`: A summary tibble showing the number of scans per subject
#'   
#'   If multiple tasks are present, also includes:
#'   - `scans_per_task`: Summary of scan counts by task
#'   - `scans_per_task_subject`: Summary of scan counts by subject and task
#'   - `size_per_task`: Tibble with file size statistics by task
#'   
#'   If only one task is present:
#'   - `size_per_subject`: Tibble with file size statistics by subject
#'
#' @examples
#' # Create a BIDS project object
#' proj <- bids_project(system.file("extdata/ds001", package="bidser"))
#'
#' # Check functional scans
#' scan_check <- check_func_scans(proj)
#'
#' # View available tasks
#' print(scan_check$tasklist)
#'
#' # Check scan counts per subject
#' print(scan_check$scans_per_subject)
#'
#' # Example with multiple tasks
#' ds007 <- bids_project(system.file("extdata/ds007", package="bidser"))
#' multi_check <- check_func_scans(ds007)
#'
#' # View scan distribution across tasks
#' print(multi_check$scans_per_task)
#'
#' # Check for potential issues
#' if (nrow(multi_check$scans) > 0) {
#'   # Look for subjects with fewer scans than expected
#'   expected_scans <- 4  # Example: expecting 4 scans per subject
#'   missing <- multi_check$scans_per_subject[
#'     multi_check$scans_per_subject$n < expected_scans,
#'   ]
#'   if (nrow(missing) > 0) {
#'     print("Subjects with missing scans:")
#'     print(missing)
#'   }
#' }
#'
#' @importFrom fs file_size
#' @importFrom dplyr group_by summarize mutate select everything
#' @importFrom dplyr bind_rows tibble filter
#' @importFrom tidyr unnest
#' @importFrom stringr str_detect
#' @importFrom magrittr %>%
#' @export
check_func_scans <- function(x) {
  if (!inherits(x, "bids_project")) {
    stop("`x` must be a `bids_project` object.")
  }
  
  # Retrieve functional scans and task list
  fscans <- func_scans(x)
  tasklist <- tasks(x)
  
  if (length(fscans) == 0) {
    warning("No functional scans found in this project.")
    return(list(
      scans = tibble::tibble(),
      tasklist = character(0),
      scans_per_subject = tibble::tibble()
    ))
  }
  
  # For each scan file, encode and gather metadata
  ret <- lapply(fscans, function(fn) {
    enc <- encode(basename(fn))
    sz <- fs::file_size(fn)
    if (is.null(enc)) {
      warning("Could not encode file: ", fn)
      dplyr::tibble(file = fn, size = sz)
    } else {
      dplyr::as_tibble(enc) %>%
        dplyr::mutate(file = basename(fn), size = sz) %>%
        dplyr::select(file, size, dplyr::everything())
    }
  }) %>% dplyr::bind_rows()
  
  # Summaries
  scans_per_subject <- ret %>%
    dplyr::group_by(subid) %>%
    dplyr::summarize(nscans = dplyr::n(), .groups = "drop")
  
  size_per_subject <- ret %>%
    dplyr::group_by(subid) %>%
    dplyr::mutate(size_delta = size - median(size)) %>%
    dplyr::ungroup()
  
  if (length(tasklist) > 1) {
    scans_per_task <- ret %>%
      dplyr::group_by(task) %>%
      dplyr::summarize(nscans = dplyr::n(), .groups = "drop")
    
    scans_per_task_subject <- ret %>%
      dplyr::group_by(subid, task) %>%
      dplyr::summarize(nscans = dplyr::n(), .groups = "drop")
    
    size_per_task <- ret %>%
      dplyr::group_by(task) %>%
      dplyr::mutate(size_delta = size - median(size)) %>%
      dplyr::ungroup()
    
    out <- list(
      scans = ret,
      tasklist = tasklist,
      scans_per_subject = scans_per_subject,
      scans_per_task = scans_per_task,
      scans_per_task_subject = scans_per_task_subject,
      size_per_task = size_per_task
    )
  } else {
    out <- list(
      scans = ret,
      tasklist = tasklist,
      scans_per_subject = scans_per_subject,
      size_per_subject = size_per_subject
    )
  }
  
  class(out) <- c("check", "check_func_scans")
  out
}


#' Find File Pairs in a BIDS Project
#'
#' This function matches pairs of related files (e.g., BOLD and event files) in a BIDS project,
#' returning a tibble with matched filenames. It's useful for verifying that corresponding files
#' exist for each subject and task, such as ensuring every BOLD file has an associated events file.
#'
#' @param x A \code{bids_project} object.
#' @param pair A character string specifying which pair of files to match. Currently supported:
#'   - "bold-events": matches BOLD files with event files
#'   - "preproc-events": matches preprocessed BOLD files with event files
#' @param task A regex pattern to filter tasks. Default is ".*" (no filter).
#' @param matchon A character vector of keys to match on, usually c("run", "task").
#' @param ... Additional arguments passed to internal functions.
#'
#' @return A tibble with columns:
#'   - `subid`: The subject ID
#'   - `task`: The task name
#'   - `[type1]`: The name of the first file type (e.g., "bold" or "preproc")
#'   - `[type2]`: The matched file of the second type (e.g., "events"), or `NA` if no match found
#'   - Additional columns for matched metadata (e.g., run, session)
#'
#' @examples
#' # Create a BIDS project object
#' proj <- bids_project(system.file("extdata/ds001", package="bidser"))
#'
#' # Match BOLD files with their corresponding event files
#' bold_pairs <- file_pairs(proj, pair="bold-events")
#'
#' # Check pairs for a specific task
#' task_pairs <- file_pairs(proj, 
#'                         pair="bold-events",
#'                         task="balloonanalogrisktask")
#'
#' # Create a project with preprocessed data
#' prep_proj <- bids_project(system.file("extdata/phoneme_stripped", package="bidser"),
#'                          fmriprep=TRUE)
#'
#' # Match preprocessed files with event files
#' preproc_pairs <- file_pairs(prep_proj, pair="preproc-events")
#'
#' # Check for missing pairs
#' missing_pairs <- preproc_pairs[is.na(preproc_pairs$events), ]
#'
#' @importFrom dplyr filter mutate tibble bind_rows group_by summarize
#' @importFrom assertthat assert_that
#' @importFrom stringr str_detect str_match
#' @importFrom stringdist stringdistmatrix
#' @importFrom rlang sym
#' @export
file_pairs <- function(x, pair=c("bold-events", "preproc-events"), task=".*", matchon=c("run", "task"), ...) {
  assertthat::assert_that(inherits(x, "bids_project"))
  
  pair <- match.arg(pair)
  sids <- participants(x)
  
  # Extract types from pair
  parts <- strsplit(pair, "-")[[1]]
  type1 <- parts[1]
  type2 <- parts[2]
  
  # Determine appropriate regex for files based on pair
  if (pair == "bold-events") {
    # Bold is typically associated with .nii or .nii.gz files
    # Events with .tsv
    regex_mod1 <- "(nii|nii\\.gz)$"
    regex_mod2 <- "events\\.tsv$"
  } else if (pair == "preproc-events") {
    regex_mod1 <- "preproc\\.nii(\\.gz)*$"
    regex_mod2 <- "events\\.tsv$"
  } else {
    stop("Unsupported pair: ", pair)
  }
  
  results <- lapply(sids, function(s) {
    # Filter for type1 files
    df1 <- dplyr::filter(x$tbl,
                         subid == s,
                         modality == type1,
                         stringr::str_detect(task, task))
    df1 <- df1[grep(regex_mod1, df1$name), , drop=FALSE]
    
    # Filter for type2 files
    df2 <- dplyr::filter(x$tbl,
                         subid == s,
                         modality == type2,
                         stringr::str_detect(task, task))
    df2 <- df2[grep(regex_mod2, df2$name), , drop=FALSE]
    
    # If no type2 matches
    if (nrow(df1) > 0 && nrow(df2) == 0) {
      # Return df1 with NA for type2
      return(dplyr::tibble(
        subid = s,
        task = df1$task,
        !!rlang::sym(type1) := df1$name,
        !!rlang::sym(type2) := NA_character_
      ))
    }
    
    # If no type1 matches
    if (nrow(df2) > 0 && nrow(df1) == 0) {
      # Return a row with no matches for type1
      return(dplyr::tibble(
        subid = s,
        task = NA_character_,
        !!rlang::sym(type1) := character(0),
        !!rlang::sym(type2) := character(0)
      ))
    }
    
    # If both are present
    if (nrow(df1) == 0 && nrow(df2) == 0) {
      # No files found at all for this subject
      return(dplyr::tibble(
        subid = s,
        task = NA_character_,
        !!rlang::sym(type1) := character(0),
        !!rlang::sym(type2) := character(0)
      ))
    }
    
    # Match rows by run/task strings using stringdist
    mat1 <- df1[, matchon, drop=FALSE]
    mat2 <- df2[, matchon, drop=FALSE]
    
    # Create strings to match on
    str1 <- apply(mat1, 1, paste, collapse="-")
    str2 <- apply(mat2, 1, paste, collapse="-")
    
    sdmat <- stringdist::stringdistmatrix(str1, str2)
    
    # For each row in df1, find the best match in df2 with a distance of 0
    s2match <- apply(sdmat, 1, function(z) {
      zmin <- min(z)
      if (zmin == 0) {
        df2$name[which.min(z)]
      } else {
        NA_character_
      }
    })
    
    dplyr::tibble(
      subid = s,
      task = df1$task,
      !!rlang::sym(type1) := df1$name,
      !!rlang::sym(type2) := s2match
    )
  })
  
  dplyr::bind_rows(results)
}
</file>

<file path="R/match_helpers.R">
## convenience methods for matching different patterns

#' Extract `type` and `suffix` fields from a parsed value
#'
#' @param x A parsed value (likely from a parser combinator)
#' @keywords internal
extractor <- function(x) {
  list(type = x[[1]][[1]], suffix = x[[2]][[1]])
}

#' Alternate extractor that expects a slightly different structure
#'
#' @param x A parsed value (likely from a parser combinator)
#' @keywords internal
alt_extractor <- function(x) {
  list(type = x[[1]][[1]], suffix = x[[2]]$value)
}


#' Create a parser for an optional BIDS key
#'
#' @param label The label of the key to parse.
#' @param regex A regex pattern that the key's value should match.
#' @return A parser that matches zero or more occurrences of `_<label>-<id>`
#' @keywords internal
optional_key <- function(label, regex = "[A-Za-z0-9]+") {
  if (!is.character(label) || length(label) != 1) {
    stop("`label` must be a single character string.")
  }
  pMany(
    paste0("has_", label),
    pSeq(
      function(value) { value[[4]]$value },
      pLiteral("_"), pLiteral(label), pLiteral("-"), pRegex("id", regex)
    )
  )
}

#' Create a parser for an optional BIDS literal
#'
#' This matches zero or one occurrence of `_<lit>`
#'
#' @param lit A literal to match (a fixed string).
#' @param label A label for the parser.
#' @return A parser that matches zero or one occurrence of `_<lit>`
#' @keywords internal
optional_literal <- function(lit, label) {
  if (!is.character(lit) || length(lit) != 1) {
    stop("`lit` must be a single character string.")
  }
  if (!is.character(label) || length(label) != 1) {
    stop("`label` must be a single character string.")
  }
  pMany(
    paste0("has_", label),
    pSeq(
      function(value) { value[[2]][[1]][[1]] },
      pLiteral("_"), pLiteral(lit)
    )
  )
}

#' Create a parser for a mandatory BIDS key
#'
#' Matches a pattern `_<label>-<id>` where `id` matches a given regex.
#'
#' @param label The label of the key to parse.
#' @param regex The regex for the key's value.
#' @return A parser that must match one occurrence of `_<label>-<id>`
#' @keywords internal
mandatory_key <- function(label, regex = "[A-Za-z0-9]+") {
  if (!is.character(label) || length(label) != 1) {
    stop("`label` must be a single character string.")
  }
  pSeq(
    function(value) { value[[4]]$value },
    pLiteral("_"), pLiteral(label), pLiteral("-"), pRegex("id", regex)
  )
}

#' Create a parser for a starting BIDS key (no leading underscore)
#'
#' Matches `<label>-<id>` at the start of a filename.
#'
#' @param label The label of the key to parse.
#' @param regex The regex for the key's value.
#' @return A parser that matches `<label>-<id>` at the start
start_key <- function(label, regex = "[A-Za-z0-9]+") {
  if (!is.character(label) || length(label) != 1) {
    stop("`label` must be a single character string.")
  }
  pSeq(
    function(value) { value[[3]]$value },
    pLiteral(label), pLiteral("-"), pRegex("id", regex)
  )
}

#' Match one of several possible labels
#'
#' Given a vector of labels, matches `_<label>` where <label> is one of them.
#'
#' @param labels A character vector of possible labels.
#' @return A parser that matches `_<one_of_labels>`
#' @keywords internal
one_of <- function(labels) {
  if (!is.character(labels) || length(labels) == 0) {
    stop("`labels` must be a non-empty character vector.")
  }
  
  literals <- lapply(labels, pLiteral)
  pSeq(
    function(value) { value[[2]][[1]] },
    pLiteral("_"),
    do.call(pAlt, c(literals, tag = function(x) { x }))
  )
}

#' Match zero or one of several labels
#'
#' Similar to `one_of` but matches zero or one occurrence.
#'
#' @param labels A character vector of possible labels.
#' @param label A label for the parser.
#' @return A parser that matches zero or one of `_<labels>`
#' @keywords internal
zero_or_one_of <- function(labels, label) {
  if (!is.character(labels) || length(labels) == 0) {
    stop("`labels` must be a non-empty character vector.")
  }
  if (!is.character(label) || length(label) != 1) {
    stop("`label` must be a single character string.")
  }
  
  literals <- lapply(labels, pLiteral)
  pMany(
    paste0("has_", label),
    pSeq(
      function(value) { value[[2]][[1]] },
      pLiteral("_"),
      do.call(pAlt, c(literals, tag = function(x) x))
    )
  )
}

#' Create a parser that matches a fixed pattern of type followed by suffix
#'
#' This function creates a parser that matches a fixed pattern of type followed by suffix,
#' used internally to match specific BIDS file patterns. The parser uses a provided extractor
#' function to extract matched fields from the filename.
#'
#' @param type A literal for the type (e.g., "bold", "T1w").
#' @param suffix A literal for the suffix (e.g., ".nii.gz", ".tsv").
#' @param extractor A function to extract matched fields from the filename.
#'
#' @return A parser function that matches `type` followed by `suffix`. The parser returns:
#'   - A list with the matched components if successful
#'   - NULL if the pattern doesn't match
#'
#' @examples
#' # Create a parser for BOLD files
#' bold_parser <- gen_lit("bold", ".nii.gz", function(x) list(type="bold"))
#' bold_parser("sub-01_task-rest_bold.nii.gz")  # Returns list(type="bold")
#' bold_parser("sub-01_T1w.nii.gz")  # Returns NULL (no match)
#'
#' # Create a parser for T1w files
#' t1w_parser <- gen_lit("T1w", ".nii.gz", function(x) list(type="T1w"))
#' t1w_parser("sub-01_T1w.nii.gz")  # Returns list(type="T1w")
#'
#' # Create a parser for event files
#' event_parser <- gen_lit("events", ".tsv", function(x) list(type="events"))
#' event_parser("sub-01_task-rest_events.tsv")  # Returns list(type="events")
#'
#' @keywords internal
gen_lit <- function(type, suffix, extractor) {
  if (!is.character(type) || length(type) != 1) {
    stop("`type` must be a single character string.")
  }
  if (!is.character(suffix) || length(suffix) != 1) {
    stop("`suffix` must be a single character string.")
  }
  
  pSeq(extractor, pLiteral(type), pLiteral(suffix))
}

#' Multiple literal matchers
#'
#' Given multiple `types` and a single `suffix`, generates a list of parsers.
#'
#' @param types A character vector of types.
#' @param suffix A single suffix string.
#' @param extractor A function to extract matched fields.
#' @return A list of parsers.
#' @keywords internal
gen_lits <- function(types, suffix, extractor) {
  if (!is.character(types) || length(types) == 0) {
    stop("`types` must be a non-empty character vector.")
  }
  lapply(types, function(t) gen_lit(t, suffix, extractor))
}
</file>

<file path="R/events.R">
#' Retrieve event files from a BIDS project
#' 
#' Finds event files matching the given subject, task, run, and session criteria.
#'
#' @param x A \code{bids_project} object.
#' @param subid Regex pattern to match subject IDs. Default is ".*" (all subjects).
#' @param task Regex pattern to match tasks. Default is ".*" (all tasks).
#' @param run Regex pattern to match runs. Default is ".*" (all runs).
#' @param session Regex pattern to match sessions. Default is ".*" (all sessions).
#' @param full_path If \code{TRUE}, return full paths of files. Otherwise, return relative paths.
#' @param ... Additional arguments passed on to \code{search_files}.
#' @return A character vector of file paths to event files. If no matching files are found, returns an empty character vector.
#' @rdname event_files-method
#' @export
#' @examples
#' \donttest{
#' # Get event files for a specific subject and task
#' x <- bids_project(system.file("extdata/ds001", package="bidser"))
#' files <- event_files(x, subid="01", task="balloonanalogrisktask")
#' }
event_files.bids_project <- function(x, subid=".*", task=".*", run=".*", session=".*", full_path=TRUE, ...) {
  # Validate input
  if (!inherits(x, "bids_project")) {
    stop("`x` must be a `bids_project` object.")
  }
  
  # Use search_files to find event files
  tryCatch({
    search_files(
      x,
      regex = "events\\.tsv$",  # Match files ending with events.tsv
      subid = subid,
      task = task,
      session = session,
      run = run,
      full_path = full_path,
      strict = TRUE,  # Require that all queried keys exist in matched files
      ...
    )
  }, error = function(e) {
    warning("Error searching for event files: ", e$message)
    character(0)  # Return empty character vector on error
  })
}


#' Read event files from a BIDS project
#'
#' Reads and nests event files for given subjects and tasks from a \code{bids_project} object.
#' Returns a nested tibble with event data grouped by task, run, and subject. Event files
#' typically contain trial-by-trial information for task-based fMRI data, including onset times,
#' durations, trial types, and other task-specific variables.
#'
#' @param x A \code{bids_project} object.
#' @param subid Regex pattern to match subject IDs. Default is ".*" (all subjects).
#' @param task Regex pattern to match tasks. Default is ".*" (all tasks).
#' @param run Regex pattern to match runs. Default is ".*" (all runs).
#' @param session Regex pattern to match sessions. Default is ".*" (all sessions).
#' @param ... Additional arguments passed to \code{event_files}.
#'
#' @return A nested tibble with columns:
#'   - `.subid`: Subject ID
#'   - `.task`: Task name
#'   - `.run`: Run number
#'   - `.session`: Session ID (if present)
#'   - `data`: A nested tibble containing the event data with columns:
#'     - `onset`: Event onset time in seconds
#'     - `duration`: Event duration in seconds
#'     - Additional task-specific columns (e.g., trial type, response, accuracy)
#'   If no matching data is found, returns an empty tibble with appropriate columns.
#'
#' @importFrom dplyr mutate group_by bind_rows %>% filter
#' @importFrom tidyr nest
#' @importFrom magrittr %>%
#' @importFrom stringr str_detect
#' @importFrom rlang .data
#' @examples
#' # Create a BIDS project object
#' proj <- bids_project(system.file("extdata/ds001", package="bidser"))
#'
#' # Read all event files
#' all_events <- read_events(proj)
#'
#' # Read events for a specific subject and task
#' sub01_events <- read_events(proj, 
#'                           subid="01", 
#'                           task="balloonanalogrisktask")
#'
#' # Read events for multiple subjects and a specific run
#' multi_sub_events <- read_events(proj, 
#'                               subid="0[1-3]", 
#'                               run="01")
#'
#' # Access nested data for analysis
#' if (nrow(sub01_events) > 0) {
#'   # Get first subject's data
#'   first_sub_data <- sub01_events$data[[1]]
#'   
#'   # Calculate mean trial duration
#'   mean_duration <- mean(first_sub_data$duration)
#' }
#' @export
read_events.bids_project <- function(x, subid=".*", task=".*", run=".*", session=".*", ...) {
  # Validate input
  if (!inherits(x, "bids_project")) {
    stop("`x` must be a `bids_project` object.")
  }
  
  # Create empty result tibble with correct structure
  empty_result <- tibble::tibble(
    .task = character(0),
    .run = character(0),
    .subid = character(0),
    data = list()
  )
  
  # Get matching participants
  participants_vec <- participants(x)
  if (length(participants_vec) == 0) {
    warning("No participants found in the BIDS project.")
    return(empty_result)
  }
  
  p_idx <- grep(subid, participants_vec)
  if (length(p_idx) == 0) {
    warning("No matching participants found for 'subid' pattern: ", subid)
    return(empty_result)
  }
  sids <- participants_vec[p_idx]
  
  # Get matching tasks
  task_vec <- tasks(x)
  if (length(task_vec) == 0) {
    warning("No tasks found in the BIDS project.")
    return(empty_result)
  }
  
  t_idx <- grep(task, task_vec)
  if (length(t_idx) == 0) {
    warning("No matching tasks found for 'task' pattern: ", task)
    return(empty_result)
  }
  selected_tasks <- task_vec[t_idx]
  
  # Parser for extracting run info
  p <- func_parser()
  
  # Process each task and subject combination
  results <- vector("list", length(selected_tasks))
  
  for (i in seq_along(selected_tasks)) {
    tk <- selected_tasks[i]
    task_results <- vector("list", length(sids))
    
    for (j in seq_along(sids)) {
      sid <- sids[j]
      
      # Get event files for this subject and task
      evs <- tryCatch({
        event_files(x, subid = as.character(sid), task = tk)
      }, error = function(e) {
        warning("Error retrieving event files for subject ", sid, " and task ", tk, ": ", e$message)
        character(0)
      })
      
      if (length(evs) == 0) {
        # No event files found for this subject and task
        task_results[[j]] <- NULL
        next
      }
      
      # Extract run information from filenames
      runs <- character(length(evs))
      for (k in seq_along(evs)) {
        parsed <- tryCatch({
          parse(p, basename(evs[k]))
        }, error = function(e) {
          warning("Failed to parse filename: ", basename(evs[k]), " - ", e$message)
          NULL
        })
        
        runs[k] <- if (!is.null(parsed) && !is.null(parsed$result$run)) {
          parsed$result$run
        } else {
          NA_character_
        }
      }
      
      # Read event files
      event_data <- vector("list", length(evs))
      for (k in seq_along(evs)) {
        df <- tryCatch({
          read.table(evs[k], header = TRUE, stringsAsFactors = FALSE, 
                    na.strings = c("n/a", "NA", "N/A", ""))
        }, error = function(e) {
          warning("Failed to read event file: ", evs[k], " - ", e$message)
          NULL
        })
        
        if (!is.null(df)) {
          # Add metadata columns
          event_data[[k]] <- dplyr::mutate(df, 
                                          .subid = sid, 
                                          .run = runs[k],
                                          .file = evs[k])
        }
      }
      
      # Combine all runs for this subject
      combined_data <- dplyr::bind_rows(event_data)
      if (nrow(combined_data) > 0) {
        task_results[[j]] <- combined_data
      }
    }
    
    # Combine results for this task
    task_combined <- dplyr::bind_rows(task_results)
    if (nrow(task_combined) > 0) {
      results[[i]] <- task_combined %>% 
        dplyr::mutate(.task = tk) %>%
        dplyr::group_by(.data$.task, .data$.run, .data$.subid) %>%
        tidyr::nest()
    }
  }
  
  # Combine results across all selected tasks
  final_result <- dplyr::bind_rows(results)
  
  # If no data returned at all, return empty tibble with correct structure
  if (nrow(final_result) == 0) {
    message("No event data found for the given selection of subjects and tasks.")
    return(empty_result)
  }
  
  final_result
}
</file>

<file path="README.Rmd">
---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# bidser

<!-- badges: start -->
[![Codecov test coverage](https://codecov.io/gh/bbuchsbaum/bidser/branch/master/graph/badge.svg)](https://codecov.io/gh/bbuchsbaum/bidser?branch=master)
<!-- badges: end -->

[BIDS](https://bids.neuroimaging.io/) in R -- (it's a start!)

The goal of bidser is to make working with the BIDS neuroimaging format convenient in R. 
Currently there is support for MRI data and some support for some [fmriprep](https://fmriprep.org/en/stable/) derivatives.


## Installation


Install the development version from [GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("bbuchsbaum/bidser")
```
## Example

See https://bbuchsbaum.github.io/bidser/articles/quickstart.html
</file>

<file path="R/specs.R">
#' Given a match specification, generate a parser
#'
#' @param spec A specification object containing `keystruc` and `kinds` tables.
#'   `keystruc` defines the keys and their regex patterns, and `kinds` defines 
#'   the possible file types and suffixes.
#' @param typename The name given to the final type element. Default is "kind".
#' @keywords internal
gen_parser <- function(spec, typename = "kind") {
  # Check input
  if (!is.list(spec) || !all(c("keystruc", "kinds", "type") %in% names(spec))) {
    stop("`spec` must be a list containing 'keystruc', 'kinds', and 'type'.")
  }
  if (!is.data.frame(spec$keystruc) || !is.data.frame(spec$kinds)) {
    stop("`spec$keystruc` and `spec$kinds` must be data frames.")
  }
  if (!is.character(typename) || length(typename) != 1) {
    stop("`typename` must be a single character string.")
  }
  
  keystruc <- spec$keystruc
  
  # Construct key matchers from the specification
  keymatchers <- lapply(seq_len(nrow(keystruc)), function(i) {
    key <- keystruc$key[[i]]
    pat <- keystruc$pattern[[i]]
    opt <- keystruc$optional[[i]]
    nm  <- keystruc$name[[i]]
    
    if (i == 1) {
      # The first key is mandatory and at the start, so we use start_key
      start_key(key, pat)
    } else {
      # Subsequent keys can be optional or mandatory, or can be a zero_or_one_of variant
      if (is.null(pat)) {
        # This likely means a literal or zero_or_one_of scenario
        if (is.list(key)) {
          zero_or_one_of(unlist(key), nm)
        } else {
          optional_literal(key, nm)
        }
      } else {
        # Key has a pattern
        if (opt) {
          optional_key(key, pat)
        } else {
          mandatory_key(key, pat)
        }
      }
    }
  })
  
  # Construct type matchers for the kinds of files this spec supports
  # Each row in `kinds` defines a `kind` and its associated suffixes
  typematchers <- lapply(seq_len(nrow(spec$kinds)), function(i) {
    knd <- spec$kinds$kind[i]
    suf <- spec$kinds$suffix[i]
    
    if (is.list(suf)) {
      # Multiple possible suffixes
      lits <- lapply(unlist(suf), pLiteral)
      # Combine suffix literals into an alternative parser
      fun <- purrr::partial(pAlt, tag = function(x) x)
      pSeq(alt_extractor, pLiteral(knd), do.call(fun, lits))
    } else {
      # Single suffix
      pSeq(extractor, pLiteral(knd), pLiteral(suf))
    }
  })
  
  # Create a combined type matcher that starts with "_"
  p_alt <- purrr::partial(pAlt, tag = function(x) x)
  typematchers <- do.call(p_alt, typematchers)
  typematchers <- pSeq(function(x) x[[2]], pLiteral("_"), typematchers)
  
  # Combine key matchers and type matchers into one sequence
  filematcher <- c(keymatchers, list(typematchers))
  
  # A builder function to construct the output list from parsed values
  builder <- function(x) {
    out <- list()
    for (i in seq_len(nrow(spec$keystruc))) {
      nm  <- spec$keystruc$name[i]
      opt <- spec$keystruc$optional[i]
      
      if (i == 1) {
        # The first key is mandatory
        out[[nm]] <- x[[i]]
      } else if (opt) {
        out[[nm]] <- unlist(x[[i]]$value)
      } else {
        out[[nm]] <- x[[i]]
      }
    }
    
    # The type and suffix are after all keys
    index <- nrow(spec$keystruc) + 1
    out[[typename]] <- x[[index]]$type
    # Remove the leading "." from suffix if present
    out$suffix <- substring(x[[index]]$suffix, 2)
    out$type <- spec$type
    
    out
  }
  
  # Create the final parser
  pseq <- purrr::partial(pSeq, tag = builder)
  pout <- do.call(pseq, filematcher)
  pout
}


#' Create a spec table for "func" files
#'
#' The `spec` object describes pattern rules for matching BIDS filenames.
#' It consists of a `keystruc` table and a `kinds` table. The `keystruc` table 
#' defines keys, their regex patterns, their optionality, etc. The `kinds` table 
#' defines allowed file kinds and their suffixes.
#'
#' @keywords internal
func_spec <- function() {
  keystruc <- tibble::tribble(
    ~name,          ~key, ~optional, ~pattern,         ~order,
    "subid",        "sub", FALSE,    "[A-Za-z0-9]+",   1,
    "session",      "ses", TRUE,     "[A-Za-z0-9]+",   2,
    "task",         "task",FALSE,    "[A-Za-z0-9]+",   3,
    "acquisition",  "acq", TRUE,     "[A-Za-z0-9]+",   5,
    "contrast",     "ce",  TRUE,     "[A-Za-z0-9]+",   6,
    "reconstruction","rec",TRUE,     "[A-Za-z0-9]+",   7,
    "run",          "run", TRUE,     "[0-9]+",         4,
    "echo",         "echo",TRUE,     "[0-9]+",         8
  )
  
  kinds <- tibble::tribble(
    ~kind,    ~suffix,
    "bold",   list(".nii.gz",".nii", ".json"),
    "events", ".tsv",
    "sbref",  list(".nii.gz",".nii", ".json"),
    "physio", ".tsv"
  )
  
  ret <- list(keystruc = keystruc, kinds = kinds, type = "func")
  class(ret) <- c("func_spec", "parser_spec")
  ret
}


#' Create a spec table for "anat" files
#' @keywords internal
anat_spec <- function() {
  keystruc <- tibble::tribble(
    ~name,            ~key, ~optional, ~pattern,         ~order,
    "subid",          "sub",FALSE,    "[A-Za-z0-9]+",    1,
    "session",        "ses",TRUE,     "[A-Za-z0-9]+",    2,
    "acquisition",    "acq",TRUE,     "[A-Za-z0-9]+",    4,
    "contrast",       "ce", TRUE,     "[A-Za-z0-9]+",    5,
    "dir",            "dir",TRUE,     "[A-Za-z0-9]+",    6,
    "reconstruction", "rec",TRUE,     "[A-Za-z0-9]+",    7,
    "run",            "run",TRUE,     "[0-9]+",          3
  )
  
  kinds <- tibble::tribble(
    ~kind,       ~suffix,
    "defacemask", list(".nii.gz", ".nii", ".json"),
    "T1w",        list(".nii.gz", ".nii", ".json"),
    "T2w",        list(".nii.gz", ".nii", ".json"),
    "T1map",      list(".nii.gz", ".nii", ".json"),
    "T2map",      list(".nii.gz", ".nii", ".json"),
    "T2star",     list(".nii.gz", ".nii", ".json"),
    "FLAIR",      list(".nii.gz", ".nii", ".json"),
    "FLASH",      list(".nii.gz", ".nii", ".json"),
    "PDmap",      list(".nii.gz", ".nii", ".json"),
    "PDT2",       list(".nii.gz", ".nii", ".json"),
    "inplaneT1",  list(".nii.gz", ".nii", ".json"),
    "inplaneT2",  list(".nii.gz", ".nii", ".json"),
    "angio",       list(".nii.gz", ".nii", ".json")
  )
  
  ret <- list(keystruc = keystruc, kinds = kinds, type = "anat") 
 
  
  class(ret) <- c("anat_spec", "parser_spec")
  ret
}


#' Create a spec table for fMRIPrep "func" files
#' @keywords internal
funcprepspec <- function() {
  keystruc <- tibble::tribble(
    ~name,          ~key,     ~optional, ~pattern,       ~order,
    "subid",        "sub",    FALSE,    "[A-Za-z0-9]+",  1,
    "session",      "ses",    TRUE,     "[A-Za-z0-9]+",  2,
    "task",         "task",   FALSE,    "[A-Za-z0-9]+",  3,
    "acquisition",  "acq",    TRUE,     "[A-Za-z0-9]+",  5,
    "contrast",     "ce",     TRUE,     "[A-Za-z0-9]+",  6,
    "reconstruction","rec",   TRUE,     "[A-Za-z0-9]+",  6,
    "run",          "run",    TRUE,     "[a-z0-9]+",     4,
    "echo",         "echo",   TRUE,     "[0-9]+",        6,
    "modality",     "bold",   TRUE,     NULL,            8,
    "space",        "space",  TRUE,     "[A-Za-z0-9]+",  9,
    "res",          "res",    TRUE,     "[A-Za-z0-9]+", 10,
    "desc",         "desc",   TRUE,     "[A-Za-z0-9]+", 11,
    "label",        "label",  TRUE,     "[A-Za-z0-9]+", 12,
    "variant",      "variant",TRUE,     "[A-Za-z0-9]+", 14
  )
  
  kinds <- tibble::tribble(
    ~kind,         ~suffix,
    "roi",         list(".nii.gz", ".nii", ".json"),
    "regressors",  ".tsv",
    "latent",      ".lv.h5",
    "preproc",     list(".nii.gz", ".nii", ".json"),
    "bold",        list(".nii.gz", ".nii", ".json", ".lv.h5"),
    "brainmask",   list(".nii.gz", ".nii", ".json"),
    "mask",        list(".nii.gz", ".nii", ".json"),
    "confounds",   ".tsv",
    "timeseries",  ".tsv",
    "MELODICmix",  ".tsv",
    "mixing",      ".tsv",
    "AROMAnoiseICs",".tsv"
  )
  
  ret <- list(keystruc = keystruc, kinds = kinds, type = "funcprep")
  class(ret) <- c("funcprep_spec", "parser_spec")
  ret
}


#' Create a spec table for fMRIPrep "anat" files
#' @keywords internal
anatprepspec <- function() {
  anat_types <- c("defacemask","T1w", "T2w","T1map", "T2map", "T2star","FLAIR", "FLASH", "PDmap","PD","PDT2",
                  "inplaneT1", "inplaneT2", "angio")
  
  keystruc <- tibble::tribble(
    ~name,           ~key,      ~optional, ~pattern,        ~order,
    "subid",         "sub",     FALSE,    "[A-Za-z0-9]+",   1,
    "session",       "ses",     TRUE,     "[A-Za-z0-9]+",   2,
    "acquisition",   "acq",     TRUE,     "[A-Za-z0-9]+",   4,
    "from",          "from",    TRUE,     "[A-Za-z0-9]+",   4,
    "to",            "to",      TRUE,     "[A-Za-z0-9]+",   5,
    "contrast",      "ce",      TRUE,     "[A-Za-z0-9]+",   5,
    "dir",           "dir",     TRUE,     "[A-Za-z0-9]+",   6,
    "reconstruction","rec",     TRUE,     "[A-Za-z0-9]+",   7,
    "run",           "run",     TRUE,     "[0-9]+",         3,
    "modality",      list(anat_types),TRUE, NULL,            8,
    "space",         "space",   TRUE,     "[A-Za-z0-9]+",   9,
    "label",         "label",   TRUE,     "[A-Za-z0-9]+",  10,
    "desc",          "desc",    TRUE,     "[A-Za-z0-9]+",  11,
    "mode",          "mode",    TRUE,     "[A-Za-z0-9]+",  11,
    "target",        "target",  TRUE,     "[A-Za-z0-9]+",  12,
    "class",         "class",   TRUE,     "[A-Za-z0-9]+",  13,
    "mod",           "mod",     TRUE,     "[A-Za-z0-9]+",  14
  )
  
  kinds <- tibble::tribble(
    ~kind,         ~suffix,
    "preproc",     list(".nii.gz", ".nii", ".json"),
    "brainmask",   list(".nii.gz", ".nii", ".json"),
    "probtissue",  list(".nii.gz", ".nii", ".json"),
    "mask",        list(".nii.gz", ".nii", ".json"),
    "T1w",         list(".nii.gz", ".nii", ".json"),
    "probseg",     list(".nii.gz", ".nii", ".json"),
    "dtissue",     list(".nii.gz", ".nii", ".json"),
    "dseg",        list(".nii.gz", ".nii", ".json"),
    "warp",        ".h5",
    "xfm",         c(".txt", ".h5"),
    "inflated.L.surf", ".gii",
    "inflated.R.surf", ".gii",
    "midthickness.L.surf", ".gii",
    "midthickness.R.surf", ".gii",
    "pial.L.surf", ".gii",
    "pial.R.surf", ".gii",
    "smoothwm.L.surf", ".gii",
    "smoothwm.R.surf", ".gii",
    "roi",         list(".nii.gz", ".nii", ".json"),
    "affine",      ".txt"
  )
  
  ret <- list(keystruc = keystruc, kinds = kinds, type = "anatprep")
  class(ret) <- c("anatprep_spec", "parser_spec")
  ret
}


#' Create a spec table for fieldmap files
#' @keywords internal
fmapspec <- function() {
  keystruc <- tibble::tribble(
    ~name,            ~key, ~optional, ~pattern,         ~order,
    "subid",          "sub",FALSE,    "[A-Za-z0-9]+",    1,
    "session",        "ses",TRUE,     "[A-Za-z0-9]+",    2,
    "acquisition",    "acq",TRUE,     "[A-Za-z0-9]+",    4,
    "contrast",       "ce", TRUE,     "[A-Za-z0-9]+",    5,
    "dir",            "dir",TRUE,     "[A-Za-z0-9]+",    6,
    "reconstruction", "rec",TRUE,     "[A-Za-z0-9]+",    7,
    "run",            "run",TRUE,     "[0-9]+",          8,
    "mod",            "mod",TRUE,     "[A-Za-z0-9]+",    9
  )
  
  kinds <- tibble::tribble(
    ~kind,       ~suffix,
    "magnitude",  list(".nii.gz", ".nii", ".json"),
    "magnitude1", list(".nii.gz", ".nii", ".json"),
    "magnitude2", list(".nii.gz", ".nii", ".json"),
    "phase",      list(".nii.gz", ".nii", ".json"),
    "phase1",     list(".nii.gz", ".nii", ".json"),
    "phase2",     list(".nii.gz", ".nii", ".json"),
    "phasediff",  list(".nii.gz", ".nii", ".json")
  )
  
  ret <- list(keystruc = keystruc, kinds = kinds, type = "fmap")
  class(ret) <- c("fmap_spec", "parser_spec")
  ret
}
</file>

<file path="tests/testthat/test_parse.R">
context("parser")
test_that("can parse various file types", {
  expect_type(encode("sub-2001_T1w_brainmask.nii.gz"), "list")
  expect_type(encode("sub-2001_T1w_class-CSF_probtissue.nii.gz"), "list")
  expect_type(encode("sub-2001_T1w_class-GM_probtissue.nii.gz"), "list")
  expect_type(encode("sub-2001_T1w_class-WM_probtissue.nii.gz"), "list")
  expect_type(encode("sub-2001_T1w_dtissue.nii.gz"), "list")
  expect_type(encode("sub-2001_T1w_inflated.L.surf.gii"), "list")
  expect_type(encode("sub-2001_T1w_inflated.R.surf.gii"), "list")
  expect_type(encode("sub-2001_T1w_label-aparcaseg_roi.nii.gz"), "list")		
  expect_type(encode("sub-2001_T1w_label-aseg_roi.nii.gz"), "list")		
  expect_type(encode("sub-2001_T1w_midthickness.L.surf.gii"), "list")	
  expect_type(encode("sub-2001_T1w_midthickness.R.surf.gii"), "list")	
  expect_type(encode("sub-2001_T1w_pial.L.surf.gii"), "list")	
  expect_type(encode("sub-2001_T1w_pial.R.surf.gii"), "list")
  
  expect_type(encode("sub-2001_T1w_preproc.nii.gz"), "list")
  expect_type(encode("sub-2001_T1w_smoothwm.R.surf.gii"), "list")
  expect_type(encode("sub-2001_T1w_space-MNI152NLin2009cAsym_brainmask.nii.gz"), "list")
  expect_type(encode("sub-2001_T1w_space-MNI152NLin2009cAsym_class-CSF_probtissue.nii.gz"), "list")
  expect_type(encode("sub-2001_T1w_space-MNI152NLin2009cAsym_class-GM_probtissue.nii.gz"), "list")
  #expect_type(encode("sub-2001_T1w_space-MNI152NLin2009cAsym_class-GM_probtissue_small.nii.gz"), "list")
  expect_type(encode("sub-2001_T1w_space-MNI152NLin2009cAsym_class-WM_probtissue.nii.gz"), "list")
  expect_type(encode("sub-2001_T1w_preproc.nii.gz"), "list")
  
  expect_type(encode("sub-2001_T1w_target-fsnative_affine.txt"), "list")
  expect_type(encode("sub-2001_T1w_target-MNI152NLin2009cAsym_warp.h5"), "list")
  expect_type(encode("sub-2001_T1w_space-MNI152NLin2009cAsym_target-T1w_warp.h5"), "list")
  expect_type(encode("sub-2001_T1w_space-orig_target-T1w_affine.txt"), "list")
  expect_type(encode("sub-2001_T1w_space-MNI152NLin2009cAsym_preproc.nii.gz"), "list")
  expect_type(encode("sub-2001_T1w_space-MNI152NLin2009cAsym_dtissue.nii.gz"), "list")
  expect_type(encode("sub-1006_task-phoneme_run-all_bold_space-MNI152NLin2009cAsym_latent.lv.h5"), "list")
  expect_type(encode("sub-1006_task-phoneme_run-all_bold_space-MNI152NLin2009cAsym_desc-junk_latent.lv.h5"), "list")
  expect_type(encode("sub-28_task-citizenfour_run-04_space-MNI152Lin_res-native_desc-brain_mask.nii.gz"), "list")
  expect_type(encode("sub-2001_task-test_confounds.tsv"), "list")
  expect_type(encode("sub-2001_ses-01_task-test_run-01_bold_space-MNI152NLin2009cAsym_preproc.nii.gz"), "list")
  expect_type(encode("sub-2001_ses-01_task-test_run-01_bold_space-MNI152NLin2009cAsym_variant-smoothAROMAnonaggr_preproc.nii.gz"), "list")
  expect_type(encode("sub-2001_task-test_run-01_bold_MELODICmix.tsv"), "list")
  expect_type(encode("sub-2001_task-test_run-01_bold_AROMAnoiseICs.tsv"), "list")
  expect_type(encode("sub-1001_task-dae_run-all_space-MNI152Lin_res-native_desc-latent_bold.lv.h5"), "list")
  expect_type(encode("sub-2001_task-alice_echo-2_bold.nii.gz"), "list")
  expect_type(encode("sub-2001_task-alice_echo-2_space-hello_res-2_desc-preproc_bold.nii.gz"), "list")
  
  #expect_type(encode("sub-2001_task-test_run-01_bold_AROMAnoiseICs.csv"), "list")
  
  #BIDS 1.6.0 conventions
  expect_type(encode("sub-01_task-test_desc-confounds_timeseries.tsv"), "list")
  expect_type(encode("sub-2001_task-test_run-01_desc-MELODIC_mixing.tsv"), "list")
  
  expect_type(encode("sub-01_ses-01_task-test_run-01_echo-01_bold.nii.gz"), "list")
  expect_type(encode("sub-01_task-test_desc-preproc_bold.nii.gz"), "list")
  expect_type(encode("sub-01_task-test_run-01_desc-preproc_bold.nii.gz"), "list")
  expect_type(encode("sub-01_ses-01_task-test_run-01_desc-preproc_bold.nii.gz"), "list")
  expect_type(encode("sub-01_ses-01_task-test_run-01_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz"), "list")
  expect_type(encode("sub-sid000009_task-movie_run-03_space-MNI152Lin_res-native_desc-preproc_bold.nii.gz"), "list")
})


# sub-2001_T1w_brainmask.nii.gz						sub-2001_T1w_smoothwm.R.surf.gii
# sub-2001_T1w_class-CSF_probtissue.nii.gz				sub-2001_T1w_space-MNI152NLin2009cAsym_brainmask.nii.gz
# sub-2001_T1w_class-GM_probtissue.nii.gz					sub-2001_T1w_space-MNI152NLin2009cAsym_class-CSF_probtissue.nii.gz
# sub-2001_T1w_class-WM_probtissue.nii.gz					sub-2001_T1w_space-MNI152NLin2009cAsym_class-GM_probtissue.nii.gz
# sub-2001_T1w_dtissue.nii.gz						sub-2001_T1w_space-MNI152NLin2009cAsym_class-GM_probtissue_small.nii.gz
# sub-2001_T1w_inflated.L.surf.gii					sub-2001_T1w_space-MNI152NLin2009cAsym_class-WM_probtissue.nii.gz
# sub-2001_T1w_inflated.R.surf.gii					sub-2001_T1w_space-MNI152NLin2009cAsym_dtissue.nii.gz
# sub-2001_T1w_label-aparcaseg_roi.nii.gz					sub-2001_T1w_space-MNI152NLin2009cAsym_label-aparcaseg_roi.nii.gz
# sub-2001_T1w_label-aseg_roi.nii.gz					sub-2001_T1w_space-MNI152NLin2009cAsym_preproc.nii.gz
# sub-2001_T1w_midthickness.L.surf.gii					sub-2001_T1w_space-MNI152NLin2009cAsym_target-T1w_warp.h5
# sub-2001_T1w_midthickness.R.surf.gii					sub-2001_T1w_space-orig_target-T1w_affine.txt
# sub-2001_T1w_pial.L.surf.gii						sub-2001_T1w_target-MNI152NLin2009cAsym_warp.h5
# sub-2001_T1w_pial.R.surf.gii						sub-2001_T1w_target-fsnative_affine.txt
# sub-2001_T1w_preproc.nii.gz
</file>

<file path="DESCRIPTION">
Package: bidser
Version: 0.0.0.9000
Title: Work with BIDS projects
Description: Tools for working with Brain Imaging Data Structure (BIDS) formatted neuroimaging datasets.
    The package provides functionality for reading, validating, and querying BIDS-compliant 
    projects, creating mock BIDS datasets for testing, and extracting preprocessed data from 
    BIDS derivatives. It supports searching and filtering BIDS files by various entities
    such as subject, session, task, and run to streamline neuroimaging data workflow.
Authors@R: person("Bradley", "Buchsbaum", , "brad.buchsbaum@gmail.com", c("aut", "cre"))
License: MIT + file LICENSE
Encoding: UTF-8
LazyData: true
ByteCompile: true
Roxygen: list(markdown = TRUE)
RoxygenNote: 7.3.2.9000
Imports:
  stringr,
  data.tree,
  Combin8R,
  neuroim2,
  progress,
  tidyselect,
  dplyr,
  ggplot2,
  scales,
  plotly,
  patchwork,
  viridis,
  assertthat,
  crayon,
  fs,
  jsonlite,
  magrittr, 
  readr,
  rlang,
  stringdist,
  tibble,
  tidyr
Remotes: 
  SWotherspoon/Combin8R,
  bbuchsbaum/neuroim2
Suggests: 
    knitr,
    rmarkdown,
    testthat,
    covr,
    gluedown
VignetteBuilder: knitr
</file>

<file path="R/matchers.R">
#' @importFrom Combin8R pSeq pLiteral pRegex pAlt pMany
NULL


#' Create a parser for a generic BIDS file
#'
#' This parser tries to match against various known parsers (anat, func, fmriprep anat/func).
#' @keywords internal
bids_parser <- function() {
  parser <- pAlt(
    "bids_generic",
    anat_parser()$parser,
    func_parser()$parser,
    fmriprep_anat_parser()$parser,
    fmriprep_func_parser()$parser
  )
  
  ret <- list(parser = parser)
  class(ret) <- c("bids_parser", "parser")
  ret
}

#' @export
parse.parser <- function(x, fname) {
  if (!is.list(x) || !"parser" %in% class(x)) {
    stop("`x` must be a valid parser object.")
  }
  if (!is.character(fname) || length(fname) != 1) {
    stop("`fname` must be a single character string (a filename).")
  }
  x$parser(fname)
}

#' Functional parser constructor
#'
#' @keywords internal
func_parser <- function() {
  spec <- func_spec()
  parser <- gen_parser(spec)
  ret <- list(parser = parser)
  class(ret) <- c("func_parser", "parser")
  ret
}

#' Anatomical parser constructor
#'
#' @keywords internal
anat_parser <- function() {
  spec <- anat_spec()
  parser <- gen_parser(spec)
  ret <- list(parser = parser)
  class(ret) <- c("anat_parser", "parser")
  ret
}

#' fMRIPrep anatomical parser constructor
#'
#' @keywords internal
fmriprep_anat_parser <- function() {
  spec <- anatprepspec()
  parser <- gen_parser(spec)
  ret <- list(parser = parser)
  class(ret) <- c("anatprep_parser", "parser")
  ret
}

#' fMRIPrep functional parser constructor
#'
#' @keywords internal
fmriprep_func_parser <- function() {
  spec <- funcprepspec()
  parser <- gen_parser(spec)
  ret <- list(parser = parser)
  class(ret) <- c("funcprep_parser", "parser")
  ret
}

#' Fieldmap parser constructor
#'
#' @keywords internal
fmap_parser <- function() {
  spec <- fmapspec()
  parser <- gen_parser(spec)
  ret <- list(parser = parser)
  class(ret) <- c("fmap_parser", "parser")
  ret
}
</file>

<file path="R/all_generic.R">
#' Parse a file-name into BIDS components
#'
#' This generic function parses a BIDS filename into its component parts.
#' It uses a parser combinator approach to match the filename against known BIDS patterns
#' and extract relevant metadata such as subject ID, session, task, run, and modality.
#'
#' @param x the parser object to use for parsing
#' @param fname the string (filename) to parse
#' @param ... extra args passed to methods
#' @return A parsed representation of the BIDS filename, typically a list with extracted components
#' @export
#' @rdname parse-method
#' @examples
#' # Parse an anatomical file
#' parser <- anat_parser()
#' parse(parser, "sub-01_T1w.nii.gz")
#' 
#' # Parse a functional file
#' parser <- func_parser()
#' parse(parser, "sub-01_task-rest_run-01_bold.nii.gz")
#' 
#' # Use the generic BIDS parser
#' parser <- bids_parser()
#' parse(parser, "sub-01_ses-pre_task-rest_run-01_bold.nii.gz")
parse <- function (x, fname,...) {
  UseMethod("parse", x)
}

#' Encode a string into a BIDS key-value list
#'
#' This function parses a BIDS filename and extracts its components into a key-value list.
#' It understands standard BIDS entities like subject, session, task, run, etc.
#'
#' @param x The string (filename) to encode
#' @param ... Additional arguments passed to methods
#' @return A list of key-value pairs extracted from the filename
#' @export
#' @examples
#' # Encode an anatomical file
#' encode("sub-01_T1w.nii.gz")
#'
#' # Encode a functional file
#' encode("sub-01_task-rest_run-01_bold.nii.gz")
#'
#' # Encode a file with session information
#' encode("sub-01_ses-pre_task-rest_run-01_bold.nii.gz")
encode <- function(x, ...) {
  UseMethod("encode")
}


#' Decode a key-value list into a string
#' 
#' @param x the list to decode
#' @param ... extra args
#' @noRd
decode <- function(x,...) {
  UseMethod("decode")
}


#' Get sessions from a BIDS project
#' 
#' This function retrieves a vector of session IDs from a BIDS project.
#' Sessions in BIDS are typically represented as directories named 'ses-XX'
#' within subject directories. This function extracts and returns the unique
#' session identifiers.
#' 
#' @param x the object to extract sessions from
#' @param ... extra args passed to methods
#' @return A character vector of unique session IDs if the project has sessions,
#'   or NULL if the project does not have sessions
#' @export
#' @rdname sessions-method
#' @examples 
#' # Get sessions from a BIDS project
#' p <- system.file("extdata/ds001", package="bidser")
#' sessions(bids_project(p))
#' 
#' # Create a BIDS structure with sessions and check them
#' bs <- bids_structure(name="Test", subjects=c("01", "02"), 
#'                     sessions=c("pre", "post"))
#' sessions(bs)
sessions <- function (x, ...) {
  UseMethod("sessions", x)
}


#' Get tasks from a BIDS project
#' 
#' This function retrieves a sorted vector of unique task names from a BIDS project.
#' Tasks in BIDS are typically represented in filenames with the pattern 'task-XX'.
#' This function extracts and returns the unique task identifiers, filtering out
#' any NULL or NA values.
#' 
#' @param x the object to extract tasks from
#' @param ... extra args passed to methods
#' @return A character vector of unique, sorted task names found in the BIDS project
#' @export
#' @rdname tasks-method
#' @examples 
#' # Get tasks from a BIDS project
#' p <- system.file("extdata/ds001", package="bidser")
#' tasks(bids_project(p))
#' 
#' # Create a BIDS structure with specific tasks and check them
#' bs <- bids_structure(name="Test", subjects=c("01", "02"), 
#'                     tasks=c("rest", "memory", "working"))
#' tasks(bs)
tasks <- function (x, ...) {
  UseMethod("tasks", x)
}

#' Get "flat" representation of BIDS Project
#' 
#' This function returns a flattened (non-hierarchical) representation of a BIDS project
#' formatted as a data frame. It extracts file paths or file names from the BIDS tree
#' structure, filtering for entries that start with "sub-" to focus on subject-level data.
#' 
#' @param x the `bids_project` object
#' @param full_path If TRUE, return full paths to files; if FALSE, return just file names (default: TRUE)
#' @param ... extra args passed to methods
#' 
#' @return A data frame containing either full paths to files (if `full_path=TRUE`) or 
#'   just the file names (if `full_path=FALSE`). Each row represents one file in the BIDS project.
#' @export
#' @rdname flat_list-method
#' @examples 
#' # Get flat representation with full paths
#' p <- system.file("extdata/ds001", package="bidser")
#' flat_list(bids_project(p))
#' 
#' # Get flat representation with just file names
#' flat_list(bids_project(p), full_path=FALSE)
#' 
#' # Create a BIDS structure and get its flat representation
#' bs <- bids_structure(name="Test", subjects=c("01", "02"))
#' flat_list(bs)
flat_list <- function(x, ...) {
  UseMethod("flat_list", x)
}

#' Get participants from a BIDS project
#' 
#' This function retrieves a vector of unique participant IDs from a BIDS project.
#' It extracts the subject identifiers from the project's data table, filtering out
#' any NA values. Participant IDs in BIDS typically follow the format 'sub-XX'.
#' 
#' @param x the `bids_project` object
#' @param ... extra args passed to methods
#' 
#' @return A character vector of unique participant IDs found in the BIDS project.
#'   If no participants are found or the 'subid' column doesn't exist in the project's
#'   data table, returns an empty character vector.
#' @export
#' @rdname participants-method
#' @examples 
#' # Get participants from a BIDS project
#' p <- system.file("extdata/ds001", package="bidser")
#' participants(bids_project(p))
#' 
#' # Create a BIDS structure with specific participants and check them
#' bs <- bids_structure(name="Test", subjects=c("01", "02", "03"))
#' participants(bs)
participants <- function (x, ...) {
  UseMethod("participants", x)
}

#' Get event files from a BIDS project
#' 
#' This function retrieves a vector of event files (events.tsv) from a BIDS project
#' that match specified criteria. Event files in BIDS contain trial information for
#' task-based functional MRI data, including onset times, durations, and trial types.
#' 
#' @param x the `bids_project` object
#' @param ... extra args passed to methods, including:
#'   \itemize{
#'     \item{subid}{Regex to match subject IDs (default: ".*")}
#'     \item{task}{Regex to match tasks (default: ".*")}
#'     \item{run}{Regex to match runs (default: ".*")}
#'     \item{session}{Regex to match sessions (default: ".*")}
#'     \item{full_path}{If TRUE, return full paths of files (default: TRUE)}
#'   }
#' 
#' @return A character vector of file paths to event files matching the specified criteria.
#'   If no matching files are found, returns NULL.
#' @export
#' @rdname event_files-method
#' @examples 
#' # Get all event files from a BIDS project
#' p <- system.file("extdata/ds001", package="bidser")
#' event_files(bids_project(p))
#' 
#' # Get event files for specific subjects and tasks
#' p <- system.file("extdata/ds001", package="bidser")
#' event_files(bids_project(p), subid="sub-0[12]", task="balloonanalog")
#' 
#' # Create a BIDS structure and check for event files
#' bs <- bids_structure(name="Test", subjects=c("01", "02"), 
#'                     tasks=c("rest", "memory"))
#' event_files(bs)
event_files <- function (x, ...) {
  UseMethod("event_files", x)
}

#' Get confound files from a BIDS project
#' 
#' This function retrieves a vector of confound files from a BIDS project that match 
#' specified criteria. Confound files in BIDS derivatives (typically from fMRIPrep) 
#' contain nuisance variables that can be used for denoising fMRI data, such as 
#' motion parameters, physiological signals, and other noise components.
#' 
#' @param x the `bids_project` object
#' @param ... extra args passed to methods, including:
#'   \itemize{
#'     \item{subid}{Regex to match subject IDs (default: ".*")}
#'     \item{task}{Regex to match tasks (default: ".*")}
#'     \item{session}{Regex to match sessions (default: ".*")}
#'     \item{nest}{If TRUE, results are nested by subject/session/run (default: TRUE)}
#'   }
#' 
#' @return A character vector of file paths to confound files matching the specified criteria.
#'   If no matching files are found, returns NULL.
#' @export
#' @rdname confound_files-method
#' @examples 
#' # Get all confound files from a BIDS project with fMRIPrep derivatives
#' p <- system.file("extdata/phoneme_stripped", package="bidser")
#' proj <- bids_project(p, fmriprep=TRUE)
#' confound_files(proj)
#' 
#' # Get confound files for specific subjects and tasks
#' confound_files(proj, subid="sub-01", task="phoneme")
#' 
#' # Create a BIDS structure with fMRIPrep and check for confound files
#' bs <- bids_structure(name="Test", subjects=c("01", "02"), 
#'                     tasks=c("rest"), include_fmriprep=TRUE)
#' confound_files(bs)
confound_files <- function (x, ...) {
  UseMethod("confound_files", x)
}

#' Read Event Files from a BIDS Project
#'
#' This generic function reads and nests event files from a BIDS project. Event files
#' contain timing information about task events, conditions, and responses during
#' functional MRI scans. The function can filter events by subject and task, and
#' returns a nested tibble for easy data manipulation.
#'
#' @param x The object to read events from (typically a `bids_project`).
#' @param ... Additional arguments passed to methods.
#'
#' @return A nested tibble with columns:
#'   - `.task`: Task name
#'   - `.run`: Run number
#'   - `.subid`: Subject ID
#'   - `data`: Nested column containing the event data
#'   If no matching data is found, returns an empty tibble with appropriate columns.
#'
#' @examples
#' # Create a BIDS project
#' ds001_path <- system.file("extdata/ds001", package="bidser")
#' proj <- bids_project(ds001_path)
#'
#' # Read all event files
#' all_events <- read_events(proj)
#'
#' # Read events for specific subjects
#' sub_events <- read_events(proj, subid="0[123]")
#'
#' # Read events for a specific task
#' task_events <- read_events(proj, task="balloonanalogrisktask")
#'
#' # Combine multiple filters
#' filtered_events <- read_events(proj,
#'                               subid="01",
#'                               task="balloonanalogrisktask")
#'
#' # Access nested data
#' if (nrow(filtered_events) > 0) {
#'   first_run <- filtered_events$data[[1]]
#'   print(head(first_run))
#' }
#'
#' @export
read_events <- function(x, ...) {
  UseMethod("read_events")
}


#' Read Confound Files from a BIDS Project
#'
#' This function reads in fMRIPrep confound tables for one or more subjects from a
#' BIDS project. Confound files contain nuisance variables that can be used for
#' denoising fMRI data, such as motion parameters, physiological signals, and other
#' noise components. The function can optionally perform PCA reduction on the confounds
#' and return either nested or flat tibbles.
#'
#' @param x The object to read confounds from (typically a `bids_project`).
#' @param ... Additional arguments passed to methods, including:
#'   - `subid`: Regex to match subject IDs (default: ".*")
#'   - `task`: Regex to match tasks (default: ".*")
#'   - `session`: Regex to match sessions (default: ".*")
#'   - `run`: Regex to match runs (default: ".*")
#'   - `cvars`: Character vector of confound variable names to select
#'   - `npcs`: Integer. Perform PCA reduction and return this many PCs
#'   - `perc_var`: Numeric. Perform PCA reduction to retain this percentage of variance
#'   - `nest`: Logical. If TRUE, nests confound tables by subject/session/run (default: TRUE)
#'
#' @return A tibble containing confound data. If `nest=TRUE` (default), returns a
#'   nested tibble with columns for subject, session, run, and a nested `data` column
#'   containing the confound variables. If `nest=FALSE`, returns a flat tibble with
#'   all confound variables. Returns NULL if no matching files are found.
#'
#' @examples
#' # Create a BIDS project with fMRIPrep derivatives
#' fmriprep_path <- system.file("extdata/phoneme_stripped", package="bidser")
#' proj <- bids_project(fmriprep_path, fmriprep=TRUE)
#'
#' # Read all confound files
#' all_conf <- read_confounds(proj)
#'
#' # Read confounds for specific subjects and tasks
#' sub_conf <- read_confounds(proj,
#'                           subid="01",
#'                           task="phoneme")
#'
#' # Select specific confound variables
#' motion_conf <- read_confounds(proj,
#'                              cvars=c("framewise_displacement",
#'                                     "trans_x", "trans_y", "trans_z",
#'                                     "rot_x", "rot_y", "rot_z"))
#'
#' # Perform PCA reduction
#' pca_conf <- read_confounds(proj, npcs=5)
#'
#' # Get confounds as a flat tibble
#' flat_conf <- read_confounds(proj, nest=FALSE)
#'
#' # Combine multiple options
#' custom_conf <- read_confounds(proj,
#'                              subid="01",
#'                              task="phoneme",
#'                              cvars=c("framewise_displacement",
#'                                     "trans_x", "trans_y", "trans_z"),
#'                              npcs=3,
#'                              nest=FALSE)
#'
#' @export
read_confounds <- function(x, ...) {
  UseMethod("read_confounds")
}



#' Get functional scans from a BIDS project
#'
#' This function extracts functional scan files from a BIDS project that match specified
#' criteria such as subject ID, task name, run number, and session. It can return either
#' full paths or relative paths to the files.
#'
#' @param x A \code{bids_project} object.
#' @param ... Additional arguments passed to methods, including:
#'   - `subid`: Regex pattern to match subject IDs (default: ".*")
#'   - `task`: Regex pattern to match tasks (default: ".*")
#'   - `run`: Regex pattern to match runs (default: ".*")
#'   - `session`: Regex pattern to match sessions (default: ".*")
#'   - `kind`: Type of functional data (default: "bold")
#'   - `full_path`: Whether to return full file paths (default: TRUE)
#'
#' @return A character vector of file paths to functional scans matching the criteria.
#'   Returns NULL if no matching files are found.
#'
#' @examples
#' # Create a BIDS project object
#' proj <- bids_project(system.file("extdata/ds001", package="bidser"))
#'
#' # Get all functional scans
#' all_scans <- func_scans(proj)
#'
#' # Get scans for specific subjects
#' sub_scans <- func_scans(proj, subid="sub-0[123]")
#'
#' # Get scans for a specific task and run
#' task_scans <- func_scans(proj, 
#'                         task="balloonanalogrisktask",
#'                         run="01")
#'
#' # Get scans with relative paths
#' rel_scans <- func_scans(proj, full_path=FALSE)
#'
#' # Get scans from a project with sessions
#' ds007 <- bids_project(system.file("extdata/ds007", package="bidser"))
#' session_scans <- func_scans(ds007, session="test")
#'
#' @export
func_scans <- function(x, ...) {
  UseMethod("func_scans", x)
}

#' Get preprocessed functional MRI scans
#' 
#' This function retrieves paths to preprocessed functional MRI scans from a BIDS project.
#' It searches for files in the fMRIPrep derivatives directory that match specified criteria,
#' such as subject ID, task, run, and other BIDS metadata. Preprocessed scans are identified
#' by having either 'desc-preproc' or 'kind-preproc' in their filename.
#' 
#' @param x A \code{bids_project} object
#' @param subid Subject ID regex to match specific subjects (default: ".*" for all subjects)
#' @param task Task regex to match specific tasks (default: ".*" for all tasks)
#' @param run Run regex to match specific runs (default: ".*" for all runs)
#' @param variant Preprocessing variant to match (default: NULL, which matches files without a variant)
#' @param space Space regex to match specific spaces (default: ".*" for all spaces)
#' @param session Session regex to match specific sessions (default: ".*" for all sessions)
#' @param modality Image modality to match (default: "bold" for functional MRI)
#' @param kind Kind regex to match specific kinds (default: ".*" for all kinds)
#' @param full_path If TRUE, return full file paths; if FALSE, return paths relative to the project root (default: FALSE)
#' @param ... Additional arguments passed to internal functions
#' 
#' @return A character vector of file paths to preprocessed functional scans matching the criteria.
#'   If no matching files are found, returns NULL.
#' @export
#' @rdname preproc_scans-method
#' @examples
#' # Get all preprocessed scans from a BIDS project with fMRIPrep derivatives
#' \donttest{
#' # Load a BIDS project with fMRIPrep derivatives
#' proj <- bids_project("/path/to/bids/dataset", fmriprep=TRUE)
#' 
#' # Get all preprocessed scans
#' scans <- preproc_scans(proj)
#' 
#' # Get preprocessed scans for a specific subject
#' sub01_scans <- preproc_scans(proj, subid="01")
#' 
#' # Get preprocessed scans for a specific task and space
#' task_scans <- preproc_scans(proj, task="rest", space="MNI152NLin2009cAsym")
#' 
#' # Get preprocessed scans for a specific session (if the dataset has sessions)
#' session_scans <- preproc_scans(proj, session="01")
#' 
#' # Filter by multiple criteria
#' filtered_scans <- preproc_scans(proj, 
#'                                subid="01",
#'                                task="rest", 
#'                                run="01", 
#'                                space="MNI152NLin2009cAsym")
#' 
#' # Get full paths to preprocessed scans
#' full_paths <- preproc_scans(proj, full_path=TRUE)
#' }
preproc_scans <- function(x, ...) {
  UseMethod("preproc_scans", x)
}

#' Create a preprocessing mask from BIDS data
#'
#' @param x A bids_project object
#' @param subid A regular expression pattern to match subject IDs
#' @param thresh Threshold value for mask creation (default: 0.99)
#' @param ... Additional arguments passed to methods
#' @return A logical mask volume
#' @export
#' @examples
#' \donttest{
#' proj <- bids_project(system.file("extdata/phoneme_stripped", package="bidser"))
#' mask <- create_preproc_mask(proj, subid=".*")
#'
#' # Create mask for single subject
#' sub01_mask <- create_preproc_mask(proj, subid="01")
#'
#' # Create mask with different threshold
#' mask_thresh <- create_preproc_mask(proj, subid=".*", thresh=0.95)
#' }
create_preproc_mask <- function(x, subid, thresh=0.99, ...) {
  UseMethod("create_preproc_mask", x)
}

#' Search files in BIDS structure
#' 
#' This function searches for files in a BIDS project that match a specified pattern and
#' optional key-value criteria. It can be used to find files in both raw data and preprocessed
#' derivatives based on filename patterns and BIDS metadata.
#' 
#' @param x A \code{bids_project} object created by \code{bids_project()}.
#' @param regex A regular expression to match against filenames. Default is ".*" (all files).
#' @param full_path If TRUE, return full file paths. If FALSE, return paths relative to the project root.
#' @param strict If TRUE, require that all queried keys must exist in matched files.
#'        If FALSE, allow matches for files missing queried keys.
#' @param new Deprecated parameter. Should always be FALSE.
#' @param ... Additional key-value pairs to filter files (e.g., subid = "01", task = "wm").
#'        These are matched against the corresponding metadata in the BIDS files.
#' @return A character vector of file paths matching the criteria, or NULL if no matches found.
#' @export
#' @rdname search_files
#' @examples
#' # Search for event files in a BIDS dataset
#' proj <- bids_project(system.file("extdata/ds001", package="bidser"), fmriprep=FALSE)
#' event_files <- search_files(proj, regex="events\\.tsv$")
#' 
#' # Search with additional criteria
#' sub01_files <- search_files(proj, regex="bold\\.nii\\.gz$", subid="01", task="balloonanalogrisktask")
#' 
#' # Get full paths
#' full_paths <- search_files(proj, regex="events\\.tsv$", full_path=TRUE)
#' 
#' # Search with strict matching
#' strict_matches <- search_files(proj, regex="\\.tsv$", strict=TRUE, task="balloonanalogrisktask")
search_files <- function(x, ...) {
  UseMethod("search_files", x)
}

#' Load All Event Files
#' 
#' @description Searches for and reads event files (`events.tsv`) from a BIDS 
#' project, combining them into a single (potentially nested) tibble.
#' 
#' @param x A BIDS project object.
#' @param subid Regex to match subject IDs (default: ".*")
#' @param task Regex to match tasks (default: ".*")
#' @param run Regex to match runs (default: ".*")
#' @param session Regex to match sessions (default: ".*")
#' @param full_path If TRUE, return full paths of files (default: TRUE)
#' @param ... Additional arguments passed to methods
#' 
#' @return A tibble containing the combined event data.
#' @export
#' @rdname load_all_events-method
#' @examples
#' # Example with a bids_project (assuming events exist)
#' 
#' proj <- try(bids_project(system.file("extdata/ds001", package="bidser")))
#' if (!inherits(proj, "try-error")) {
#'   all_events <- load_all_events(proj)
#'   print(all_events)
#'   
#'   # Load specific subject/task
#'   sub01_events <- load_all_events(proj, subid="01", task="balloon")
#'   print(sub01_events)
#' }
#' 
load_all_events <- function(x, ...) {
  UseMethod("load_all_events")
}

#' Summarize a BIDS dataset
#'
#' @param x A bids_project object
#' @return A list containing summary statistics about the BIDS dataset
#' @export
#' @examples
#' proj <- bids_project(system.file("extdata/ds001", package="bidser"))
#' summary <- bids_summary(proj)
bids_summary <- function(x) {
  UseMethod("bids_summary")
}

#' Basic BIDS Compliance Checks
#'
#' @param x A bids_project object
#' @return A list with compliance check results
#' @export
#' @examples
#' proj <- bids_project(system.file("extdata/ds001", package="bidser"))
#' compliance <- bids_check_compliance(proj)
bids_check_compliance <- function(x) {
  UseMethod("bids_check_compliance")
}

#' @noRd
anomalies <- function(x, ...) {
  UseMethod("anomalies", x)
}

#' Get data matrix from dataset
#' 
#' Extract data matrix from various dataset types
#' 
#' @param x the dataset object
#' @param ... extra args
#' @noRd
get_data_matrix <- function(x, ...) {
  UseMethod("get_data_matrix")
}
</file>

<file path="R/bidsio.R">
#' Read in a set of four-dimensional functional scans
#'
#' @param x A \code{bids_project} object
#' @param mask A brain mask of type \code{LogicalNeuroVol}
#' @param mode The file mode: 'normal' for in-memory files or 'bigvec' for on-disk files
#' @param subid One or more subject IDs (regex)
#' @param task An optional task regex
#' @param run An optional run regex
#' @param modality The image modality (usually "bold")
#' @param ... Extra arguments passed to \code{neuroim2::read_vec}
#' @return An instance of type \code{NeuroVec}
#' @export
read_func_scans.bids_project <- function(x, mask, mode = c("normal", "bigvec"),
                                         subid="^sub-.*", task=".*", run = ".*", modality="bold", ...) {
  mode <- match.arg(mode)
  
  # Check required arguments
  if (!inherits(x, "bids_project")) {
    stop("`x` must be a `bids_project` object.")
  }
  if (is.null(mask)) {
    stop("`mask` cannot be NULL. Please provide a LogicalNeuroVol mask.")
  }
  
  fnames <- func_scans(x, subid=subid, task=task, run=run, modality=modality)
  if (length(fnames) == 0 || all(is.na(fnames))) {
    stop("No matching scans found for the given subject/task/run/modality criteria.")
  }
  
  if (!requireNamespace("neuroim2", quietly=TRUE)) {
    stop("Package `neuroim2` is required for `read_func_scans`.")
  }
  
  neuroim2::read_vec(fnames, mask=mask, mode=mode, ...)
}


#' Read preprocessed functional MRI scans from a BIDS project
#'
#' This function reads preprocessed functional MRI scans from a BIDS project's fMRIPrep
#' derivatives directory. It uses the \code{preproc_scans} function to locate the files
#' and then reads them into a \code{NeuroVec} object using the neuroim2 package. If a
#' mask is not provided, one will be automatically created from available brainmask files.
#'
#' @param x A \code{bids_project} object with fMRIPrep derivatives
#' @param mask A brain mask of type \code{LogicalNeuroVol}, or NULL (if NULL, a mask will be created automatically)
#' @param mode The file mode: 'normal' for in-memory files or 'bigvec' for on-disk files
#' @param subid Regular expression to match subject IDs (default: "^sub-.*" to match all subjects)
#' @param task Regular expression to match tasks (default: ".*" to match all tasks)
#' @param run Regular expression to match runs (default: ".*" to match all runs)
#' @param modality Image modality to match (default: "bold" for functional MRI)
#' @param ... Extra arguments passed to \code{neuroim2::read_vec}
#' 
#' @return An instance of type \code{NeuroVec} containing the preprocessed functional data.
#' 
#' @details
#' This function requires the \code{neuroim2} package to be installed. It will throw an
#' error if the package is not available or if fMRIPrep derivatives are not found in the
#' BIDS project. If no mask is provided, it will create one using the \code{create_preproc_mask}
#' function.
#'
#' @examples
#' \donttest{
#' # Load a BIDS project with fMRIPrep derivatives
#' proj <- bids_project("/path/to/bids/dataset", fmriprep=TRUE)
#'
#' # Read preprocessed scans for all subjects
#' # (mask will be created automatically)
#' all_scans <- read_preproc_scans(proj)
#'
#' # Read preprocessed scans for a specific subject
#' sub01_scans <- read_preproc_scans(proj, subid="01")
#'
#' # Read preprocessed scans for a specific task and run
#' task_scans <- read_preproc_scans(proj, 
#'                                 task="rest",
#'                                 run="01")
#'
#' # Specify mode for large datasets
#' bigvec_scans <- read_preproc_scans(proj, mode="bigvec")
#'
#' # Provide a custom mask
#' mask <- create_preproc_mask(proj, thresh=0.95)
#' masked_scans <- read_preproc_scans(proj, mask=mask)
#' }
#'
#' @export
read_preproc_scans.bids_project <- function(x, mask=NULL, mode = c("normal", "bigvec"),
                                            subid="^sub-.*", task=".*", run = ".*", modality="bold", ...) {
  mode <- match.arg(mode)
  
  if (!inherits(x, "bids_project")) {
    stop("`x` must be a `bids_project` object.")
  }
  
  if (!x$has_fmriprep) {
    stop("Fmriprep derivatives not found. Please run `bids_project()` with `fmriprep=TRUE` or ensure fmriprep data is present.")
  }
  
  fnames <- preproc_scans(x, subid=subid, task=task, run=run, modality=modality, full_path=TRUE)
  if (length(fnames) == 0 || all(is.na(fnames))) {
    stop("No matching preprocessed scans found for the given subject/task/run/modality criteria.")
  }
  
  # Create mask if not provided
  if (is.null(mask)) {
    mask <- create_preproc_mask(x, subid)
    if (is.null(mask) || all(mask == 0)) {
      stop("Could not create a valid mask from preprocessed scans.")
    }
  }
  
  if (!requireNamespace("neuroim2", quietly=TRUE)) {
    stop("Package `neuroim2` is required for `read_preproc_scans`.")
  }
  
  neuroim2::read_vec(fnames, mask=mask, mode=mode, ...)
}


#' Create a binary brain mask from preprocessed scans
#'
#' This function creates a binary brain mask from preprocessed functional scans in a BIDS project.
#' It searches for brainmask files in the fMRIPrep derivatives directory, reads them using the 
#' neuroim2 package, and averages them to create a single mask. The resulting mask can be used
#' for subsequent analyses with preprocessed functional data.
#'
#' @param x A \code{bids_project} object with fMRIPrep derivatives
#' @param subid Regular expression to match subject IDs (e.g., "01" for subject 01, ".*" for all subjects)
#' @param thresh Threshold value between 0 and 1 (default 0.99) - voxels with values below this threshold are excluded from the mask
#' @param ... Additional arguments passed to \code{search_files} for finding mask files
#'
#' @return A logical mask volume (\code{LogicalNeuroVol}) that can be used for subsequent analyses with preprocessed functional data.
#'
#' @details
#' The function works by finding all brainmask files that match the subject ID pattern,
#' reading them into memory, averaging them, and then thresholding the result to create
#' a binary mask. This is useful when you want to analyze multiple runs or subjects together
#' and need a common mask that covers the brain areas present in all scans.
#' 
#' The threshold parameter controls how conservative the mask is. Higher values (closer to 1)
#' result in a more conservative mask that includes only voxels that are consistently marked
#' as brain across all subjects/runs. Lower values create a more inclusive mask.
#'
#' @examples
#' \donttest{
#' # Load a BIDS project with fMRIPrep derivatives
#' proj <- bids_project("/path/to/bids/dataset", fmriprep=TRUE)
#'
#' # Create a mask for all subjects (conservative threshold)
#' all_subj_mask <- create_preproc_mask(proj, subid=".*")
#'
#' # Create a mask for a specific subject
#' sub01_mask <- create_preproc_mask(proj, subid="01")
#'
#' # Create a more inclusive mask with a lower threshold
#' inclusive_mask <- create_preproc_mask(proj, subid=".*", thresh=0.8)
#'
#' # Use additional search criteria
#' task_mask <- create_preproc_mask(proj, subid=".*", task="rest")
#' }
#'
#' @export
create_preproc_mask.bids_project <- function(x, subid, thresh=.99, ...) {
  if (!inherits(x, "bids_project")) {
    stop("`x` must be a `bids_project` object.")
  }
  
  if (!x$has_fmriprep) {
    stop("No fmriprep data available. Cannot create preproc mask.")
  }
  
  maskfiles <- search_files(x, subid=subid, deriv="brainmask", full_path=TRUE, ...)
  if (length(maskfiles) == 0) {
    stop("No brainmask files found matching the specified subject.")
  }
  
  if (!requireNamespace("neuroim2", quietly=TRUE)) {
    stop("Package `neuroim2` is required for `create_preproc_mask`.")
  }
  
  vols <- lapply(maskfiles, neuroim2::read_vol)
  if (length(vols) == 0) {
    stop("Could not read any mask volumes.")
  }
  
  avg <- Reduce("+", vols)/length(vols)
  avg[avg < thresh] <- 0
  as.logical(avg)
}


DEFAULT_CVARS <- c("CSF", "WhiteMatter", "GlobalSignal", "stdDVARS", "non.stdDVARS",
                   "vx.wisestdDVARS", "FramewiseDisplacement", "tCompCor00", "tCompCor01", "tCompCor02",
                   "tCompCor03", "tCompCor04", "tCompCor05", "aCompCor00", "aCompCor01",
                   "aCompCor02", "aCompCor03", "aCompCor04", "aCompCor05", "X", "Y", "Z",
                   "RotX", "RotY", "RotZ")

DEFAULT_CVARS2 <- c("csf", "white_matter", "global_signal", "std_dvars",
                    "framewise_displacement", "t_comp_cor_00", "t_comp_cor_01", "t_comp_cor_02",
                    "t_comp_cor_03", "t_comp_cor_04", "t_comp_cor_00", "a_comp_cor_00", "a_comp_cor_01",
                    "a_comp_cor_02" , "a_comp_cor_03", "a_comp_cor_04", "a_comp_cor_03", "trans_x", "trans_y", "trans_z",
                    "rot_x", "rot_y", "rot_z")


#' Locate confound files
#'
#' @param x A \code{bids_project} object
#' @param subid Subject ID regex
#' @param task Task regex
#' @param session Session regex
#' @param nest If TRUE, results are nested
#' @return A character vector of file paths
#' @export
confound_files.bids_project <- function(x, subid=".*", task=".*", session=".*", nest=TRUE) {
  if (!inherits(x, "bids_project")) {
    stop("`x` must be a `bids_project` object.")
  }
  
  # Check if project has fmriprep derivatives
  if (!x$has_fmriprep) {
    rlang::inform("Project does not have fmriprep derivatives enabled. Cannot search for confound files.")
    return(NULL)
  }
  
  # Search for confound files with different possible formats *within derivatives*
  fnames1 <- search_files(x, subid=subid, task=task, session=session, deriv="confounds", full_path=TRUE)
  fnames2 <- search_files(x, subid=subid, task=task, session=session, desc="confounds", full_path=TRUE)
  fnames3 <- search_files(x, subid=subid, task=task, session=session, kind="confounds", full_path=TRUE)
  
  # Also search for files with _confounds.tsv suffix pattern *within derivatives*
  fnames4 <- search_files(x, regex="_confounds\\.tsv$", subid=subid, task=task, session=session, full_path=TRUE)
  
  # Combine all results and remove duplicates
  found_files <- unique(c(fnames1, fnames2, fnames3, fnames4))
  
  if (length(found_files) == 0) {
    return(NULL)
  }
  
  return(found_files)
}


#' Read confound files
#'
#' Reads in fmriprep confound tables for one or more subjects.
#'
#' @param x A \code{bids_project} object
#' @param subid Subject ID regex
#' @param task Task regex
#' @param session Session regex
#' @param run Run regex
#' @param cvars The names of the confound variables to select. Defaults to \code{DEFAULT_CVARS}.
#' @param npcs Perform PCA reduction on confounds and return \code{npcs} PCs.
#' @param perc_var Perform PCA reduction to retain \code{perc_var}% variance.
#' @param nest If TRUE, nests confound tables by subject/session/run.
#' @import dplyr
#' @importFrom tidyr nest
#' @importFrom tidyselect any_of
#' @return A nested tibble (if nest=TRUE) or a flat tibble (if nest=FALSE) of confounds.
#' @export
read_confounds.bids_project <- function(x, subid=".*", task=".*", session=".*", run=".*",
                                        cvars=DEFAULT_CVARS, npcs=-1, perc_var=-1, nest=TRUE) {
  if (!inherits(x, "bids_project")) {
    stop("`x` must be a `bids_project` object.")
  }
  
  # Check participants
  sids <- participants(x)
  gidx <- grep(subid, sids)
  if (length(gidx) == 0) {
    stop("No matching participants found for regex: ", subid)
  }
  sids <- sids[gidx]
  
  ret <- lapply(sids, function(s) {
    # Use confound_files to get all possible confound files
    fnames <- confound_files(x, subid=paste0("^", as.character(s), "$"), task=task, session=session, nest=FALSE)
    
    # Filter by run if specified
    if (run != ".*") {
      fnames <- fnames[grepl(paste0("_run-", run), fnames)]
    }
    
    if (length(fnames) == 0) {
      # No confound files for this participant; return empty frame
      return(data.frame())
    }
    
    # Process each confound file
    dflist <- lapply(fnames, function(fn) {
      # Extract run and session from filename
      run_val <- stringr::str_match(fn, "_run-([0-9]+)")[1,2]
      sess_val <- stringr::str_match(fn, "_ses-([A-Za-z0-9]+)")[1,2]
      
      if (is.na(sess_val)) {
        sess_val <- "1"
      }
      
      # Read table
      dfx <- tryCatch({
        read.table(fn, header=TRUE, na.strings=c("NA", "n/a"), stringsAsFactors=FALSE)
      }, error=function(e) {
        warning("Unable to read file: ", fn, " Error: ", e$message)
        return(NULL)
      })
      
      if (is.null(dfx)) return(NULL)
      
      # Select requested confound columns
      dfx <- dfx %>% dplyr::select(any_of(cvars))
      
      # Process confounds if PCA requested
      if ((npcs > 0 || perc_var > 0) && ncol(dfx) > 1) {
        dfx <- process_confounds(dfx, npcs=npcs, perc_var=perc_var)
      }
      
      # Add identifying columns
      dfx %>%
        mutate(participant_id=s, run=run_val, session=sess_val)
    })
    
    # Filter out any NULL returns
    dflist <- dflist[!sapply(dflist, is.null)]
    if (length(dflist) == 0) return(data.frame())
    
    dplyr::bind_rows(dflist)
  })
  
  ret <- ret[!sapply(ret, function(z) nrow(z)==0)]
  if (length(ret) == 0) {
    message("No confound data found for the given selection.")
    return(NULL)
  }
  
  ret <- dplyr::bind_rows(ret)
  
  if (nest) {
    ret %>% dplyr::group_by(participant_id, run, session) %>% tidyr::nest()
  } else {
    ret
  }
}


#' @keywords internal
process_confounds <- function(dfx, center=TRUE, scale=TRUE, npcs=-1, perc_var=-1) {
  m <- as.matrix(dfx)
  # Impute NAs
  if (anyNA(m)) {
    m <- apply(m, 2, function(v) {
      mu <- median(v, na.rm=TRUE)
      v[is.na(v)] <- mu
      v
    })
  }
  
  sm <- scale(m, center=center, scale=scale)
  # If PCA requested
  if ((npcs > 0 || perc_var > 0) && ncol(sm) > 1) {
    pres <- prcomp(sm, scale.=FALSE)
    varexp <- cumsum(pres$sdev^2)/sum(pres$sdev^2) * 100
    
    # Determine how many PCs to keep
    if (npcs > 0 && perc_var <= 0) {
      # Use npcs directly
      keep_npcs <- min(npcs, ncol(pres$x))
    } else if (npcs <= 0 && perc_var > 0) {
      # Keep PCs until we exceed perc_var
      keep_npcs <- which((varexp - perc_var) >= 0)[1]
      if (is.na(keep_npcs)) keep_npcs <- ncol(pres$x) # fallback
    } else {
      # Both npcs and perc_var specified
      keep_npcs_var <- which((varexp - perc_var) >= 0)[1]
      if (is.na(keep_npcs_var)) keep_npcs_var <- ncol(pres$x)
      keep_npcs <- max(c(keep_npcs_var, npcs))
      keep_npcs <- max(1, keep_npcs) # at least 1 PC
    }
    
    sm <- pres$x[, 1:keep_npcs, drop=FALSE]
    colnames(sm) <- paste0("PC", seq_len(ncol(sm)))
  }
  
  as.data.frame(sm)
}
</file>

<file path="R/bids.R">
#' @importFrom crayon green cyan magenta yellow bold
NULL

#' @noRd
set_key <- function(fname, key, value) {
  p <- encode(fname)
  p[[key]] <- value
  p
}



#' @export
#' @rdname encode
#' @param fname The filename string to encode
encode.character <- function(fname) {
  p <- bids_parser()
  ret <- parse(p, fname)
  if (!is.null(ret)) {
    v <- ret$result$value
    v[!sapply(v, is.null)]
  } else {
    NULL
  }
}


#' @keywords internal
#' @noRd
list_files_github <- function(user, repo, subdir="") {
  gurl <- paste0("https://api.github.com/repos/", user, "/", repo, "/git/trees/master?recursive=1")
  req <- httr::GET(gurl)
  httr::stop_for_status(req)
  filelist <- unlist(lapply(httr::content(req)$tree, "[", "path"), use.names = F)
  if (subdir != "") {
    grep(paste0(subdir, "/"), filelist, value = TRUE, fixed = TRUE)
  } else {
    filelist
  }
}

#' @keywords internal
read_example <- function(project) {
  projurl <- paste0("https://raw.githubusercontent.com/bids-standard/bids-examples/master/", project)
  part_df <- rio::import(paste0(projurl, "/participants.tsv"))
}


#' @keywords internal
#' @noRd
get_sessions <- function(path, sid) {
  dnames <- basename(fs::dir_ls(paste0(path, "/", sid)))
  ret <- str_detect(dnames, "ses-.*")
  if (any(ret)) {
    dnames[ret]
  } else {
    list()
  }
}


#' @keywords internal
#' @noRd
descend <- function(node, path, ftype, parser) {
  # List all files in the directory
  dnames <- basename(fs::dir_ls(paste0(path)))
  ret <- str_detect(dnames, ftype)
  
  # Add the folder node (e.g., 'anat', 'func')
  node <- add_node(node, ftype, folder=ftype)
  
  if (any(ret)) {
    # Get all files in the folder
    fnames <- basename(fs::dir_ls(paste0(path, "/", ftype)))
    
    # Debug info to see which files we're attempting to parse
    # message("Processing ", length(fnames), " files in ", ftype, " folder at ", path)
    
    for (fname in fnames) {
      # Try to parse the filename using the provided parser
      mat <- parse(parser, fname)
      
      if (!is.null(mat)) {
        # The parser matched the file - extract the results
        keep <- sapply(mat$result, function(x) !is.null(x) && length(x) > 0)
        res <- mat$result[keep]
        
        # Ensure 'kind' attribute is always set when dealing with func files
        if (ftype == "func" && !is.null(res$suffix)) {
          # For func files with .nii or .nii.gz extension but no explicit kind
          if (grepl("nii(\\.gz)?$", res$suffix) && 
              (is.null(res$kind) || is.na(res$kind) || res$kind == "")) {
            # Explicitly set kind to "bold" for functional MRI files
            res$kind <- "bold"
          }
        }
        
        # Create a new node for this file
        pf <- purrr::partial(Node$new, fname)
        n <- Node$new(fname)
        n <- do.call(pf, res)
        
        # Add file path for reference
        n$relative_path <- file.path(ftype, fname)
        
        # Add the file node to the parent folder node
        node$AddChildNode(n)
      } else {
        # Parser didn't match - could add warning or debug info here
        # message("Could not parse file: ", fname, " in ", ftype, " folder")
      }
    }
  }
  
  return(node)
}


#' @keywords internal
#' @noRd
add_node <- function(bids, name, ...) {
  bids$AddChild(name, ...)
}

#' @keywords internal
#' @noRd
add_file <- function(bids, name,...) {
  bids$AddChild(name, ...)
}



#' Create a BIDS Project Object
#'
#' This function creates a BIDS project object from a directory containing BIDS-formatted
#' neuroimaging data. It can optionally load preprocessed derivatives from fMRIPrep.
#' The function validates the basic BIDS structure and provides methods for accessing
#' raw and preprocessed data, querying subjects, sessions, and tasks, reading event
#' files, and checking BIDS compliance.
#'
#' @param path Character string. The file path to the root of the BIDS project.
#'   Defaults to the current directory (".").
#' @param fmriprep Logical. Whether to load the fMRIPrep derivatives folder hierarchy.
#'   Defaults to FALSE.
#' @param prep_dir Character string. The location of the fMRIPrep subfolder relative
#'   to the derivatives directory. Defaults to "derivatives/fmriprep".
#'
#' @return A `bids_project` object representing the BIDS project structure. The object
#'   provides methods for:
#'   - Accessing raw and preprocessed data files
#'   - Querying subjects, sessions, and tasks
#'   - Reading event files and confound regressors
#'   - Checking BIDS compliance
#'   - Extracting metadata from file names
#'   Returns NULL if the directory does not contain a valid BIDS dataset.
#'
#' @examples
#' # Load a basic BIDS dataset
#' ds001_path <- system.file("extdata/ds001", package="bidser")
#' proj <- bids_project(ds001_path)
#'
#' # Check available tasks
#' tasks(proj)
#'
#' # Get participant IDs
#' participants(proj)
#'
#' # Load a dataset with fMRIPrep derivatives
#' fmriprep_path <- system.file("extdata/phoneme_stripped", package="bidser")
#' proj_prep <- bids_project(fmriprep_path, fmriprep=TRUE)
#'
#' # Access preprocessed data
#' preproc_scans(proj_prep)
#'
#' # Load a dataset with a custom fMRIPrep directory
#' proj_custom <- bids_project(fmriprep_path,
#'                            fmriprep=TRUE,
#'                            prep_dir="derivatives/custom_fmriprep")
#'
#' @export
bids_project <- function(path=".", fmriprep=FALSE, prep_dir="derivatives/fmriprep") {
  aparser <- anat_parser()
  fparser <- func_parser()
  
  path <- normalizePath(path)

  if (!file.exists(paste0(path, "/participants.tsv"))) {
    stop("participants.tsv is missing")
  }

  if (!file.exists(paste0(path, "/dataset_description.json"))) {
    warning("dataset_description.json is missing")
    desc <- list()
  } else {
    desc <- jsonlite::read_json(paste0(path, "/dataset_description.json"))
  }

  part_df <- read.table(paste0(path, "/participants.tsv"), header=TRUE, stringsAsFactors=FALSE, 
                        colClasses=c(participant_id="character"))
  project_name <- basename(path)

  bids <- Node$new(project_name)
  bids_raw <- add_node(bids, "raw")
  
  if (fmriprep) {
    #bids_prep <- bids$AddChild("derivatives/fmriprep")
    bids_prep <- add_node(bids, prep_dir)
    prep_func_parser <- fmriprep_func_parser()
    prep_anat_parser <- fmriprep_anat_parser() 
  } 
    
  sdirs <- as.character(part_df$participant_id)
  
  if (!all(stringr::str_detect(sdirs, "^sub"))) {
    ind <- which(!str_detect(sdirs, "^sub"))
    sdirs[ind] <- paste0("sub-", sdirs[ind])
  }
  
  has_sessions <- FALSE

  pb <- progress::progress_bar$new(total = length(sdirs))

  for (sdir in sdirs) {
   
    if (file.exists(paste0(path, "/", sdir))) {
      #node <- bids_raw$AddChild(sdir)
      node <- add_node(bids_raw, sdir)
      if (fmriprep && file.exists(paste0(path, "/", prep_dir, "/", sdir))) {
        #prepnode <- bids_prep$AddChild(sdir)
        prepnode <- add_node(bids_prep, sdir)
      }
    } else {
      next
    }

    sessions <- get_sessions(path, sdir)

    if (length(sessions) > 0) {
      has_sessions <- TRUE
      for (sess in sessions) {
        #snode <- node$AddChild(sess)
        snode <- add_node(node, sess, session=gsub("ses-", "", sess))
        #snode$session <- gsub("ses-", "", sess)
      
        descend(snode, paste0(path, "/", sdir, "/", sess), "anat", aparser)
        descend(snode, paste0(path, "/", sdir, "/", sess), "func", fparser)
        
        if (fmriprep) {
          #snode_prepped <- prepnode$AddChild(sess)
          #snode_prepped$session <- gsub("ses-", "", sess)
          snode_prepped <- add_node(prepnode, sess, session=gsub("ses-", "", sess))
          
          descend(snode_prepped, paste0(path, "/", prep_dir, "/", sdir, "/", sess), "anat", prep_anat_parser)
          descend(snode_prepped, paste0(path, "/", prep_dir, "/", sdir, "/", sess), "func", prep_func_parser)
          
        }
      }
    } else {
      descend(node, paste0(path, "/", sdir), "anat", aparser)
      descend(node, paste0(path, "/", sdir), "func", fparser)
      
      if (fmriprep) {
        descend(prepnode, paste0(path, "/", prep_dir, "/", sdir), "anat", prep_anat_parser)
        descend(prepnode, paste0(path, "/", prep_dir, "/", sdir), "func", prep_func_parser)
      }
    }
    
    pb$tick()
  }
  
  tbl <- tibble::as_tibble(data.tree::ToDataFrameTypeCol(bids, 'name', 'type', 'subid', 'session', 'task', 'run', 'modality', 'suffix'))
  tbl <- tbl %>% select(-starts_with("level_"))
  
  ret <- list(name=project_name, 
              part_df=part_df,
              bids_tree = bids,
              tbl = tbl,
              path=path,
              has_fmriprep=fmriprep,
              prep_dir=if (fmriprep) prep_dir else "",
              has_sessions=has_sessions)

  class(ret) <- "bids_project"
  ret
}

#' @export
#' @rdname flat_list-method
#' @method flat_list bids_project
flat_list.bids_project <- function(x, full_path=TRUE) {
  if (full_path) {
    data.tree::ToDataFrameTable(x$bids_tree, "pathString", "name") %>% filter(stringr::str_detect(name, "^sub-")) %>%
    rename(path=pathString) %>% select(path)
  } else {
    data.tree::ToDataFrameTable(x$bids_tree, "pathString", "name") %>% filter(stringr::str_detect(name, "^sub-")) %>%
      rename(path=pathString) %>% select(name)
  }
}



#' @export
print.bids_project <- function(x, ...) {
  # Ensure crayon is available
  if (!requireNamespace("crayon", quietly = TRUE)) {
    warning("`crayon` is not installed. Please install `crayon` for colored output.")
    # fallback to original print if crayon not available
    cat("project: ", x$name, "\n")
    cat("participants (n):", nrow(x$part_df), "\n")
    cat("tasks: ", tasks(x), "\n")
    if (x$has_sessions) {
      cat("sessions: ", sessions(x), "\n")
    }
    if (x$has_fmriprep) {
      cat("fmriprep: ", x$prep_dir, "\n")
    }
    cat("image types: ", unique(x$tbl$type[!is.na(x$tbl$type)]), "\n")
    cat("modalities: ", paste(unique(x$tbl$modality[!is.na(x$tbl$modality)]), collapse=", "), "\n")
    cat("keys: ", paste(unique(x$bids_tree$attributesAll), collapse=", "), "\n")
    return(invisible(x))
  }
  
  # Using crayon for colored output
  project_col <- crayon::bold(crayon::cyan(x$name))
  participant_count_col <- crayon::bold(crayon::green(nrow(x$part_df)))
  task_list <- tasks(x)
  task_list_col <- if (length(task_list) > 0) {
    crayon::yellow(paste(task_list, collapse=", "))
  } else {
    crayon::yellow("(none)")
  }
  
  cat(crayon::bold("BIDS Project Summary"), "\n")
  cat(crayon::bold("Project Name: "), project_col, "\n")
  cat(crayon::bold("Participants (n): "), participant_count_col, "\n")
  cat(crayon::bold("Tasks: "), task_list_col, "\n")
  
  if (x$has_sessions) {
    sess <- sessions(x)
    sess_col <- if (length(sess) > 0) crayon::yellow(paste(sess, collapse=", ")) else crayon::yellow("(none)")
    cat(crayon::bold("Sessions: "), sess_col, "\n")
  }
  
  if (x$has_fmriprep) {
    cat(crayon::bold("fMRIPrep Derivatives: "), crayon::magenta(x$prep_dir), "\n")
  }
  
  # Image types
  img_types <- unique(x$tbl$type[!is.na(x$tbl$type)])
  img_types_col <- if (length(img_types) > 0) crayon::green(paste(img_types, collapse=", ")) else crayon::green("(none)")
  cat(crayon::bold("Image Types: "), img_types_col, "\n")
  
  # Modalities
  mods <- unique(x$tbl$modality[!is.na(x$tbl$modality)])
  mods_col <- if (length(mods) > 0) crayon::green(paste(mods, collapse=", ")) else crayon::green("(none)")
  cat(crayon::bold("Modalities: "), mods_col, "\n")
  
  # Keys
  keys <- unique(x$bids_tree$attributesAll)
  keys_col <- if (length(keys) > 0) crayon::yellow(paste(keys, collapse=", ")) else crayon::yellow("(none)")
  cat(crayon::bold("Keys: "), keys_col, "\n")
  
  invisible(x)
}


#' @export
#' @rdname sessions-method
#' @method sessions bids_project
sessions.bids_project <- function(x) {
  if (x$has_session) {
    unique(unlist(x$bids_tree$Get("session", filterFun = function(x) !is.null(x$session))))
  } else {
    NULL
  }
}

#' @export
#' @rdname tasks-method
#' @method tasks bids_project
tasks.bids_project <- function(x) {
  sort(unique(x$bids_tree$Get("task", filterFun = function(x) {!is.na(x$task) && !is.null(x$task) } )))
  ##unique(x$bids_tree$Get("task", filterFun = function(x) !is.null(x$task) & !is.na(x$task)))
}


#' @export
#' @rdname participants-method
participants.bids_project <- function(x, ...) {
  if ("subid" %in% names(x$tbl)) {
    unique(x$tbl$subid[!is.na(x$tbl$subid)])
  } else {
    character(0)
  }
}



#' Get Functional Scans from a BIDS Project
#'
#' This method extracts functional scan files from a BIDS project based on specified
#' criteria such as subject ID, task name, run number, and session. It can return
#' either full or relative file paths to the functional scans.
#'
#' @param x A `bids_project` object.
#' @param subid Regular expression for matching subject IDs. Default is ".*".
#' @param task Regular expression for matching task names. Default is ".*".
#' @param run Regular expression for matching run numbers. Default is ".*".
#' @param session Regular expression for matching session IDs. Default is ".*".
#' @param kind Regular expression for matching scan type. Default is "bold".
#' @param full_path Logical. If TRUE, return full file paths. If FALSE, return
#'   relative paths. Default is TRUE.
#' @param ... Additional arguments (not currently used).
#'
#' @return A character vector of file paths to functional scans matching the criteria.
#'   Returns NULL if:
#'   - No matching files are found
#'   - The project doesn't contain functional data
#'   - The specified criteria don't match any files
#'
#' @examples
#' # Create a BIDS project
#' ds001_path <- system.file("extdata/ds001", package="bidser")
#' proj <- bids_project(ds001_path)
#'
#' # Get all functional scans
#' all_scans <- func_scans(proj)
#'
#' # Get scans for specific subjects
#' sub_scans <- func_scans(proj, subid="0[123]")
#'
#' # Get scans for a specific task
#' task_scans <- func_scans(proj, task="rest")
#'
#' # Get scans from specific runs
#' run_scans <- func_scans(proj, run="0[123]")
#'
#' # Combine multiple filters
#' filtered_scans <- func_scans(proj,
#'                             subid="01",
#'                             task="rest",
#'                             run="01")
#'
#' # Get relative paths instead of full paths
#' rel_scans <- func_scans(proj, full_path=FALSE)
#'
#' @export
func_scans.bids_project <- function (x, subid=".*", task=".*", run = ".*", session=".*", 
                                     kind="bold", full_path=TRUE, ...) {
  
  f <- function(node) {
    paste0(node$path[3:length(node$path)], collapse="/")
  }
  
  ret <- x$bids_tree$children$raw$Get(f, filterFun = function(z) {
    if (z$isLeaf && !is.null(z$task) &&  !is.null(z$type) && str_detect_null(z$kind,kind)
        && str_detect_null(z$subid, subid)  && str_detect_null(z$task, task) 
        && str_detect_null(z$session, session, default=TRUE) 
        && str_detect_null(z$run, run, default=TRUE) && str_detect_null(z$suffix, "nii(.gz)?$")) {
      TRUE
    } else {
      FALSE
    }
  })
  
  #ret <- names(ret)
  #paths <- sapply(stringr::str_split(ret, "_"), function(sp) {
  #  paste0(sp[[1]], "/", sp[[2]], "/func")
  #})
  #paste0(paths, "/", ret)
  if (full_path && !is.null(ret)) {
    ret <- paste0(x$path, "/", ret)
  }
  
  unname(ret)
}


#' @keywords internal
#' @noRd
str_detect_null <- function(x, pat, default=FALSE) {
  if (is.null(x) || is.na(x)) default else str_detect(x,pat)
}

#' Get preprocessed scans from a BIDS project
#'
#' This function retrieves paths to preprocessed functional MRI scans from a BIDS project's
#' fMRIPrep derivatives. It allows filtering by various BIDS entities such as subject,
#' task, run, session, and space. The function is particularly useful for accessing
#' preprocessed data for analysis pipelines.
#'
#' @param x A \code{bids_project} object.
#' @param subid A regex pattern for matching subjects. Default is ".*".
#' @param task A regex pattern for matching tasks. Default is ".*".
#' @param run A regex pattern for matching runs. Default is ".*".
#' @param variant A regex pattern for matching preprocessing variants. Default is NULL
#'   (no variant filtering).
#' @param space A regex pattern for matching spaces (e.g., "MNI152NLin2009cAsym").
#'   Default is ".*".
#' @param session A regex pattern for matching sessions. Default is ".*".
#' @param modality A regex pattern for matching modality. Default is "bold".
#'   Set this to something else if you need a different modality.
#' @param kind The kind of preprocessed data to return. Default is ".*" to match any kind.
#' @param full_path If TRUE, return full file paths. Otherwise return relative paths.
#'   Default is FALSE.
#' @param ... Additional arguments passed to internal functions.
#'
#' @return A character vector of file paths to preprocessed scans matching the criteria.
#'   Returns NULL if:
#'   - No matching files are found
#'   - The project doesn't have fMRIPrep derivatives
#'   - The specified criteria don't match any files
#'
#' @examples
#' # Create a BIDS project with fMRIPrep derivatives
#' proj <- bids_project(system.file("extdata/phoneme_stripped", package="bidser"),
#'                      fmriprep=TRUE)
#'
#' # Get all preprocessed BOLD scans
#' all_scans <- preproc_scans(proj)
#'
#' # Get preprocessed scans for specific subjects
#' sub_scans <- preproc_scans(proj, subid="0[12]")
#'
#' # Get scans in MNI space
#' mni_scans <- preproc_scans(proj, space="MNI152NLin2009cAsym")
#'
#' # Get scans for a specific task with full paths
#' task_scans <- preproc_scans(proj,
#'                            task="phoneme",
#'                            full_path=TRUE)
#'
#' # Get scans from a specific session
#' session_scans <- preproc_scans(proj, session="test")
#'
#' # Combine multiple filters
#' filtered_scans <- preproc_scans(proj,
#'                                subid="01",
#'                                task="phoneme",
#'                                run="01",
#'                                space="MNI152NLin2009cAsym")
#'
#' @export
preproc_scans.bids_project <- function(x, subid=".*", task=".*", run=".*", variant=NULL,
                                      space=".*", session=".*", modality="bold", kind=".*",
                                      full_path=FALSE, ...) {
  # Function to extract path from node
  f <- function(node) paste0(node$path[2:length(node$path)], collapse="/")
  
  pdir <- x$prep_dir
  
  # If variant is NULL, treat it as ".*"
  var_pattern <- if (is.null(variant)) ".*" else variant
  
  # Create a list of criteria to check
  criteria <- list(
    # Basic file criteria
    is_leaf = function(z) z$isLeaf,
    is_nifti = function(z) str_detect_null(z$suffix, "nii(.gz)?$"),
    
    # Metadata criteria
    matches_modality = function(z) str_detect_null(z$modality, modality, default=TRUE),
    matches_kind = function(z) str_detect_null(z$kind, kind, default=TRUE),
    matches_subid = function(z) str_detect_null(z$subid, subid),
    matches_task = function(z) str_detect_null(z$task, task, default=TRUE),
    matches_run = function(z) str_detect_null(z$run, run, default=TRUE),
    matches_session = function(z) str_detect_null(z$session, session, default=TRUE),
    matches_space = function(z) str_detect_null(z$space, space, default=TRUE),
    
    # Special handling for variant
    matches_variant = function(z) {
      # If variant not specified but z$variant is not null, skip this node
      if (is.null(variant) && !is.null(z$variant)) {
        return(FALSE)
      }
      return(str_detect_null(z$variant, var_pattern, default=TRUE))
    },
    
    # Preprocessed file criteria - must have either desc=preproc OR kind=preproc
    is_preprocessed = function(z) {
      return(str_detect_null(z$desc, "preproc", default=FALSE) || 
             str_detect_null(z$kind, "preproc", default=FALSE))
    }
  )
  
  # Get files matching all criteria
  ret <- x$bids_tree$children[[pdir]]$Get(f, filterFun = function(z) {
    # Apply all criteria and return TRUE only if all are met
    all(sapply(criteria, function(criterion) criterion(z)))
  })
  
  # Add full path if requested
  if (!is.null(ret) && full_path) {
    ret <- file.path(x$path, ret)
  }
  
  ret
}

#' @keywords internal
#' @noRd
key_match <- function(default=FALSE, ...) {
  keyvals <- list(...)
  
  # If no key-value pairs provided, always return TRUE
  if (length(keyvals) == 0) {
    return(function(x) TRUE)
  }
  
  keys <- names(keyvals)
  
  # Return a function that checks if an object matches all patterns
  function(x) {
    all(vapply(keys, function(k) {
      # Case 1: Key value is NULL in pattern but exists in object - no match
      if (is.null(keyvals[[k]]) && !is.null(x[[k]])) {
        return(FALSE)
      }
      
      # Case 2: Key value is NULL in pattern and NULL in object - match
      if (is.null(keyvals[[k]]) && is.null(x[[k]])) {
        return(TRUE)
      }
      
      # Case 3: Wildcard pattern ".*" - always match
      if (identical(keyvals[[k]], ".*")) {
        return(TRUE)
      }
      
      # Case 4: Use str_detect_null to match pattern
      return(str_detect_null(x[[k]], keyvals[[k]], default))
    }, logical(1)))
  }
}


#' Search for files in a BIDS project
#' 
#' This function searches for files in a BIDS project that match a specified pattern
#' and optional key-value criteria. It can search in both raw data and preprocessed 
#' derivatives (if available).
#'
#' @param x A \code{bids_project} object.
#' @param regex A regular expression to match against filenames. Default is ".*" (all files).
#' @param full_path If TRUE, return full file paths. If FALSE, return paths relative to the project root.
#' @param strict If TRUE, require that all queried keys must exist in matched files.
#'        If FALSE, allow matches for files missing queried keys.
#' @param new Deprecated parameter. Should always be FALSE.
#' @param ... Additional key-value pairs to filter files (e.g., subid = "01", task = "wm").
#'        These are matched against the corresponding metadata in the BIDS files.
#' @return A character vector of file paths matching the criteria, or NULL if no matches found.
#' @export
#' @rdname search_files 
#' @importFrom stringr str_detect
#' @examples
#' # Search for event files in a BIDS dataset
#' proj <- bids_project(system.file("extdata/ds001", package="bidser"), fmriprep=FALSE)
#' event_files <- search_files(proj, regex="events\\\\.tsv$")
#' 
#' # Search with additional criteria (note: ds001 only has one subject '01')
#' sub01_files <- search_files(proj, regex="bold\\\\.nii\\\\.gz$", subid="01", task="balloonanalogrisktask")
#' 
#' # Get full paths
#' full_paths <- search_files(proj, regex="events\\\\.tsv$", full_path=TRUE)
#' @param regex a regular expression to match files
#' @param full_path return full_path of files
#' @param strict if `TRUE` require that a queried key must exist in match files. 
#'     Otherwise, allow matches for files missing queried key.
#' @param ... additional keys to match on (e.g. subid = "01", task="wm")
#' @export
#' @rdname search_files 
#' @importFrom stringr str_detect
#' @examples
#'  proj <- bids_project(system.file("extdata/ds001", package="bidser"), fmriprep=FALSE)
#'  x = search_files(proj, regex="events")
search_files.bids_project <- function(x, regex=".*", full_path=FALSE, strict=TRUE, ...) {
  f <- function(node) {
    pdir_parts <- strsplit(x$prep_dir, "/")[[1]]
    # If preprocessed data are available and the node path matches the prep_dir structure:
    is_prep <- x$has_fmriprep && 
      length(node$path) > length(pdir_parts) && 
      all(node$path[2:(1+length(pdir_parts))] == pdir_parts)
    
    if (is_prep) {
      # If inside the preprocessed directory
      paste0(node$path[2:length(node$path)], collapse="/")
    } else {
      # If inside raw data directory
      paste0(node$path[3:length(node$path)], collapse="/")
    }
  }
  
  matcher <- key_match(default = !strict, ...)
  ret <- x$bids_tree$Get(f, filterFun = function(z) {
    z$isLeaf && str_detect(z$name, regex) && matcher(z)
  }, simplify=FALSE)
  
  if (length(ret) == 0) {
    return(NULL)
  }
  
  ret <- if (full_path && !is.null(ret)) {
    file.path(x$path, ret)
  } else {
    ret
  }
  
  as.vector(unlist(ret))
}


#' @keywords internal
match_attribute <- function(x, ...) {
  ll <- list(...)
  
  all(sapply(names(ll), function(key) {
    stringr::str_detect(attr(x, key), as.character(ll[[key]]))
  }))
}

#' Load all event files into a combined tibble
#'
#' This function searches for all `events.tsv` files that match the provided
#' filters (subid, task, run, session) and loads them into a single tibble.
#' If `full_path=TRUE`, full file paths are returned; otherwise relative paths.
#'
#' @param x A \code{bids_project} object.
#' @param subid A regex for matching participant IDs. Default is `".*"`.
#' @param task A regex for matching tasks. Default is `".*"`.
#' @param run A regex for matching runs. Default is `".*"`.
#' @param session A regex for matching sessions. Default is `".*"`.
#' @param full_path If TRUE, return full file paths before reading. Default is TRUE.
#' @param ... Additional arguments passed on to \code{search_files}.
#'
#' @return A tibble combining all matched event files, with columns `.subid`, `.task`, `.run`, `.session`
#' and all event columns. If no events are found, returns an empty tibble.
#'
#' @importFrom dplyr bind_rows mutate
#' @importFrom stringr str_match
#' @importFrom readr read_tsv
#' @importFrom tibble tibble
#' @export
load_all_events <- function(x, subid=".*", task=".*", run=".*", session=".*", full_path=TRUE, ...) {
  # Find all events files matching criteria
  event_files <- search_files(x, regex="events\\.tsv$", full_path=full_path, strict=TRUE,
                              subid=subid, task=task, run=run, session=session, ...)
  
  if (is.null(event_files) || length(event_files) == 0) {
    message("No matching event files found.")
    return(tibble::tibble())
  }
  
  # A helper to parse metadata from file name using keys in x$tbl
  parse_metadata <- function(fn) {
    # We will rely on encode() if available, or parse keys using regex
    # If `encode` is not stable enough, we can directly extract from file name:
    # sub-XXX[_ses-XXX][_task-XXX][_run-XXX]_events.tsv
    bname <- basename(fn)
    
    # Extract sub, ses, task, run from filename:
    subid_val <- stringr::str_match(bname, "sub-([A-Za-z0-9]+)")[,2]
    session_val <- stringr::str_match(bname, "ses-([A-Za-z0-9]+)")[,2]
    task_val <- stringr::str_match(bname, "task-([A-Za-z0-9]+)")[,2]
    run_val <- stringr::str_match(bname, "run-([0-9]+)")[,2]
    
    tibble::tibble(
      .subid = subid_val,
      .session = session_val,
      .task = task_val,
      .run = run_val,
      file = fn
    )
  }
  
  # Read and combine
  df_list <- lapply(event_files, function(fn) {
    meta <- parse_metadata(fn)
    dfx <- tryCatch({
      readr::read_tsv(fn, na = c("n/a", "NA"))
    }, error = function(e) {
      warning("Failed to read file: ", fn, " - ", e$message)
      return(NULL)
    })
    if (is.null(dfx)) return(NULL)
    dfx <- dfx %>% dplyr::mutate(.file = fn)
    dplyr::bind_cols(meta, dfx)
  })
  
  # Filter out any NULLs
  df_list <- df_list[!sapply(df_list, is.null)]
  
  if (length(df_list) == 0) {
    message("No valid event files could be read.")
    return(tibble::tibble())
  }
  
  dplyr::bind_rows(df_list)
}


#' Summarize a BIDS dataset
#'
#' Provides a quick summary of dataset statistics, including:
#' - Number of subjects
#' - Number of sessions (if applicable)
#' - Available tasks and the number of runs per task
#' - Total number of runs
#'
#' @param x A \code{bids_project} object.
#' @return A list with summary information:
#'   - `n_subjects`: number of participants
#'   - `n_sessions`: number of sessions (if any), otherwise NULL
#'   - `tasks`: a data frame with `task` and `n_runs` columns
#'   - `total_runs`: total number of runs across the dataset
#'
#' @importFrom dplyr group_by summarize n distinct
#' @importFrom tibble as_tibble
#' @export
bids_summary <- function(x) {
  # Participants
  subs <- participants(x)
  n_subs <- length(subs)
  
  # Sessions (if any)
  sess <- NULL
  if (x$has_sessions) {
    sess <- sessions(x)
  }
  
  # Tasks and runs
  # Assuming x$tbl has columns: subid, session, task, run
  # Count runs per task
  # Some datasets may have no runs or tasks columns populated, so guard checks:
  tbl <- x$tbl
  if (!"task" %in% names(tbl)) {
    # If no tasks at all, empty summary
    tasks_df <- tibble::tibble(task = character(0), n_runs = integer(0))
    total_runs <- 0
  } else {
    # Count how many runs per task:
    # If run is missing or always NA, treat each file as a run
    # If run is present, count unique run values:
    if ("run" %in% names(tbl)) {
      tasks_df <- tbl %>%
        dplyr::filter(!is.na(task)) %>%
        dplyr::group_by(task) %>%
        dplyr::summarize(n_runs = dplyr::n_distinct(run, na.rm=TRUE), .groups = "drop")
    } else {
      # If no run column, count occurrences of task as runs:
      tasks_df <- tbl %>%
        dplyr::filter(!is.na(task)) %>%
        dplyr::group_by(task) %>%
        dplyr::summarize(n_runs = n(), .groups = "drop")
    }
    
    total_runs <- sum(tasks_df$n_runs)
  }
  
  # Return a list summary
  list(
    n_subjects = n_subs,
    n_sessions = if (!is.null(sess)) length(sess) else NULL,
    tasks = tasks_df,
    total_runs = total_runs
  )
}

#' Basic BIDS Compliance Checks
#'
#' This function performs a simple, lightweight check of common BIDS requirements:
#' - Checks that `participants.tsv` and `dataset_description.json` exist at the root.
#' - Ensures all subject directories begin with `sub-`.
#' - If sessions are present, ensures that session directories begin with `ses-`.
#'
#' Note: This is not a full BIDS validator. For complete validation, use the 
#' official BIDS validator.
#'
#' @param x A \code{bids_project} object.
#'
#' @return A list with:
#'   - `passed` (logical): TRUE if all checks passed, FALSE otherwise.
#'   - `issues` (character vector): Descriptions of any issues found.
#'
#' @export
bids_check_compliance <- function(x) {
  issues <- character(0)
  
  # Check for participants.tsv
  if (!file.exists(file.path(x$path, "participants.tsv"))) {
    issues <- c(issues, "Missing participants.tsv at the root level.")
  }
  
  # Check for dataset_description.json
  if (!file.exists(file.path(x$path, "dataset_description.json"))) {
    issues <- c(issues, "Missing dataset_description.json at the root level.")
  }
  
  # Check subject directories
  # We assume subjects are identified by directories starting with "sub-"
  # Retrieve participant directories from the project object or files
  sub_dirs <- list.dirs(x$path, recursive = FALSE, full.names = FALSE)
  # Filter only directories that might be subjects (i.e. start with 'sub-')
  # We know from the project object, or we can guess by presence in participants
  # For a lightweight check, let's just ensure that all subjects in participants are present and start with "sub-"
  expected_subs <- participants(x)
  # participants(x) should return strings like "sub-01", "sub-02", etc.
  
  for (sid in expected_subs) {
    if (!dir.exists(file.path(x$path, sid))) {
      issues <- c(issues, paste("Subject directory not found for:", sid))
    }
    if (!grepl("^sub-", sid)) {
      issues <- c(issues, paste("Subject ID does not start with 'sub-':", sid))
    }
  }
  
  # Check session directories if sessions are present
  if (x$has_sessions) {
    # We assume sessions are directories inside subject directories
    # and should start with "ses-"
    for (sid in expected_subs) {
      s_path <- file.path(x$path, sid)
      if (dir.exists(s_path)) {
        # list sessions
        sess_dirs <- list.dirs(s_path, recursive = FALSE, full.names = FALSE)
        # Filter out known raw or derivative directories
        sess_dirs <- sess_dirs[grepl("^ses-", sess_dirs)]
        
        # sessions(x) returns all sessions; we can cross-check
        proj_sess <- sessions(x)
        # If proj_sess is NULL or empty, no sessions to check
        if (!is.null(proj_sess) && length(proj_sess) > 0) {
          # All sessions in proj_sess should appear as ses-xxx directories
          # also ensure they start with 'ses-'
          for (ss in proj_sess) {
            sdir <- paste0("ses-", ss)
            if (!dir.exists(file.path(s_path, sdir))) {
              issues <- c(issues, paste("Session directory not found for:", sdir, "in", sid))
            }
            if (!grepl("^ses-", sdir)) {
              issues <- c(issues, paste("Session ID does not start with 'ses-':", sdir))
            }
          }
        }
      }
    }
  }
  
  # Determine pass/fail
  passed <- length(issues) == 0
  
  list(passed = passed, issues = issues)
}
</file>

</files>
